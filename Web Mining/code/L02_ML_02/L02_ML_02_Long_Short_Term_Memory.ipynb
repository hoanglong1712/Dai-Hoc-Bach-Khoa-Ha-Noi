{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"L02_ML_02_Long_Short_Term_Memory.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMy/i+oj79B39LAaFnDXokW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"DXPLkZoPJBAZ"},"source":["This demo is derived from this [article](https://towardsdatascience.com/sentiment-analysis-using-lstm-step-by-step-50d074f09948)"]},{"cell_type":"markdown","metadata":{"id":"LoJ0MGzjKtxf"},"source":["This demo will show you how to build a bidirectional LSTM for text classification in just a few minutes.\n","The demo is divided into the following steps:\n","\n","1. Load in and visualize the data\n","2. Data processing\n","3. Training, Validation, Test Dataset Split\n","4. Define the LSTM Network Architecture\n","5. Training the Network\n","6. Testing"]},{"cell_type":"markdown","metadata":{"id":"tdWY398nLISo"},"source":["# Preprocess data\n","Data used in this demo is from [IMDB review dataset](http://ai.stanford.edu/~amaas/data/sentiment/).  \n","First, download the dataset and preprocess it."]},{"cell_type":"markdown","metadata":{"id":"dnQyH-nbYMIO"},"source":["## Download data and read"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uN3dBfCQMrEN","executionInfo":{"status":"ok","timestamp":1626665403258,"user_tz":-420,"elapsed":3422,"user":{"displayName":"Hoàng Ngô Việt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQtGW79dIWVWhS5pGVtlbbPd1S878019zZdkUa=s64","userId":"02634054224295293956"}},"outputId":"63923252-db21-4ab0-e037-834085c1ca1a"},"source":["!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"],"execution_count":1,"outputs":[{"output_type":"stream","text":["--2021-07-19 03:30:00--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n","Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 84125825 (80M) [application/x-gzip]\n","Saving to: ‘aclImdb_v1.tar.gz’\n","\n","aclImdb_v1.tar.gz   100%[===================>]  80.23M  29.1MB/s    in 2.8s    \n","\n","2021-07-19 03:30:03 (29.1 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7xHPI_hmJaw2","executionInfo":{"status":"ok","timestamp":1626665410978,"user_tz":-420,"elapsed":6630,"user":{"displayName":"Hoàng Ngô Việt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQtGW79dIWVWhS5pGVtlbbPd1S878019zZdkUa=s64","userId":"02634054224295293956"}}},"source":["# upzip downloaded file\n","!tar -xf aclImdb_v1.tar.gz\n","!mv ./aclImdb ./data"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GtJ82q97UWVl","executionInfo":{"status":"ok","timestamp":1626665412459,"user_tz":-420,"elapsed":1491,"user":{"displayName":"Hoàng Ngô Việt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQtGW79dIWVWhS5pGVtlbbPd1S878019zZdkUa=s64","userId":"02634054224295293956"}},"outputId":"970acb23-2856-45ec-f6fe-3a80d7c34f1c"},"source":["# load data\n","import os\n","train_reviews = []\n","train_labels = []\n","test_reviews = []\n","test_labels = []\n","\n","path = './data/train/pos/'\n","for file in os.listdir(path):\n","    with open(path + file) as f:\n","        review = f.read()\n","        train_reviews.append(review)\n","        train_labels.append(1) # 1 mean positive\n","\n","path = './data/train/neg/'\n","for file in os.listdir(path):\n","    with open(path + file) as f:\n","        review = f.read()\n","        train_reviews.append(review)\n","        train_labels.append(0) # 0 mean negative\n","\n","path = './data/test/pos/'\n","for file in os.listdir(path):\n","    with open(path + file) as f:\n","        review = f.read()\n","        test_reviews.append(review)\n","        test_labels.append(1) # 1 mean positive\n","\n","path = './data/test/neg/'\n","for file in os.listdir(path):\n","    with open(path + file) as f:\n","        review = f.read()\n","        test_reviews.append(review)\n","        test_labels.append(0) # 0 mean negative\n","\n","print('train data length', len(train_reviews))\n","print('test data length', len(test_reviews))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["train data length 25000\n","test data length 25000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z3PaI4M0XX16","executionInfo":{"status":"ok","timestamp":1626665412462,"user_tz":-420,"elapsed":16,"user":{"displayName":"Hoàng Ngô Việt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQtGW79dIWVWhS5pGVtlbbPd1S878019zZdkUa=s64","userId":"02634054224295293956"}},"outputId":"db558171-a789-48fd-eb25-cb8a7213edca"},"source":["print(train_reviews[0])\n","print(train_labels[0])"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Erich Rohmer's \"L'Anglaise et le duc\" makes a perfect companion piece to Peter Watkins' \"La Commune (Paris 1871).\" Both films -screened at this year's Toronto International Film Festival- ironically illustrate how history is shaped to by the tellers of the tale. Ironic, given the tragic events that were taking place in the U.S. during the festival.<br /><br />Set in Paris during the French Revolution, the movie, based on Grace Elliott's (Lucy Russell) \"Memoirs,\" is a first-hand account of how she survived those heady but dangerous days. She also details her relationship with The Duke of Orleans (played by Jean-Claude Dreyfus), who, in contrast to herself, is a supporter of the Revolution.<br /><br />True to form, you don't know whose side of history Rohmer is going to come down on. One of the earliest of the French \"New Wave\" filmmakers, Rohmer has often been criticized for being too conservative. After all, in the midst of the rebelling-youth-Viet-Nam days of the late 60s and 70s, he was filming romantic little confections like \"Claire's Knee.\" But don't sell the old boy short, folks, he's always been a student of human nature, not an ideologue, and \"L'Anglaise et le duc\" continues to bear this out.<br /><br />Rohmer's characters are never the \"bad guys\" nor the \"good guys'; they are first and foremost human beings who are capable of exhibiting a full range of human potentialities -and limitations. That's why his movies are always provocative, and this film is no exception.<br /><br />Now for the technological nuts and bolts.<br /><br />Rohmer, though making his way into his 80s, is still on the cutting-edge of cinematic innovation. The look of \"L'Anglaise\" is like something you've never seen before. You guessed it, the old guy -like several of the festival's directors this year- has gone digital.<br /><br />All of the movie's exterior scenes look as though they are taking place in their original 1780s Parisian settings. As a matter of fact, you may get so distracted from marveling at the authenticity of the film's look you may have to go back for a second screening to catch the subtleties of the film's psychological -and yes, I'll say it- political insights.<br /><br />Toronto features some of the world's edgiest young filmmakers this year, as well as some of the world's oldest. And the old masters are standing there on cinema's cutting-edges right alongside the young ones.<br /><br />Long live youth. Long live old age. And long live Erich Rohmer.<br /><br />\n","1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"46m3zq9RMGYB"},"source":["## Convert to lower case and remove punctuation"]},{"cell_type":"code","metadata":{"id":"rMvrrVDvYXnM","executionInfo":{"status":"ok","timestamp":1626665418603,"user_tz":-420,"elapsed":6151,"user":{"displayName":"Hoàng Ngô Việt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQtGW79dIWVWhS5pGVtlbbPd1S878019zZdkUa=s64","userId":"02634054224295293956"}}},"source":["from string import punctuation\n","def preprocess(text):\n","    # convert to lower case\n","    text = text.lower()\n","\n","    # remove punctuation \n","    # !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \n","    text = ''.join([c for c in text if c not in punctuation])\n","\n","    return text\n","\n","train_reviews = [preprocess(r) for r in train_reviews]\n","test_reviews = [preprocess(r) for r in test_reviews]"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gj7tZlSoZ5MP"},"source":["# Tokenize and create vocabulary-to-integer mapping dictionary\n","In most of the NLP tasks, you will create an index mapping dictionary in such a way that your frequently occurring words are assigned lower indexes. One of the most common way of doing this is to use `Counter` method from `Collections` library."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ejrY3G4ZZZA3","executionInfo":{"status":"ok","timestamp":1626665421536,"user_tz":-420,"elapsed":2942,"user":{"displayName":"Hoàng Ngô Việt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQtGW79dIWVWhS5pGVtlbbPd1S878019zZdkUa=s64","userId":"02634054224295293956"}},"outputId":"e0a6d98c-c4a6-4d9e-885e-fc86636a2967"},"source":["from collections import Counter\n","def build_vocab(train, test):\n","\n","    counter = Counter()\n","    for review in train:\n","        words = review.split()\n","        counter.update(words)\n","\n","    for review in test:\n","        words = review.split()\n","        counter.update(words)\n","\n","    print('dictionary length', len(counter.items()))\n","    # trick here, \n","    # we count the first word from 1 to preserve 0 for padding token\n","    vocab = {w:i+1 for i, (w,c) in enumerate(counter.items())}\n","    # vocab['<pad>'] = 0\n","    return vocab\n","\n","vocab = build_vocab(train_reviews, test_reviews)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["dictionary length 181685\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sozFSt02fyq6"},"source":["## Convert reviews into vector\n","Reviews are currently in type of text. Before passing them to model, we have to convert them into vectors of numbers using `vocab`"]},{"cell_type":"code","metadata":{"id":"XGTTqtHpdWXp","executionInfo":{"status":"ok","timestamp":1626665424728,"user_tz":-420,"elapsed":3198,"user":{"displayName":"Hoàng Ngô Việt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQtGW79dIWVWhS5pGVtlbbPd1S878019zZdkUa=s64","userId":"02634054224295293956"}}},"source":["# Convert reviews into vectors\n","def numericalize(reviews, vocab):\n","    vectors = []\n","    for review in reviews:\n","        vector = [vocab[w] for w in review.split()]\n","        vectors.append(vector)\n","    return vectors\n","\n","train_vectors = numericalize(train_reviews, vocab)\n","test_vectors = numericalize(test_reviews, vocab)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AQUJZ_fifxkE"},"source":["## Pad and truncate data"]},{"cell_type":"code","metadata":{"id":"_bRncHHoL8JQ","executionInfo":{"status":"ok","timestamp":1626665425818,"user_tz":-420,"elapsed":7,"user":{"displayName":"Hoàng Ngô Việt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQtGW79dIWVWhS5pGVtlbbPd1S878019zZdkUa=s64","userId":"02634054224295293956"}}},"source":["train_vectors_length = [len(v) for v in train_vectors]\n","test_vectors_length = [len(v) for v in test_vectors]"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":448},"id":"5V_OX8BDfpk5","executionInfo":{"status":"ok","timestamp":1626665427276,"user_tz":-420,"elapsed":504,"user":{"displayName":"Hoàng Ngô Việt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQtGW79dIWVWhS5pGVtlbbPd1S878019zZdkUa=s64","userId":"02634054224295293956"}},"outputId":"c54474ae-f5ad-4b12-ab93-ffdc62809bbb"},"source":["import matplotlib.pyplot as plt\n","print('min review length', min(train_vectors_length))\n","print('max review length', max(train_vectors_length))\n","print('mean review length', sum(train_vectors_length) / len(train_vectors_length))\n","\n","plt.figure(figsize=(12,6))\n","plt.hist(train_vectors_length, bins=100)\n","plt.plot()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["min review length 10\n","max review length 2469\n","mean review length 232.87256\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{"tags":[]},"execution_count":9},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"9WrVCvqRgjjn"},"source":["As the histogram depict, there are approximate 80% of data has fewer than 500 words. We will choose this as the fixed-length of data. Review with shorter length will be padded; review with longer length will be truncated to the fixed-length. "]},{"cell_type":"code","metadata":{"id":"VbyzYbcGh-5q","executionInfo":{"status":"ok","timestamp":1626665428197,"user_tz":-420,"elapsed":934,"user":{"displayName":"Hoàng Ngô Việt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQtGW79dIWVWhS5pGVtlbbPd1S878019zZdkUa=s64","userId":"02634054224295293956"}}},"source":["def edit_length(vectors):\n","    fixed_length = 500\n","    pad_index = 0\n","    new_vectors = []\n","    for vector in vectors:\n","        if len(vector) < fixed_length:\n","            # add padding index to head of vector\n","            vector = [pad_index] * (fixed_length - len(vector)) + vector\n","        else:\n","            vector = vector[:fixed_length]\n","        new_vectors.append(vector)\n","        \n","    return new_vectors\n","\n","train_vectors = edit_length(train_vectors)\n","test_vectors = edit_length(test_vectors)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xLgA4gt9jJgO"},"source":["# Train, dev split"]},{"cell_type":"code","metadata":{"id":"jibxGw8quvl6","executionInfo":{"status":"ok","timestamp":1626665428691,"user_tz":-420,"elapsed":510,"user":{"displayName":"Hoàng Ngô Việt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQtGW79dIWVWhS5pGVtlbbPd1S878019zZdkUa=s64","userId":"02634054224295293956"}}},"source":["from sklearn.model_selection import train_test_split\n","train_vectors, valid_vectors, train_labels, valid_labels = \\\n","    train_test_split(train_vectors, train_labels, test_size=0.2, random_state=0)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6XHIX0VxvjnX","executionInfo":{"status":"ok","timestamp":1626665429303,"user_tz":-420,"elapsed":7,"user":{"displayName":"Hoàng Ngô Việt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQtGW79dIWVWhS5pGVtlbbPd1S878019zZdkUa=s64","userId":"02634054224295293956"}},"outputId":"9ff25663-f643-4dae-ec7d-8999904ffa21"},"source":["print(len(train_vectors), len(valid_vectors))\n","print(len(train_labels), len(valid_labels))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["20000 5000\n","20000 5000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0OPrfmVgjh1a","executionInfo":{"status":"ok","timestamp":1626665435239,"user_tz":-420,"elapsed":5117,"user":{"displayName":"Hoàng Ngô Việt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQtGW79dIWVWhS5pGVtlbbPd1S878019zZdkUa=s64","userId":"02634054224295293956"}}},"source":["from torch.utils.data import TensorDataset, DataLoader\n","import torch\n","train_ds = TensorDataset(torch.Tensor(train_vectors),\n","                        #  torch.LongTensor(train_vectors_length),\n","                    torch.Tensor(train_labels))\n","valid_ds = TensorDataset(torch.Tensor(valid_vectors),\n","                        #  torch.LongTensor(train_vectors_length),\n","                    torch.Tensor(valid_labels))\n","test_ds = TensorDataset(torch.Tensor(test_vectors), \n","                        # torch.LongTensor(test_vectors_length),\n","                        torch.Tensor(test_labels))\n","\n","batch_size = 64\n","train_dl = DataLoader(train_ds, shuffle=True, batch_size=batch_size, \n","                      drop_last=True)\n","valid_dl = DataLoader(valid_ds, shuffle=False, batch_size=batch_size)\n","test_dl = DataLoader(test_ds, shuffle=False, batch_size=batch_size)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A0Ymtf1uksPw"},"source":["# Define LSTM architechture"]},{"cell_type":"code","metadata":{"id":"0Pgc0qjekluS","executionInfo":{"status":"ok","timestamp":1626665599256,"user_tz":-420,"elapsed":323,"user":{"displayName":"Hoàng Ngô Việt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQtGW79dIWVWhS5pGVtlbbPd1S878019zZdkUa=s64","userId":"02634054224295293956"}}},"source":["import torch.nn as nn\n","\n","class SentimentLSTM(nn.Module):\n","    \"\"\"\n","    The RNN model that will be used to perform Sentiment analysis.\n","    \"\"\"\n","\n","    def __init__(self, vocab_size, output_size, embedding_dim, \n","                 hidden_dim, n_layers, \n","                 drop_prob=0.5):\n","        \"\"\"\n","        Initialize the model by setting up the layers.\n","        \"\"\"\n","        super().__init__()\n","\n","        self.output_size = output_size\n","        self.n_layers = n_layers\n","        self.hidden_dim = hidden_dim\n","        \n","        # embedding and LSTM layers\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n","                            dropout=drop_prob, batch_first=True)\n","        \n","        # dropout layer\n","        self.dropout = nn.Dropout(0.3)\n","        \n","        # linear and sigmoid layers\n","        self.fc = nn.Linear(hidden_dim, output_size)\n","        self.sig = nn.Sigmoid()\n","        \n","\n","    def forward(self, x, hidden):\n","        \"\"\"\n","        Perform a forward pass of our model on some input and hidden state.\n","        \"\"\"\n","        batch_size = x.size(0)\n","\n","        # embeddings and lstm_out\n","        embeds = self.embedding(x)\n","        lstm_out, hidden = self.lstm(embeds, hidden)\n","    \n","        # stack up lstm outputs\n","        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n","        \n","        # dropout and fully-connected layer\n","        out = self.dropout(lstm_out)\n","        out = self.fc(out)\n","        # sigmoid function\n","        sig_out = self.sig(out)\n","        \n","        # reshape to be batch_size first\n","        sig_out = sig_out.view(batch_size, -1)\n","        sig_out = sig_out[:, -1] # get last batch of labels\n","        \n","        # return last sigmoid output and hidden state\n","        return sig_out, hidden\n","    \n","    \n","    def init_hidden(self, batch_size):\n","        ''' Initializes hidden state '''\n","        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n","        # initialized to zero, for hidden state and cell state of LSTM\n","        weight = next(self.parameters()).data\n","        \n","        if (torch.cuda.is_available()):\n","            hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda()\n","            cell = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda()\n","        else:\n","            hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()\n","            cell = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()\n","        \n","        return hidden, cell"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eLnOMIqjrHs3"},"source":["# Train model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LR1ZhKI6rIss","executionInfo":{"status":"ok","timestamp":1626665603935,"user_tz":-420,"elapsed":749,"user":{"displayName":"Hoàng Ngô Việt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQtGW79dIWVWhS5pGVtlbbPd1S878019zZdkUa=s64","userId":"02634054224295293956"}},"outputId":"aa7b1302-f772-4408-ce21-cf9591cf55be"},"source":["# Instantiate the model w/ hyperparams\n","vocab_size = len(vocab)+1 # +1 for the 0 padding\n","output_size = 1\n","embedding_dim = 300\n","hidden_dim = 300\n","n_layers = 2\n","net = SentimentLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n","print(net)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["SentimentLSTM(\n","  (embedding): Embedding(181686, 300, padding_idx=0)\n","  (lstm): LSTM(300, 300, num_layers=2, batch_first=True, dropout=0.5)\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (fc): Linear(in_features=300, out_features=1, bias=True)\n","  (sig): Sigmoid()\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":438},"id":"U9ZhVzrMrd_4","executionInfo":{"status":"error","timestamp":1626666814725,"user_tz":-420,"elapsed":4178,"user":{"displayName":"Hoàng Ngô Việt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQtGW79dIWVWhS5pGVtlbbPd1S878019zZdkUa=s64","userId":"02634054224295293956"}},"outputId":"f5b526a1-92b8-4261-d97c-4d8b48a0dacc"},"source":["# loss and optimization functions\n","lr=0.001\n","\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n","\n","\n","# training params\n","\n","epochs = 4 # \n","\n","counter = 0\n","print_every = 1\n","clip=5 # gradient clipping\n","train_on_gpu = torch.cuda.is_available()\n","\n","# move model to GPU, if available\n","if(train_on_gpu):\n","    net.cuda()\n","\n","net.train()\n","# train for some number of epochs\n","for e in range(epochs):\n","    # initialize hidden state\n","    h, c = net.init_hidden(batch_size)\n","\n","    # batch loop\n","    for inputs, labels in train_dl:\n","        counter += 1\n","\n","        inputs = inputs.long()\n","        if(train_on_gpu):\n","            inputs, labels = inputs.cuda(), labels.cuda()\n","\n","        # Creating new variables for the hidden state, otherwise\n","        # we'd backprop through the entire training history\n","        h = h.data\n","        c = c.data\n","\n","        if train_on_gpu:\n","            h = h.cuda()\n","            c = c.cuda()\n","\n","        # zero accumulated gradients\n","        net.zero_grad()\n","\n","        # get the output from the model\n","        \n","        output, (h, c) = net(inputs, (h, c))\n","\n","        # calculate the loss and perform backprop\n","        loss = criterion(output.squeeze(), labels.float())\n","        loss.backward()\n","        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n","        nn.utils.clip_grad_norm_(net.parameters(), clip)\n","        optimizer.step()\n","\n","        # loss stats\n","        if counter % print_every == 0:\n","            # Get validation loss\n","            val_h = net.init_hidden(batch_size)\n","            val_losses = []\n","            net.eval()\n","            for inputs, labels in valid_dl:\n","\n","                # Creating new variables for the hidden state, otherwise\n","                # we'd backprop through the entire training history\n","                val_h = tuple([each.data for each in val_h])\n","                inputs = inputs.long()\n","                if(train_on_gpu):\n","                    inputs, labels = inputs.cuda(), labels.cuda()\n","                \n","                output, val_h = net(inputs, val_h)\n","                val_loss = criterion(output.squeeze(), labels.float())\n","\n","                val_losses.append(val_loss.item())\n","\n","            net.train()\n","            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n","                  \"Step: {}...\".format(counter),\n","                  \"Loss: {:.6f}...\".format(loss.item()),\n","                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"],"execution_count":33,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-00bb5e1e59db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m                 \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-9e701986028a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# embeddings and lstm_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# stack up lstm outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m         self.check_hidden_size(hidden[0], self.get_expected_hidden_size(input, batch_sizes),\n\u001b[0;32m--> 622\u001b[0;31m                                'Expected hidden[0] size {}, got {}')\n\u001b[0m\u001b[1;32m    623\u001b[0m         self.check_hidden_size(hidden[1], self.get_expected_cell_size(input, batch_sizes),\n\u001b[1;32m    624\u001b[0m                                'Expected hidden[1] size {}, got {}')\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    224\u001b[0m                           msg: str = 'Expected hidden size {}, got {}') -> None:\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected hidden[0] size (2, 8, 300), got [2, 64, 300]"]}]},{"cell_type":"markdown","metadata":{"id":"IWYTVfiqrhN4"},"source":["# Test"]},{"cell_type":"code","metadata":{"id":"a2GOQgMrriwF"},"source":["# Get test data loss and accuracy\n","\n","test_losses = [] # track loss\n","num_correct = 0\n","\n","# init hidden state\n","h = net.init_hidden(batch_size)\n","\n","net.eval()\n","# iterate over test data\n","for inputs, labels in test_loader:\n","\n","    # Creating new variables for the hidden state, otherwise\n","    # we'd backprop through the entire training history\n","    h = tuple([each.data for each in h])\n","\n","    if(train_on_gpu):\n","        inputs, labels = inputs.cuda(), labels.cuda()\n","    \n","    # get predicted outputs\n","    inputs = inputs.type(torch.LongTensor)\n","    output, h = net(inputs, h)\n","    \n","    # calculate loss\n","    test_loss = criterion(output.squeeze(), labels.float())\n","    test_losses.append(test_loss.item())\n","    \n","    # convert output probabilities to predicted class (0 or 1)\n","    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n","    \n","    # compare predictions to true label\n","    correct_tensor = pred.eq(labels.float().view_as(pred))\n","    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n","    num_correct += np.sum(correct)\n","\n","\n","# -- stats! -- ##\n","# avg test loss\n","print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n","\n","# accuracy over all test data\n","test_acc = num_correct/len(test_loader.dataset)\n","print(\"Test accuracy: {:.3f}\".format(test_acc))"],"execution_count":null,"outputs":[]}]}