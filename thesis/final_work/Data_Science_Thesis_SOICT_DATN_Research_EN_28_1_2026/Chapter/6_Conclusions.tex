\documentclass[../main.tex]{subfiles}
\begin{document}

\section{Summary}


This thesis has successfully proposed and implemented a novel two-stage methodology known as Multi-view Gait Recognition with Deep Learning (MVDL). The central aim of this approach is to improve both the accuracy and robustness of cross-view gait recognition systems, with particular emphasis on enhancing single-view inference. By combining innovative mechanisms inspired by Graph Neural Networks (GNNs) with the synthesis capabilities of Transformer models, the methodology establishes a comprehensive framework that addresses key limitations in existing research and achieves better  performance on benchmark datasets.

The first major achievement of this work is the introduction of a GNN-inspired knowledge propagation mechanism. This technique was applied to bidirectionally enrich the feature embeddings generated by view-specific Convolutional Neural Networks (CNNs). In conventional single-view training, models often suffer from data scarcity and overfitting, which limit their ability to generalize across different perspectives. By enabling embeddings from one camera angle to exchange information with those from neighboring angles, the knowledge propagation mechanism effectively mitigates these issues. As a result, the enriched embeddings become more robust and discriminative, which lays the strong foundation for accurate gait recognition across multiple viewpoints.

The second achievement is the utilization of a Transformer-based model to synthesize the enriched embedding vectors obtained from multiple camera angles. This synthesis step is critical in creating a maximally discriminative representation of gait identity. By leveraging the Transformer’s ability to capture long-range dependencies and contextual relationships, the model integrates information from angles such as 45°, 60°, 75°, and 90° into a unified representation. The complete MVDL pipeline achieved a final Rank-1 Accuracy of 96.75\% on the benchmark GEI dataset. Furthermore, the numerical results demonstrated an average Rank-1 Accuracy increase of approximately 3.79\% across the tested camera angles compared to baseline training, highlighting the effectiveness of the multi-perspective synthesis process.

The third achievement is the clear outperformance of state-of-the-art models. The accuracy of 96.75\% achieved by MVDL surpasses the performance of all currently published gait recognition approaches, including the 95.4\% accuracy reported by Cross-View Gait Recognition through Discriminative Feature Learning. This accomplishment successfully addresses the research objective of exceeding the long-standing 96\% accuracy barrier, establishing MVDL as a new benchmark in the field.

In conclusion, the MVDL methodology provides a computationally efficient and highly accurate solution for robust gait recognition. By effectively leveraging multi-view information during training, the framework significantly enhances single-view inference capability. This dual-stage approach not only extend the technical boundaries of gait recognition but also demonstrates the potential of combining GNN-inspired enrichment with Transformer-based synthesis to achieve superior results in complex recognition tasks.


\section{Suggestion for Future Works }

The findings of this research open several promising directions for future investigation, each aimed at further enhancing the performance, efficiency, and applicability of gait recognition systems. One important avenue is the integration of real-time data streams. At present, the methodology relies on static Gait Energy Image (GEI) inputs, which limits its adaptability to dynamic environments. Future work should focus on extending the knowledge propagation and synthesis mechanisms to process raw sequential video frames or skeleton data in real time. Achieving this would require the incorporation of Recurrent Neural Networks (RNNs) or specialized spatio-temporal graph models capable of capturing temporal dependencies and motion dynamics. Such an extension would significantly improve the practicality of gait recognition systems in surveillance and monitoring applications.  

Another promising direction is the development of adaptive view selection mechanisms. The current system synthesizes information from a fixed set of four camera angles, which may not always be optimal under varying environmental conditions. A more advanced approach would allow the model to dynamically select the two or three most informative camera angles based on contextual factors such as occlusions, lighting variations, or crowd density. This adaptive selection could improve computational efficiency by reducing redundant processing while maintaining or even enhancing recognition accuracy.  

Finally, hardware optimization represents a crucial step toward real-world application. Investigating techniques such as pruning and quantization for both the enriched CNN models and the Transformer-based synthesis model could enable deployment on resource-constrained edge devices, including surveillance cameras and embedded systems. By reducing computational overhead without significantly compromising accuracy, these optimizations would pave the way for scalable and cost-effective implementations of gait recognition in security systems and smart city infrastructures.  

Together, these future directions highlight the potential to transform the current methodology into a more versatile, efficient, and widely applicable solution for gait recognition in dynamic and resource-limited environments.  


\end{document}