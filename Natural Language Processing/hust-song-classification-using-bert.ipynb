{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8332955,"sourceType":"datasetVersion","datasetId":4948335}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-06T08:02:03.689175Z","iopub.execute_input":"2024-05-06T08:02:03.689799Z","iopub.status.idle":"2024-05-06T08:02:03.699194Z","shell.execute_reply.started":"2024-05-06T08:02:03.689767Z","shell.execute_reply":"2024-05-06T08:02:03.698152Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"/kaggle/input/smallsongs2/l_df.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:02:03.701017Z","iopub.execute_input":"2024-05-06T08:02:03.701327Z","iopub.status.idle":"2024-05-06T08:02:03.708519Z","shell.execute_reply.started":"2024-05-06T08:02:03.701302Z","shell.execute_reply":"2024-05-06T08:02:03.707671Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\ndef load_song_data(data_file, bert_model_name, max_length):\n  df = pd.read_csv(data_file)\n  tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n  df['encoding'] = df.apply(lambda x: tokenizer(x['S_Lyric'], return_tensors='pt', max_length=max_length, padding='max_length', truncation=True) ,  axis=1)  \n  encodings = df['encoding'].tolist()\n  #texts = df['S_Lyric'].tolist()\n  labels = [int(v) for v in df['Genre_Index'].tolist()]\n  ids_genres = df[['Genre_Index', 'Genre']].drop_duplicates()\n  ids_genres = ids_genres.set_index('Genre_Index')\n  return encodings, labels, ids_genres\n  #return texts, labels, ids_genres","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:02:03.709501Z","iopub.execute_input":"2024-05-06T08:02:03.709757Z","iopub.status.idle":"2024-05-06T08:02:03.717788Z","shell.execute_reply.started":"2024-05-06T08:02:03.709734Z","shell.execute_reply":"2024-05-06T08:02:03.716726Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class TextClassificationDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length):\n        self.texts = texts\n        self.labels = labels\n        \n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        pass\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        encoding = self.texts[idx]\n        label = self.labels[idx]\n        #encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n        return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'label': torch.tensor(label)}\n        #encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n        #return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'label': torch.tensor(label)}\n        \nclass BERTClassifier(nn.Module):\n    def __init__(self, bert_model_name, num_classes):\n        super(BERTClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained(bert_model_name)\n        self.dropout = nn.Dropout(0.1)\n        #self.fc1 = nn.Linear(self.bert.config.hidden_size, 64)\n        #self.relu = nn.ReLU()\n        #self.fc2 = nn.Linear(256, 64)\n        #self.fc3 = nn.Linear(64, num_classes)\n        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        x = self.dropout(pooled_output)\n        #x = self.relu(self.fc1(x))\n        #x = self.fc2(x)\n        #x = self.fc3(x)\n        #return x\n        logits = self.fc(x)\n        return logits\n\ndef train(model, data_loader, optimizer, scheduler, device):\n    model.train()\n    for batch in data_loader:\n        optimizer.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        loss = nn.CrossEntropyLoss()(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\ndef evaluate(model, data_loader, device):\n    model.eval()\n    predictions = []\n    actual_labels = []\n    with torch.no_grad():\n        for batch in data_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            _, preds = torch.max(outputs, dim=1)\n            predictions.extend(preds.cpu().tolist())\n            actual_labels.extend(labels.cpu().tolist())\n    return accuracy_score(actual_labels, predictions), classification_report(actual_labels, predictions)\n\ndef predict_sentiment(text, model, tokenizer, device, ids_genres, max_length=128):\n    model.eval()\n    #encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n    encoding = text\n    input_ids = encoding['input_ids'].to(device)\n    attention_mask = encoding['attention_mask'].to(device)\n\n    with torch.no_grad():\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            _, preds = torch.max(outputs, dim=1)\n    #return \"positive\" if preds.item() == 1 else \"negative\"\n    return ids_genres.loc[preds.item()][0]","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:05:49.738124Z","iopub.execute_input":"2024-05-06T08:05:49.738538Z","iopub.status.idle":"2024-05-06T08:05:49.756314Z","shell.execute_reply.started":"2024-05-06T08:05:49.738507Z","shell.execute_reply":"2024-05-06T08:05:49.755255Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Set up parameters\nbert_model_name = 'bert-base-uncased'\n\nmax_length = 128\nbatch_size = 16\nnum_epochs = 10\nlearning_rate = 2e-5\n\ndata_file = \"/kaggle/input/smallsongs2/l_df.csv\"\ntexts, labels, ids_genres = load_song_data(data_file, bert_model_name, max_length)\n\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2) #, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:02:03.846378Z","iopub.execute_input":"2024-05-06T08:02:03.846959Z","iopub.status.idle":"2024-05-06T08:03:42.547923Z","shell.execute_reply.started":"2024-05-06T08:02:03.846928Z","shell.execute_reply":"2024-05-06T08:03:42.546918Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"\ntokenizer = BertTokenizer.from_pretrained(bert_model_name)\ntrain_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\nval_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n\nnum_classes = ids_genres.shape[0]\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = BERTClassifier(bert_model_name, num_classes) #.to(device)\nmodel = torch.nn.DataParallel(model).to(device) #.to(device).to(device)\n\noptimizer = AdamW(model.parameters(), lr=learning_rate)\ntotal_steps = len(train_dataloader) * num_epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:05:56.300831Z","iopub.execute_input":"2024-05-06T08:05:56.301604Z","iopub.status.idle":"2024-05-06T08:05:56.927589Z","shell.execute_reply.started":"2024-05-06T08:05:56.301574Z","shell.execute_reply":"2024-05-06T08:05:56.926797Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"num_classes\nids_genres","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:03:43.193272Z","iopub.execute_input":"2024-05-06T08:03:43.193646Z","iopub.status.idle":"2024-05-06T08:03:43.208120Z","shell.execute_reply.started":"2024-05-06T08:03:43.193608Z","shell.execute_reply":"2024-05-06T08:03:43.207161Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                  Genre\nGenre_Index            \n0               Country\n1               Hip-Hop\n2            Electronic\n3                   R&B","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Genre</th>\n    </tr>\n    <tr>\n      <th>Genre_Index</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Country</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Hip-Hop</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Electronic</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>R&amp;B</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n  print(f\"Epoch {epoch + 1}/{num_epochs}\")\n  train(model, train_dataloader, optimizer, scheduler, device)\n  accuracy, report = evaluate(model, train_dataloader, device)\n  print(f\"Train Accuracy: {accuracy:.4f}\")\n  accuracy, report = evaluate(model, val_dataloader, device)\n  print(f\"Validation Accuracy: {accuracy:.4f}\")\n  torch.save(model.state_dict(), f\"version-{epoch}-acc-{accuracy:.4f}.pth\")\n  print(report)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:06:02.221277Z","iopub.execute_input":"2024-05-06T08:06:02.221950Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/10\nTrain Accuracy: 0.7780\nValidation Accuracy: 0.6829\n              precision    recall  f1-score   support\n\n           0       0.76      0.56      0.65       710\n           1       0.85      0.80      0.83      1946\n           2       0.48      0.69      0.56       873\n           3       0.61      0.58      0.60      1432\n\n    accuracy                           0.68      4961\n   macro avg       0.68      0.66      0.66      4961\nweighted avg       0.70      0.68      0.69      4961\n\nEpoch 2/10\nTrain Accuracy: 0.9077\nValidation Accuracy: 0.7148\n              precision    recall  f1-score   support\n\n           0       0.81      0.57      0.67       710\n           1       0.88      0.81      0.84      1946\n           2       0.55      0.66      0.60       873\n           3       0.61      0.70      0.65      1432\n\n    accuracy                           0.71      4961\n   macro avg       0.71      0.68      0.69      4961\nweighted avg       0.73      0.71      0.72      4961\n\nEpoch 3/10\nTrain Accuracy: 0.9785\nValidation Accuracy: 0.7428\n              precision    recall  f1-score   support\n\n           0       0.77      0.66      0.71       710\n           1       0.86      0.83      0.85      1946\n           2       0.62      0.61      0.62       873\n           3       0.66      0.74      0.70      1432\n\n    accuracy                           0.74      4961\n   macro avg       0.73      0.71      0.72      4961\nweighted avg       0.75      0.74      0.74      4961\n\nEpoch 4/10\nTrain Accuracy: 0.9919\nValidation Accuracy: 0.7507\n              precision    recall  f1-score   support\n\n           0       0.76      0.71      0.73       710\n           1       0.83      0.87      0.85      1946\n           2       0.63      0.66      0.65       873\n           3       0.70      0.67      0.69      1432\n\n    accuracy                           0.75      4961\n   macro avg       0.73      0.73      0.73      4961\nweighted avg       0.75      0.75      0.75      4961\n\nEpoch 5/10\nTrain Accuracy: 0.9941\nValidation Accuracy: 0.7472\n              precision    recall  f1-score   support\n\n           0       0.64      0.81      0.71       710\n           1       0.85      0.85      0.85      1946\n           2       0.70      0.60      0.65       873\n           3       0.70      0.67      0.68      1432\n\n    accuracy                           0.75      4961\n   macro avg       0.72      0.73      0.72      4961\nweighted avg       0.75      0.75      0.75      4961\n\nEpoch 6/10\n","output_type":"stream"}]},{"cell_type":"code","source":"#!rm /kaggle/working/*","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:03:43.438189Z","iopub.status.idle":"2024-05-06T08:03:43.438535Z","shell.execute_reply.started":"2024-05-06T08:03:43.438367Z","shell.execute_reply":"2024-05-06T08:03:43.438382Z"},"trusted":true},"execution_count":null,"outputs":[]}]}