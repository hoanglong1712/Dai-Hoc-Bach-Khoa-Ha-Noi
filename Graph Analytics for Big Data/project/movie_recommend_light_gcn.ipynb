{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIuJJ0L5QQL7"
      },
      "source": [
        "https://github.com/pyg-team/pytorch_geometric/issues/9520"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_3UojdkPq3o",
        "outputId": "46a149ac-82f0-4323-aaf7-3ddab68d52b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Collecting pyg_lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/pyg_lib-0.4.0%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_scatter-2.1.2%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_sparse-0.6.18%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_cluster-1.6.3%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (947 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m947.1/947.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.26.4)\n",
            "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
            "Successfully installed pyg_lib-0.4.0+pt23cu121 torch_cluster-1.6.3+pt23cu121 torch_scatter-2.1.2+pt23cu121 torch_sparse-0.6.18+pt23cu121 torch_spline_conv-1.2.2+pt23cu121\n",
            "Collecting tensorly\n",
            "  Downloading tensorly-0.8.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorly) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from tensorly) (1.13.1)\n",
            "Downloading tensorly-0.8.1-py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.7/229.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorly\n",
            "Successfully installed tensorly-0.8.1\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.9)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.13.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "!pip install tensorly\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fmW2cugGTM-",
        "outputId": "10794d8b-e214-4518-a9a0-9807ffb8fec2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/libpyg.so: undefined symbol: _ZN3c1010Dispatcher17runRecordFunctionERN2at14RecordFunctionESt17reference_wrapperIKNS_14FunctionSchemaEENS_11DispatchKeyE\n",
            "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_cluster/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_spline_conv/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
          ]
        }
      ],
      "source": [
        "import collections\n",
        "import math\n",
        "import os\n",
        "import os.path as osp\n",
        "from tqdm import tqdm\n",
        "from typing import List\n",
        "import random\n",
        "import time\n",
        "import zipfile\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.options.display.max_rows = 10\n",
        "from sklearn import metrics\n",
        "from tensorly import decomposition\n",
        "\n",
        "import torch\n",
        "from torch.functional import tensordot\n",
        "from torch import nn, optim, Tensor\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Dataset, Data, download_url, extract_zip\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.typing import Adj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYW0MwN31fdW",
        "outputId": "5f412e81-11c3-4064-9836-62e3663a3468"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch has version 2.4.1+cu121\n",
            "Torch version: 2.4.1+cu121\n",
            "Cuda available: False\n",
            "Torch geometric version: 2.6.1\n"
          ]
        }
      ],
      "source": [
        "print(f\"PyTorch has version {torch.__version__}\")\n",
        "print(f\"Torch version: {torch.__version__}\")\n",
        "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
        "print(f\"Torch geometric version: {torch_geometric.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nAUZ8LY0wyI"
      },
      "outputs": [],
      "source": [
        "rating_threshold = 3\n",
        "##@param {type: \"integer\"}: Ratings equal to or greater than 3 are positive items.\n",
        "\n",
        "config_dict = {\n",
        "    \"num_samples_per_user\": 500,\n",
        "    \"num_users\": 200,\n",
        "\n",
        "    \"epochs\": 100,\n",
        "    \"batch_size\": 128,\n",
        "    \"lr\": 0.001,\n",
        "    \"weight_decay\": 0.1,\n",
        "\n",
        "    \"embedding_size\": 64,\n",
        "    \"num_layers\": 5,\n",
        "    \"K\": 10,\n",
        "    \"mf_rank\": 8,\n",
        "\n",
        "    \"minibatch_per_print\": 100,\n",
        "     \"epochs_per_print\": 1,\n",
        "\n",
        "    \"val_frac\": 0.2,\n",
        "    \"test_frac\": 0.1,\n",
        "\n",
        "    \"model_name\": \"model.pth\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ky0BvUtCQdxt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "\n",
        "Tập dữ liệu được sử dụng là MovieLens 1M.\n",
        "Tập dữ liêu này bao gồm 1 triệu đánh giá từ 1 đến 5.\n",
        "Tập có 6 nghìn người dùng và 4 nghìn bộ phim"
      ],
      "metadata": {
        "id": "I8Qke4RDQMTp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aFE4Jbg14IS"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = \"https://files.grouplens.org/datasets/movielens/ml-1m.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaZK6fwHzyd_"
      },
      "outputs": [],
      "source": [
        "def trans_ml(dat, thres):\n",
        "    \"\"\"\n",
        "    Transform function that assign non-negative entries >= thres 1, and non-\n",
        "    negative entries <= thres 0. Keep other entries the same.\n",
        "    hàm biến đổi dùng để gán những giá trị không âm >= thres là 1, còn lại là 0.\n",
        "    Những giá trị khác thì giữ nguyên.\n",
        "    INPUT:\n",
        "    dat: Data object\n",
        "    thres: threshold\n",
        "    return: Data object\n",
        "    \"\"\"\n",
        "    # lấy giá trị trần làm mốc phân biệt\n",
        "    thres = thres[0]\n",
        "    # lấy ma trận chỉ mục của cạnh\n",
        "    matrix = dat['edge_index']\n",
        "    # cập nhật ma trận\n",
        "    matrix[(matrix < thres) & (matrix > -1)] = 0\n",
        "    matrix[(matrix >= thres)] = 1\n",
        "\n",
        "    # gán lại ma trận vào từ điển\n",
        "    dat['edge_index'] = matrix\n",
        "    return dat\n",
        "\n",
        "\n",
        "class MovieLens(Dataset):\n",
        "  '''\n",
        "  MovieLens class extends Dataset class\n",
        "  '''\n",
        "  def __init__(self, root, transform=None, pre_transform=None,\n",
        "          transform_args=None, pre_transform_args=None):\n",
        "      \"\"\"\n",
        "      root = where the dataset should be stored. This folder is split\n",
        "      into raw_dir (downloaded dataset) and processed_dir (process data).\n",
        "      root: thư mục chứa dữ liệu, bao gồm 2 thư mục raw_dir và processed_dir\n",
        "\n",
        "      transform, transform_args, pre_transform, and pre_transform_args\n",
        "      are passed to the call of the super class.\n",
        "      transform, transform_args, pre_transform, và pre_transform_args\n",
        "      được truyền vào khi gọi lớp cha \"Dataset\"\n",
        "      Dataset là 1 phần của torch_geometric.data\n",
        "      https://pytorch-geometric.readthedocs.io/en/stable/generated/torch_geometric.data.Dataset.html\n",
        "\n",
        "\n",
        "      Args:\n",
        "          root (string): Root directory\n",
        "          transform (callable, optional): A function/transform that takes in\n",
        "              an Data object and returns a transformed version.\n",
        "              The data object will be transformed before every access.\n",
        "              (default: :obj:`None`)\n",
        "          pre_transform (callable, optional): A function/transform that takes\n",
        "              in an Data object and returns a transformed version. The data\n",
        "              object will be transformed before every access.\n",
        "              (default: :obj:`None`)\n",
        "\n",
        "\n",
        "      \"\"\"\n",
        "      super(MovieLens, self).__init__(root, transform, pre_transform)\n",
        "      self.transform = transform\n",
        "      self.pre_transform = pre_transform\n",
        "      self.transform_args = transform_args\n",
        "      self.pre_transform_args = pre_transform_args\n",
        "\n",
        "  @property\n",
        "  def raw_file_names(self):\n",
        "      return \"ml-1m.zip\"\n",
        "\n",
        "  @property\n",
        "  def processed_file_names(self):\n",
        "      return [\"data_movielens.pt\"]\n",
        "\n",
        "  def download(self):\n",
        "      # Download to `self.raw_dir`.\n",
        "      # dowload_url là 1 phần của torch_geometric.data\n",
        "      download_url(DATA_PATH, self.raw_dir)\n",
        "\n",
        "  def _load(self):\n",
        "      print(self.raw_dir)\n",
        "      # extract_zip(self.raw_paths[0], self.raw_dir)\n",
        "      with zipfile.ZipFile(self.raw_paths[0], 'r') as zip_ref:\n",
        "          zip_ref.extractall(self.raw_dir)\n",
        "\n",
        "      unames = ['user_id', 'gender', 'age', 'occupation', 'zip']\n",
        "      users = pd.read_table(self.raw_dir+'/ml-1m/users.dat',\n",
        "                            sep='::', header=None, names=unames,\n",
        "                            engine='python', encoding='latin-1')\n",
        "      rnames = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
        "      ratings = pd.read_table(self.raw_dir+'/ml-1m/ratings.dat', sep='::',\n",
        "                              header=None, names=rnames, engine='python',\n",
        "                              encoding='latin-1')\n",
        "      mnames = ['movie_id', 'title', 'genres']\n",
        "      movies = pd.read_table(self.raw_dir+'/ml-1m/movies.dat', sep='::',\n",
        "                              header=None, names=mnames, engine='python',\n",
        "                              encoding='latin-1')\n",
        "      # tạo ma trận\n",
        "      dat = pd.merge(pd.merge(ratings, users), movies)\n",
        "\n",
        "      return users, ratings, movies, dat\n",
        "\n",
        "  def process(self):\n",
        "      print('run process')\n",
        "      # load information from file\n",
        "      users, ratings, movies, dat = self._load()\n",
        "\n",
        "      users = users['user_id']\n",
        "      movies = movies['movie_id']\n",
        "\n",
        "      num_users = config_dict[\"num_users\"]\n",
        "      # lọc bớt các đỉnh người dùng nếu cần thiết\n",
        "      if num_users != -1:\n",
        "          users = users[:num_users]\n",
        "\n",
        "      user_ids = range(len(users))\n",
        "      movie_ids = range(len(movies))\n",
        "\n",
        "      user_to_id = dict(zip(users, user_ids))\n",
        "      movie_to_id = dict(zip(movies, movie_ids))\n",
        "\n",
        "      # get adjacency info\n",
        "      # lấy số đỉnh người dùng và số đỉnh sản phẩm\n",
        "      self.num_user = users.shape[0]\n",
        "      self.num_item = movies.shape[0]\n",
        "\n",
        "      # initialize the adjacency matrix\n",
        "      # khởi tạo ma trận kề với hàng là người dùng, cột là sản phẩm bộ phim\n",
        "      rat = torch.zeros(self.num_user, self.num_item)\n",
        "\n",
        "      # với mỗi dòng\n",
        "      for index, row in ratings.iterrows():\n",
        "          user, movie, rating = row[:3]\n",
        "          if num_users != -1:\n",
        "            # bỏ qua nếu người dùng đang được xét không có trong danh sách\n",
        "            # đang được quan tâm hoặc đây là 1 đoạn dữ liệu bị lỗi\n",
        "            if user not in user_to_id: break\n",
        "          # create ratings matrix where (i, j) entry represents the ratings\n",
        "          # of movie j given by user i.\n",
        "          # điền tỉ lệ đánh giá vào ma trận kề\n",
        "          rat[user_to_id[user], movie_to_id[movie]] = rating\n",
        "\n",
        "      # create Data object\n",
        "      data = Data(edge_index = rat,\n",
        "                  raw_edge_index = rat.clone(),\n",
        "                  data = ratings,\n",
        "                  users = users,\n",
        "                  items = movies)\n",
        "\n",
        "      # apply any pre-transformation\n",
        "      if self.pre_transform is not None:\n",
        "          data = self.pre_transform(data, self.pre_transform_args)\n",
        "\n",
        "      # apply any post_transformation\n",
        "      # if self.transform is not None:\n",
        "      #     # data = self.transform(data, self.transform_args)\n",
        "      # cụ thể ở đây đang gọi hàm trans_ml được định nghĩa ở mục trên cùng\n",
        "      data = self.transform(data, [rating_threshold])\n",
        "\n",
        "      # save the processed data into .pt file\n",
        "      torch.save(data, osp.join(self.processed_dir, f'data_movielens.pt'))\n",
        "      print('process finished')\n",
        "\n",
        "\n",
        "  def get(self):\n",
        "      \"\"\"\n",
        "      The logic to load a single graph\n",
        "      \"\"\"\n",
        "      data = torch.load(osp.join(self.processed_dir, 'data_movielens.pt'))\n",
        "      return data\n",
        "\n",
        "  def train_val_test_split(self, val_frac=0.2, test_frac=0.1):\n",
        "      \"\"\"\n",
        "      Return two mask matrices (M, N) that represents edges present in the\n",
        "      train and validation set\n",
        "      Trả về 2 mặt nạ đánh dấu những cạnh có trong tập huấn luyện và tập\n",
        "      kiếm tra\n",
        "      những cạnh đó sẽ được lựa chọn ngẫu nhiên trong tập dữ liệu\n",
        "\n",
        "      \"\"\"\n",
        "      try:\n",
        "          self.num_user, self.num_item\n",
        "      except AttributeError:\n",
        "          data = self.get()\n",
        "          self.num_user = len(data[\"users\"].unique())\n",
        "          self.num_item = len(data[\"items\"].unique())\n",
        "      # get number of edges masked for training and validation\n",
        "      num_train_replaced = \\\n",
        "          round((test_frac+val_frac)*self.num_user*self.num_item)\n",
        "      num_val_show = round(val_frac*self.num_user*self.num_item)\n",
        "\n",
        "      # edges masked during training\n",
        "      indices_user = np.random.randint(0, self.num_user, num_train_replaced)\n",
        "      indices_item = np.random.randint(0, self.num_item, num_train_replaced)\n",
        "\n",
        "      # sample part of edges from training stage to be unmasked during\n",
        "      # validation\n",
        "      indices_val_user = np.random.choice(indices_user, num_val_show)\n",
        "      indices_val_item = np.random.choice(indices_item, num_val_show)\n",
        "\n",
        "      train_mask = torch.ones(self.num_user, self.num_item)\n",
        "      train_mask[indices_user, indices_item] = 0\n",
        "\n",
        "      val_mask = train_mask.clone()\n",
        "      val_mask[indices_val_user, indices_val_item] = 1\n",
        "\n",
        "      test_mask = torch.ones_like(train_mask)\n",
        "\n",
        "      return train_mask, val_mask, test_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cài đặt LightGCN\n",
        "\n",
        "## Tầng tính toán lân cận theo LightGCN\n",
        "\n",
        "Bắt đầu với tầng khởi tạo $E^0$ và đồ thị phân đôi, chúng ta\n",
        "duyệt qua các đỉnh và tiến hành thu thập thông tin từ các lân cận của mỗi đỉnh.\n",
        "Chúng ta cần lưu ý rằng LightGCN **sử dụng phép cộng trọng số thay cho việc sử dụng phép biến đổi đặc trưng, và hàm kích hoạt tuyến tính**.\n",
        "\n",
        "Tại mỗi tầng xử lý, từ mỗi đỉnh thuộc nhóm người dùng, chúng ta tính toán giá\n",
        " trị mới của vectơ nhúng thông qua sử dụng các\n",
        " giá trị từ các vectơ lận cận với nó \"cụ thể là các vectơ nhúng đại diện cho các bộ phim\n",
        "  mà người dùng này đã từng tương tác \"\n",
        "\n",
        "  $$e_i^{(k+1)} = \\sum_{i \\in N_u} \\frac{1}{\\sqrt{|N_u|} \\sqrt{|N_i|}} \\textbf{e}_i^{(k)}$$\n",
        "\n",
        "  tại đó $e_u^{(k)}$ và $e_i^{(k)}$ là các véc tơ nhúng đại diện cho các đỉnh người dùng và đỉnh bộ phim tại tần thứ k.\n",
        "  $ |N_u| $ và $ |N_i|$ là số lượng tương ứng các đỉnh đại diện cho người dùng và bộ phim trên phần đồ thị đang được xét,\n",
        "  ở đây có thể là toàn bộ đồ thị hoặc các đỉnh trong cụm đỉnh đạng được xét trong batch xử lý  \n",
        "\n",
        "  Tương tự như vậy, với mỗi đỉnh thuộc nhóm bộ phim, giá trị véc tơ nhúng được cập nhật thông qua\n",
        "  giá trị của các véc tơ nhúng của người dùng lân cận với nó\n",
        "  $$ \\textbf{e}_i^{(k+1)} = \\sum_{i \\in N_i} \\frac{1}{\\sqrt{|N_i|} \\sqrt{|N_u|}} \\textbf{e}_u^{(k)} $$\n"
      ],
      "metadata": {
        "id": "dvXp76_veLSX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLlXODVwzkJ9"
      },
      "outputs": [],
      "source": [
        "class LightGCNConv(MessagePassing):\n",
        "    r\"\"\"The neighbor aggregation operator from the `\"LightGCN: Simplifying and\n",
        "    Powering Graph Convolution Network for Recommendation\"\n",
        "    <https://arxiv.org/abs/2002.02126#>`_ paper\n",
        "    phái sinh từ lớp MessagePassing\n",
        "    https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.MessagePassing.html\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): Size of each input sample, or :obj:`-1` to derive\n",
        "            the size from the first input(s) to the forward method.\n",
        "        out_channels (int): Size of each output sample.\n",
        "        num_users (int): Number of users for recommendation.\n",
        "        num_items (int): Number of items to recommend.\n",
        "        **kwargs (optional): Additional arguments of\n",
        "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels: int, out_channels: int,\n",
        "                 num_users: int, num_items: int, **kwargs):\n",
        "        super(LightGCNConv, self).__init__(**kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        pass  # There are no layer parameters to learn.\n",
        "\n",
        "    def forward(self, x: Tensor, edge_index: Adj) -> Tensor:\n",
        "        \"\"\"Performs neighborhood aggregation for user/item embeddings.\"\"\"\n",
        "        # thiết lập ma trận kề\n",
        "        user_item = \\\n",
        "                torch.zeros(self.num_users, self.num_items, device=x.device)\n",
        "\n",
        "        # nếu điểm nào đại diện cho kết nối giữa người dùng và\n",
        "        # sản phẩm thì đặt nó là 1\n",
        "        user_item[edge_index[:, 0], edge_index[:, 1]] = 1\n",
        "\n",
        "        # đếm tổng số lân cận của người dùng\n",
        "        user_neighbor_counts = torch.sum(user_item, axis=1)\n",
        "        # đếm tổng số lân cận của sản phẩm\n",
        "        item_neightbor_counts = torch.sum(user_item, axis=0)\n",
        "\n",
        "        # Compute weight for aggregation: 1 / sqrt(N_u * N_i)\n",
        "        weights = user_item / torch.sqrt(\n",
        "                user_neighbor_counts.repeat(self.num_items, 1).T \\\n",
        "                * item_neightbor_counts.repeat(self.num_users, 1))\n",
        "\n",
        "        # chuẩn hóa trọng số. biến nan thành 0\n",
        "        weights = torch.nan_to_num(weights, nan=0)\n",
        "\n",
        "        # inner product\n",
        "        out = torch.concat((weights.T @ x[:self.num_users],\n",
        "                            weights @ x[self.num_users:]), 0)\n",
        "        return out\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels,\n",
        "                                   self.out_channels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mô hình LightGCN\n",
        "\n",
        "Tại bước cuối, chúng ta kết hợp các tầng với nhau,\n",
        "thông thường thì các mô hình khác lấy véc tơ trọng số của tầng cuối cùng, song LightGCN sẽ lấy. **tổng các véc tơ trọng số của các tầng**.   \n",
        "$$ \\textbf{e}_u = \\sum_{k=0}^K \\alpha_k \\textbf{e}_u^{(k)} $$\n",
        "$$ \\textbf{e}_i = \\sum_{k=0}^K \\alpha_k \\textbf{e}_i^{(k)} $$\n",
        "\n",
        "với giá trị $\\alpha > 0$. Tại đây, alpha có thể là 1 biến thay đổi được trong quá trình huấn luyện hoặc được thiết lập sẵn từ trước. Thực nghiệm cho thấy giá trị $ \\alpha = \\frac{1}{K + 1} $  phù hợp cho đa số trường hợp sử dụng.\n",
        "\n",
        "Các dự báo của LightGCN dựa trên phép tính tích bên trong của 2 vectơ nhúng đại diện cho 1 người dùng và 1 bộ phim.\n",
        "$$\\hat{y}_{ui} = \\textbf{e}_u^T \\textbf{e}_i $$\n",
        "\n",
        "Tích này đó lường độ tương tự giữa người dùng và bộ phim, từ đó cho phép chúng ta nắm được xác suất người dùng có thể tương tác với bộ phim\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X6dev05NoFpI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wz80KhdizkOz"
      },
      "outputs": [],
      "source": [
        "# for inter-layer combination\n",
        "class LightGCN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 config: dict,\n",
        "                 device=None,\n",
        "                 **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_users  = config[\"n_users\"]\n",
        "        self.num_items  = config[\"m_items\"]\n",
        "        self.embedding_size = config[\"embedding_size\"]\n",
        "        self.in_channels = self.embedding_size\n",
        "        self.out_channels = self.embedding_size\n",
        "        self.num_layers = config[\"num_layers\"]\n",
        "\n",
        "        # 0-th layer embedding.\n",
        "        self.embedding_user_item = torch.nn.Embedding(\n",
        "            num_embeddings=self.num_users + self.num_items,\n",
        "            embedding_dim=self.embedding_size)\n",
        "        self.alpha = None\n",
        "\n",
        "        # random normal init seems to be a better choice when lightGCN actually\n",
        "        # don't use any non-linear activation function\n",
        "        nn.init.normal_(self.embedding_user_item.weight, std=0.1)\n",
        "        print('use NORMAL distribution initilizer')\n",
        "\n",
        "        self.f = nn.Sigmoid()\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.convs.append(LightGCNConv(\n",
        "                self.embedding_size, self.embedding_size,\n",
        "                num_users=self.num_users, num_items=self.num_items, **kwargs))\n",
        "\n",
        "        # các tầng còn lại\n",
        "        # mỗi tầng là 1 hop trong việc tính các lân cận\n",
        "        for _ in range(1, self.num_layers):\n",
        "            self.convs.append(\n",
        "                LightGCNConv(\n",
        "                        self.embedding_size, self.embedding_size,\n",
        "                        num_users=self.num_users, num_items=self.num_items,\n",
        "                        **kwargs))\n",
        "\n",
        "        self.device = None\n",
        "        if device is not None:\n",
        "            self.convs.to(device)\n",
        "            self.device = device\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "    def forward(self, x: Tensor, edge_index: Adj, *args, **kwargs) -> Tensor:\n",
        "        xs: List[Tensor] = []\n",
        "\n",
        "        #\n",
        "        edge_index = torch.nonzero(edge_index)\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.convs[i](x, edge_index, *args, **kwargs)\n",
        "            if self.device is not None:\n",
        "                x = x.to(self.device)\n",
        "            xs.append(x)\n",
        "\n",
        "        # stack all result\n",
        "        xs = torch.stack(xs)\n",
        "\n",
        "        # tính giá trị alpha, alpha là 1 vec-tơ\n",
        "        self.alpha = 1 / (1 + self.num_layers) * torch.ones(xs.shape)\n",
        "        if self.device is not None:\n",
        "            self.alpha = self.alpha.to(self.device)\n",
        "            xs = xs.to(self.device)\n",
        "\n",
        "        # tính tổng cuối cùng\n",
        "        x = (xs * self.alpha).sum(dim=0)  # Sum along K layers.\n",
        "        return x\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
        "                f'{self.out_channels}, num_layers={self.num_layers})')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hàm bổ trợ\n",
        "các hàm hỗ trợ lấy giá trị nhúng và tính toán độ tương tự giữa người dùng và bộ phim"
      ],
      "metadata": {
        "id": "WhavHfcerd0v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqIwnDdNRRhf"
      },
      "outputs": [],
      "source": [
        "def getUsersRating(model, users, data):\n",
        "    \"\"\" Get the embedding of users\n",
        "    lấy độ tương tự giữa người dùng và bộ phim\n",
        "    INPUT:\n",
        "        model: the LightGCN model you are training on\n",
        "        users: this is the user index (note: use 0-indexed and not user number,\n",
        "            which is 1-indexed)\n",
        "        data: the entire data, used to fetch all users and all items\n",
        "    \"\"\"\n",
        "    all_users_items = model(model.embedding_user_item.weight.clone(),\n",
        "                            data[\"edge_index\"])\n",
        "    all_users = all_users_items[:len(data[\"users\"])]\n",
        "    items_emb = all_users_items[len(data[\"users\"]):]\n",
        "    users_emb = all_users[users.long()]\n",
        "    # LightGCN sử dụng phép toán nhân đơn giản\n",
        "    rating = model.f(torch.matmul(users_emb, items_emb.t()))\n",
        "    return rating\n",
        "\n",
        "def getEmbedding(model, users, pos, neg, data, mask):\n",
        "    \"\"\"\n",
        "    lấy những giá trị nhúng tương ứng từ tầng tính toán trước đó\n",
        "    để huấn luyện mô hình LightGCN\n",
        "    INPUT:\n",
        "        model: the LightGCN model you are training on\n",
        "        users: this is the user index (note: use 0-indexed and not user number,\n",
        "            which is 1-indexed)\n",
        "        pos: positive index corresponding to an item that the user like\n",
        "        neg: negative index corresponding to an item that the user doesn't like\n",
        "        data: the entire data, used to fetch all users and all items\n",
        "        mask: Masking matrix indicating edges present in the current\n",
        "            train / validation / test set.\n",
        "    \"\"\"\n",
        "    # assuming we always search for users and items by their indices (instead of\n",
        "    # user/item number)\n",
        "\n",
        "    all_users_items = model(model.embedding_user_item.weight.clone(),\n",
        "                            data[\"edge_index\"] * mask)\n",
        "    all_users = all_users_items[:len(data[\"users\"])]\n",
        "    all_items = all_users_items[len(data[\"users\"]):]\n",
        "    users_emb = all_users[users]\n",
        "    pos_emb = all_items[pos]\n",
        "    neg_emb = all_items[neg]\n",
        "    n_user = len(data[\"users\"])\n",
        "    users_emb_ego = model.embedding_user_item(users)\n",
        "    # offset the index to fetch embedding from user_item\n",
        "    pos_emb_ego = model.embedding_user_item(pos + n_user)\n",
        "    neg_emb_ego = model.embedding_user_item(neg + n_user)\n",
        "    return users_emb, pos_emb, neg_emb, users_emb_ego, pos_emb_ego, neg_emb_ego"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bayesian Personalized Ranking loss (BPR loss)\n",
        "\n",
        "Nhằm huấn luyện mô hìn LightGCN, chúng ta cần một hàm số đáp ứng bài toán đề xuất bộ phim phù hợp. Chúng ta sử dụng Bayesian Personalized Ranking loss (BPR loss), hàm mất mát này đáp ứng yêu cầu của bài toán dự báo cạnh kết nối giữa người dùng và bộ phim, nếu có kết nối thì giá trị trả về sẽ cao hơn khi không có kết nối, chúng ta áp dụng chuẩn Euclider hay còn gọi là $L_2$\n",
        "$$L_{BPR} = - \\sum_{u=1}^M \\sum_{i \\in N_u} \\sum_{j \\notin N_u} \\ln \\sigma(\\hat{y}_{ui} - \\hat{y}_{uj}) + \\lambda ||\\textbf{E}^{(0)} ||^2$$\n",
        "với $E^{(0)}$ là ma trận với các véc tơ cột là giá trị nhúng của tầng 0, \"vec tơ đặc trưng của mỗi đỉnh:"
      ],
      "metadata": {
        "id": "G8JqCUr6ryls"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZ62Sk46_uxB"
      },
      "outputs": [],
      "source": [
        "def bpr_loss(model, users, pos, neg, data, mask):\n",
        "    \"\"\"\n",
        "    INPUT:\n",
        "        model: the LightGCN model you are training on\n",
        "        users: this is the user index (note: use 0-indexed and not user number,\n",
        "            which is 1-indexed)\n",
        "        pos: positive index corresponding to an item that the user like\n",
        "            (0-indexed, note to index items starting from 0)\n",
        "        neg: negative index corresponding to an item that the user doesn't like\n",
        "        data: the entire data, used to fetch all users and all items\n",
        "        mask: Masking matrix indicating edges present in the current\n",
        "            train / validation / test set.\n",
        "    OUTPUT:\n",
        "        loss, reg_loss\n",
        "    \"\"\"\n",
        "    # assuming we always sample the same number of positive and negative sample\n",
        "    # per user\n",
        "    # đảm bảo rằng tập huấn luyện cân bằng\n",
        "    assert len(users) == len(pos) and len(users) == len(neg)\n",
        "    (users_emb, pos_emb, neg_emb,\n",
        "    userEmb0,  posEmb0, negEmb0) = getEmbedding(model, users.long(), pos.long(),\n",
        "                                                neg.long(), data, mask)\n",
        "\n",
        "    reg_loss = (1/2)*(userEmb0.norm(2).pow(2) +\n",
        "                        posEmb0.norm(2).pow(2)  +\n",
        "                        negEmb0.norm(2).pow(2))/float(len(users))\n",
        "\n",
        "    pos_scores = torch.mul(users_emb, pos_emb)\n",
        "    pos_scores = torch.sum(pos_scores, dim=1)\n",
        "    neg_scores = torch.mul(users_emb, neg_emb)\n",
        "    neg_scores = torch.sum(neg_scores, dim=1)\n",
        "\n",
        "    # https://pytorch.org/docs/stable/generated/torch.nn.functional.softplus.html\n",
        "\n",
        "    loss = torch.mean(torch.nn.functional.softplus(neg_scores - pos_scores))\n",
        "\n",
        "    return loss, reg_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjHb_Cr0_0gC"
      },
      "outputs": [],
      "source": [
        "def personalized_topk(pred, K, user_indices, edge_index):\n",
        "    \"\"\"Computes TopK precision and recall.\n",
        "\n",
        "    Args:\n",
        "        pred: Predicted similarities between user and item.\n",
        "        K: Number of items to rank.\n",
        "        user_indices: Indices of users for each prediction in `pred`.\n",
        "        edge_index: User and item connection matrix.\n",
        "\n",
        "    Returns:\n",
        "        Average Top K precision and recall for users in `user_indices`.\n",
        "    \"\"\"\n",
        "    per_user_preds = collections.defaultdict(list)\n",
        "    for index, user in enumerate(user_indices):\n",
        "        per_user_preds[user.item()].append(pred[index].item())\n",
        "    precisions = 0.0\n",
        "    recalls = 0.0\n",
        "    for user, preds in per_user_preds.items():\n",
        "        while len(preds) < K:\n",
        "            preds.append(random.choice(range(edge_index.shape[1])))\n",
        "        top_ratings, top_items = torch.topk(torch.tensor(preds), K)\n",
        "        # lấy số dự đoán đúng\n",
        "        correct_preds = edge_index[user, top_items].sum().item()\n",
        "        # tống số dự đoán gốc\n",
        "        total_pos = edge_index[user].sum().item()\n",
        "        # bổ sung vào giá trị precision\n",
        "        precisions += correct_preds / K\n",
        "\n",
        "        recalls += correct_preds / total_pos if total_pos != 0 else 0\n",
        "    num_users = len(user_indices.unique())\n",
        "    return precisions / num_users, recalls / num_users"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lấy mẫu\n",
        "\n",
        "với mỗi người dùng, chúng ta chọn ngẫu nhiên n mẫu bộ phim bao gồm cả mẫu có tương tác và mẫu không tương tác với người dùng sau đó cho vào danh sách huấn luyện, xác thực hoặc kiểm tra, thông số n sẽ được tinh chỉnh thủ công\n"
      ],
      "metadata": {
        "id": "Ej_qZ3qxeUHx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmAgY88nzzGm"
      },
      "outputs": [],
      "source": [
        "def _sample_pos_neg(data, mask, num_samples_per_user):\n",
        "    \"\"\"Samples (user, positive item, negative item) tuples per user.\n",
        "\n",
        "    If a user does not have a postive (negative) item, we choose an item\n",
        "    with unknown liking (an item without raw rating data).\n",
        "\n",
        "    Args:\n",
        "        data: Dataset object containing edge_index and raw ratings matrix.\n",
        "        mask: Masking matrix indicating edges present in the current\n",
        "            train / validation / test set.\n",
        "        num_samples_per_user: Number of samples to generate for each user.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor object of (user, positive item, negative item) samples.\n",
        "    \"\"\"\n",
        "    print(\"=====Starting to sample=====\")\n",
        "    start = time.time()\n",
        "    samples = []\n",
        "    all_items = set(range(len(data[\"items\"])))\n",
        "    for user_index, user in enumerate(data[\"users\"]):\n",
        "        pos_items = set(\n",
        "            torch.nonzero(data[\"edge_index\"][user_index])[:, 0].tolist())\n",
        "        unknown_items = all_items.difference(\n",
        "                set(\n",
        "                    torch.nonzero(\n",
        "                        data[\"raw_edge_index\"][user_index])[:, 0].tolist()))\n",
        "        neg_items = all_items.difference(\n",
        "            set(pos_items)).difference(set(unknown_items))\n",
        "        unmasked_items = set(torch.nonzero(mask[user_index])[:, 0].tolist())\n",
        "        if len(unknown_items.union(pos_items)) == 0 or \\\n",
        "                len(unknown_items.union(neg_items)) == 0:\n",
        "            continue\n",
        "        for _ in range(num_samples_per_user):\n",
        "            if len(pos_items.intersection(unmasked_items)) == 0:\n",
        "                pos_item_index = random.choice(\n",
        "                    list(unknown_items.intersection(unmasked_items)))\n",
        "            else:\n",
        "                pos_item_index = random.choice(\n",
        "                    list(pos_items.intersection(unmasked_items)))\n",
        "            if len(neg_items.intersection(unmasked_items)) == 0:\n",
        "                neg_item_index = random.choice(\n",
        "                    list(unknown_items.intersection(unmasked_items)))\n",
        "            else:\n",
        "                neg_item_index = random.choice(\n",
        "                    list(neg_items.intersection(unmasked_items)))\n",
        "            samples.append((user_index, pos_item_index, neg_item_index))\n",
        "    end = time.time()\n",
        "    print(f\"=====Sampling completed (took {end - start} seconds)=====\")\n",
        "    return torch.tensor(samples, dtype=torch.int32)\n",
        "\n",
        "def sample_pos_neg(data, train_mask, val_mask, test_mask, num_samples_per_user):\n",
        "    \"\"\"Samples (user, positive item, negative item) tuples per user.\n",
        "\n",
        "    If a user does not have a postive (negative) item, we choose an item\n",
        "    with unknown liking (an item without raw rating data).\n",
        "\n",
        "    Args:\n",
        "        data: Dataset object containing edge_index and raw ratings matrix.\n",
        "        train_mask: Masking matrix indicating edges present in train set.\n",
        "        val_mask: Masking matrix indicating edges present in validation set.\n",
        "        test_mask: Masking matrix indicating edges present in test set.\n",
        "        num_samples_per_user: Number of samples to generate for each user.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor object of (user, positive item, negative item) samples for\n",
        "        train, validation and test.\n",
        "    \"\"\"\n",
        "    train_samples = _sample_pos_neg(data, train_mask, num_samples_per_user)\n",
        "    val_samples = _sample_pos_neg(data, val_mask, num_samples_per_user)\n",
        "    test_samples = _sample_pos_neg(data, test_mask, num_samples_per_user)\n",
        "    return train_samples, val_samples, test_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Huấn luyện và đánh giá kết quả"
      ],
      "metadata": {
        "id": "cYFU9MLqjdVW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-NbgY1GzkR7",
        "outputId": "bff666cb-d777-460b-b9fd-c0b7c44d94de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run process\n",
            "/content/raw\n",
            "process finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Done!\n",
            "<ipython-input-6-068253b50276>:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(osp.join(self.processed_dir, 'data_movielens.pt'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Users: 200\n",
            "#Items: 3883\n",
            "use NORMAL distribution initilizer\n",
            "=====Starting to sample=====\n",
            "=====Sampling completed (took 5.763131141662598 seconds)=====\n",
            "=====Starting to sample=====\n",
            "=====Sampling completed (took 2.8261168003082275 seconds)=====\n",
            "=====Starting to sample=====\n",
            "=====Sampling completed (took 3.9228827953338623 seconds)=====\n",
            "#Training samples: 100000 #Validation samples: 100000 #Test samples: 100000\n",
            "Optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "Training on the 0 epoch\n",
            "Training on epoch 0 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.790049, and regularization loss is 0.096902.\n",
            " Top K precision = 0.09450549450549449, recall = 0.007693243285111315.\n",
            "Training on epoch 0 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.738869, and regularization loss is 0.045721.\n",
            " Top K precision = 0.08834951456310675, recall = 0.006766567229579858.\n",
            "Training on epoch 0 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.715943, and regularization loss is 0.022796.\n",
            " Top K precision = 0.09565217391304345, recall = 0.008392265003510351.\n",
            "Training on epoch 0 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.7078, and regularization loss is 0.014653.\n",
            " Top K precision = 0.06224489795918367, recall = 0.006904268118080957.\n",
            "Training on epoch 0 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.70186, and regularization loss is 0.008712.\n",
            " Top K precision = 0.08901098901098899, recall = 0.006356679968211437.\n",
            "Training on epoch 0 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.698631, and regularization loss is 0.005484.\n",
            " Top K precision = 0.07096774193548386, recall = 0.004708986627968142.\n",
            "Training on epoch 0 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.696965, and regularization loss is 0.003817.\n",
            " Top K precision = 0.08811881188118806, recall = 0.007271722805655244.\n",
            "Training on epoch 0 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.696655, and regularization loss is 0.003508.\n",
            " Top K precision = 0.09444444444444443, recall = 0.006907845017032662.\n",
            "\n",
            "Training on 0 epoch completed.\n",
            " Average bpr_loss on train set is 0.005567 for the current epoch.\n",
            " Training top K precision = 0.06749999999999995, recall = 0.006068394943355482.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.044999999999999984, recall = 0.00429279496478448.\n",
            "\n",
            "Training on the 1 epoch\n",
            "Training on epoch 1 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.695492, and regularization loss is 0.002345.\n",
            " Top K precision = 0.0917525773195876, recall = 0.008152532816711345.\n",
            "Training on epoch 1 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.695264, and regularization loss is 0.002117.\n",
            " Top K precision = 0.09599999999999995, recall = 0.0064498775726348915.\n",
            "Training on epoch 1 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.694508, and regularization loss is 0.001361.\n",
            " Top K precision = 0.08804347826086953, recall = 0.008074790197269192.\n",
            "Training on epoch 1 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.694518, and regularization loss is 0.00137.\n",
            " Top K precision = 0.08260869565217388, recall = 0.007598569079314961.\n",
            "Training on epoch 1 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.694118, and regularization loss is 0.000971.\n",
            " Top K precision = 0.09247311827956985, recall = 0.007837149498615513.\n",
            "Training on epoch 1 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693829, and regularization loss is 0.000682.\n",
            " Top K precision = 0.09893617021276595, recall = 0.008207687793990465.\n",
            "Training on epoch 1 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693877, and regularization loss is 0.000729.\n",
            " Top K precision = 0.08404255319148933, recall = 0.005613586516082919.\n",
            "Training on epoch 1 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693854, and regularization loss is 0.000707.\n",
            " Top K precision = 0.09999999999999994, recall = 0.008717651112497083.\n",
            "\n",
            "Training on 1 epoch completed.\n",
            " Average bpr_loss on train set is 0.00543 for the current epoch.\n",
            " Training top K precision = 0.08699999999999992, recall = 0.007522275777109813.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 2 epoch\n",
            "Training on epoch 2 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693529, and regularization loss is 0.000382.\n",
            " Top K precision = 0.09999999999999998, recall = 0.008218159271885104.\n",
            "Training on epoch 2 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693259, and regularization loss is 0.000111.\n",
            " Top K precision = 0.10312499999999995, recall = 0.0067034621271225186.\n",
            "Training on epoch 2 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693494, and regularization loss is 0.000347.\n",
            " Top K precision = 0.08686868686868685, recall = 0.007735835280424402.\n",
            "Training on epoch 2 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693468, and regularization loss is 0.00032.\n",
            " Top K precision = 0.09801980198019795, recall = 0.009452183492352967.\n",
            "Training on epoch 2 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.69371, and regularization loss is 0.000563.\n",
            " Top K precision = 0.10116279069767439, recall = 0.00816574580366682.\n",
            "Training on epoch 2 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693413, and regularization loss is 0.000265.\n",
            " Top K precision = 0.08899999999999997, recall = 0.007230325254323873.\n",
            "Training on epoch 2 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693424, and regularization loss is 0.000276.\n",
            " Top K precision = 0.083695652173913, recall = 0.007362742222068283.\n",
            "Training on epoch 2 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693273, and regularization loss is 0.000125.\n",
            " Top K precision = 0.09902912621359221, recall = 0.0071951105312072884.\n",
            "\n",
            "Training on 2 epoch completed.\n",
            " Average bpr_loss on train set is 0.005423 for the current epoch.\n",
            " Training top K precision = 0.08799999999999991, recall = 0.007430566999269649.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 3 epoch\n",
            "Training on epoch 3 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693243, and regularization loss is 9.6e-05.\n",
            " Top K precision = 0.09381443298969067, recall = 0.009014341933747916.\n",
            "Training on epoch 3 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693277, and regularization loss is 0.00013.\n",
            " Top K precision = 0.08163265306122448, recall = 0.0067206727654516305.\n",
            "Training on epoch 3 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693598, and regularization loss is 0.000451.\n",
            " Top K precision = 0.06888888888888887, recall = 0.007234985515183271.\n",
            "Training on epoch 3 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693313, and regularization loss is 0.000165.\n",
            " Top K precision = 0.09354838709677414, recall = 0.0072100719021609425.\n",
            "Training on epoch 3 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.69329, and regularization loss is 0.000143.\n",
            " Top K precision = 0.078021978021978, recall = 0.006555103115824974.\n",
            "Training on epoch 3 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693381, and regularization loss is 0.000234.\n",
            " Top K precision = 0.08279569892473115, recall = 0.008800393541440582.\n",
            "Training on epoch 3 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.69334, and regularization loss is 0.000193.\n",
            " Top K precision = 0.09473684210526313, recall = 0.007444094815242974.\n",
            "Training on epoch 3 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693177, and regularization loss is 2.9e-05.\n",
            " Top K precision = 0.09387755102040812, recall = 0.0068423984430975825.\n",
            "\n",
            "Training on 3 epoch completed.\n",
            " Average bpr_loss on train set is 0.005422 for the current epoch.\n",
            " Training top K precision = 0.08899999999999991, recall = 0.007558772127474773.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 4 epoch\n",
            "Training on epoch 4 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693283, and regularization loss is 0.000136.\n",
            " Top K precision = 0.09893617021276593, recall = 0.00858318750218052.\n",
            "Training on epoch 4 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.6932, and regularization loss is 5.3e-05.\n",
            " Top K precision = 0.09090909090909087, recall = 0.008023536123592655.\n",
            "Training on epoch 4 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693243, and regularization loss is 9.6e-05.\n",
            " Top K precision = 0.08541666666666665, recall = 0.007630382521042498.\n",
            "Training on epoch 4 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693415, and regularization loss is 0.000267.\n",
            " Top K precision = 0.08350515463917524, recall = 0.0067717143990290085.\n",
            "Training on epoch 4 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693279, and regularization loss is 0.000132.\n",
            " Top K precision = 0.07684210526315788, recall = 0.007022022927619968.\n",
            "Training on epoch 4 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693217, and regularization loss is 7e-05.\n",
            " Top K precision = 0.08651685393258424, recall = 0.009168134649053042.\n",
            "Training on epoch 4 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.08695652173913042, recall = 0.008042504954942348.\n",
            "Training on epoch 4 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693242, and regularization loss is 9.5e-05.\n",
            " Top K precision = 0.08387096774193549, recall = 0.00659422503626366.\n",
            "\n",
            "Training on 4 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.0889999999999999, recall = 0.007558772127474776.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 5 epoch\n",
            "Training on epoch 5 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693196, and regularization loss is 4.9e-05.\n",
            " Top K precision = 0.09374999999999993, recall = 0.006854341533267816.\n",
            "Training on epoch 5 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.69318, and regularization loss is 3.3e-05.\n",
            " Top K precision = 0.0894736842105263, recall = 0.004996218042420373.\n",
            "Training on epoch 5 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693216, and regularization loss is 6.8e-05.\n",
            " Top K precision = 0.08854166666666663, recall = 0.0076935623788972765.\n",
            "Training on epoch 5 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693214, and regularization loss is 6.6e-05.\n",
            " Top K precision = 0.07979797979797978, recall = 0.0062510947894426.\n",
            "Training on epoch 5 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 8e-06.\n",
            " Top K precision = 0.09157894736842097, recall = 0.006744149560293146.\n",
            "Training on epoch 5 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.07826086956521738, recall = 0.006822077815521858.\n",
            "Training on epoch 5 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693192, and regularization loss is 4.5e-05.\n",
            " Top K precision = 0.0917525773195876, recall = 0.006883473341506839.\n",
            "Training on epoch 5 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693152, and regularization loss is 5e-06.\n",
            " Top K precision = 0.09888888888888886, recall = 0.007754977631681984.\n",
            "\n",
            "Training on 5 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08900000000000001, recall = 0.007558772127474776.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 6 epoch\n",
            "Training on epoch 6 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09888888888888887, recall = 0.007013729750149548.\n",
            "Training on epoch 6 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08645833333333332, recall = 0.007392652623478428.\n",
            "Training on epoch 6 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.06703296703296703, recall = 0.006118313100580657.\n",
            "Training on epoch 6 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.0934065934065934, recall = 0.007748817650863305.\n",
            "Training on epoch 6 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693195, and regularization loss is 4.7e-05.\n",
            " Top K precision = 0.08817204301075267, recall = 0.006043973491485558.\n",
            "Training on epoch 6 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.69319, and regularization loss is 4.3e-05.\n",
            " Top K precision = 0.08924731182795696, recall = 0.007170727459922754.\n",
            "Training on epoch 6 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 8e-06.\n",
            " Top K precision = 0.0828282828282828, recall = 0.0074525284018506065.\n",
            "Training on epoch 6 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693185, and regularization loss is 3.8e-05.\n",
            " Top K precision = 0.07126436781609194, recall = 0.007557885764037356.\n",
            "\n",
            "Training on 6 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999997, recall = 0.0075379387941414445.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 7 epoch\n",
            "Training on epoch 7 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.08899999999999997, recall = 0.007423345766434924.\n",
            "Training on epoch 7 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.08163265306122446, recall = 0.007415023037298822.\n",
            "Training on epoch 7 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.0956043956043956, recall = 0.0086419091017536.\n",
            "Training on epoch 7 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.0835051546391752, recall = 0.006418901286039556.\n",
            "Training on epoch 7 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.0887755102040816, recall = 0.007260071990126781.\n",
            "Training on epoch 7 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
            " Top K precision = 0.08510638297872336, recall = 0.007088347504037229.\n",
            "Training on epoch 7 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693154, and regularization loss is 7e-06.\n",
            " Top K precision = 0.0891304347826087, recall = 0.008267919324729632.\n",
            "Training on epoch 7 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.08709677419354833, recall = 0.007074337455908138.\n",
            "\n",
            "Training on 7 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999991, recall = 0.007558772127474772.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 8 epoch\n",
            "Training on epoch 8 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.08421052631578949, recall = 0.006635218534969239.\n",
            "Training on epoch 8 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693179, and regularization loss is 3.2e-05.\n",
            " Top K precision = 0.08947368421052626, recall = 0.006917087801630446.\n",
            "Training on epoch 8 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.08681318681318678, recall = 0.00860761292712886.\n",
            "Training on epoch 8 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 9e-06.\n",
            " Top K precision = 0.07999999999999997, recall = 0.008108781554514775.\n",
            "Training on epoch 8 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
            " Top K precision = 0.09199999999999997, recall = 0.00844848189132006.\n",
            "Training on epoch 8 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
            " Top K precision = 0.10108695652173914, recall = 0.008067968549089548.\n",
            "Training on epoch 8 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
            " Top K precision = 0.10549450549450544, recall = 0.010238929868235762.\n",
            "Training on epoch 8 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09444444444444444, recall = 0.006783964935351684.\n",
            "\n",
            "Training on 8 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999998, recall = 0.007542694957056767.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 9 epoch\n",
            "Training on epoch 9 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.0967741935483871, recall = 0.008338285750766042.\n",
            "Training on epoch 9 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.0757894736842105, recall = 0.006110275805466594.\n",
            "Training on epoch 9 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.09560439560439556, recall = 0.007420004038575278.\n",
            "Training on epoch 9 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09684210526315788, recall = 0.008349955724002317.\n",
            "Training on epoch 9 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09680851063829783, recall = 0.00749006465871687.\n",
            "Training on epoch 9 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
            " Top K precision = 0.0938144329896907, recall = 0.006707742594800332.\n",
            "Training on epoch 9 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 9e-06.\n",
            " Top K precision = 0.09247311827956985, recall = 0.007574132595444834.\n",
            "Training on epoch 9 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
            " Top K precision = 0.07653061224489795, recall = 0.006959304658406655.\n",
            "\n",
            "Training on 9 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999998, recall = 0.007558772127474777.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 10 epoch\n",
            "Training on epoch 10 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 8e-06.\n",
            " Top K precision = 0.09130434782608694, recall = 0.008043152541346408.\n",
            "Training on epoch 10 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09789473684210521, recall = 0.007492133579012407.\n",
            "Training on epoch 10 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 8e-06.\n",
            " Top K precision = 0.08631578947368418, recall = 0.006833402009732248.\n",
            "Training on epoch 10 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08586956521739127, recall = 0.007551813747466689.\n",
            "Training on epoch 10 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.08888888888888884, recall = 0.006984796539759249.\n",
            "Training on epoch 10 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.07717391304347822, recall = 0.006868408083242916.\n",
            "Training on epoch 10 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08333333333333333, recall = 0.00783143541303744.\n",
            "Training on epoch 10 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.10217391304347817, recall = 0.009043527954513304.\n",
            "\n",
            "Training on 10 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999997, recall = 0.007492982653790564.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 11 epoch\n",
            "Training on epoch 11 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09318181818181816, recall = 0.007814837925041358.\n",
            "Training on epoch 11 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.08041237113402058, recall = 0.006970548584747582.\n",
            "Training on epoch 11 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08699999999999995, recall = 0.007955043085404961.\n",
            "Training on epoch 11 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08924731182795698, recall = 0.008125951522141524.\n",
            "Training on epoch 11 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.10319148936170207, recall = 0.00945299872022934.\n",
            "Training on epoch 11 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.0891304347826087, recall = 0.00761769077379127.\n",
            "Training on epoch 11 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09895833333333327, recall = 0.0071831466621955255.\n",
            "Training on epoch 11 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.08762886597938141, recall = 0.006814271261286469.\n",
            "\n",
            "Training on 11 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.007558772127474776.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08849999999999997, recall = 0.007617004302157751.\n",
            "\n",
            "Training on the 12 epoch\n",
            "Training on epoch 12 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09680851063829783, recall = 0.00885684027418058.\n",
            "Training on epoch 12 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08437499999999996, recall = 0.006479930460611033.\n",
            "Training on epoch 12 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.08350515463917524, recall = 0.007910997003139927.\n",
            "Training on epoch 12 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09021739130434782, recall = 0.008215523229093856.\n",
            "Training on epoch 12 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08152173913043477, recall = 0.005767271018821846.\n",
            "Training on epoch 12 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.0808510638297872, recall = 0.005793300097729136.\n",
            "Training on epoch 12 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09891304347826083, recall = 0.007393614611734387.\n",
            "Training on epoch 12 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09090909090909086, recall = 0.009051479228623104.\n",
            "\n",
            "Training on 12 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.0879999999999999, recall = 0.0074821835177214515.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08499999999999992, recall = 0.0074286663241644865.\n",
            "\n",
            "Training on the 13 epoch\n",
            "Training on epoch 13 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08888888888888884, recall = 0.007263115215559796.\n",
            "Training on epoch 13 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.0711111111111111, recall = 0.005559727385045975.\n",
            "Training on epoch 13 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.10736842105263152, recall = 0.008249171910548015.\n",
            "Training on epoch 13 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.07142857142857142, recall = 0.006396398278907196.\n",
            "Training on epoch 13 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.08144329896907213, recall = 0.0066195520213141925.\n",
            "Training on epoch 13 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08499999999999996, recall = 0.007524966825617529.\n",
            "Training on epoch 13 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.07551020408163261, recall = 0.006166312892626236.\n",
            "Training on epoch 13 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09213483146067411, recall = 0.007082357980629212.\n",
            "\n",
            "Training on 13 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999991, recall = 0.007558772127474776.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 14 epoch\n",
            "Training on epoch 14 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08061224489795914, recall = 0.00632160673411351.\n",
            "Training on epoch 14 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08172043010752687, recall = 0.007653204012154728.\n",
            "Training on epoch 14 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09072164948453605, recall = 0.007086061117856558.\n",
            "Training on epoch 14 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09900990099009896, recall = 0.007434855874294738.\n",
            "Training on epoch 14 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.0947368421052631, recall = 0.008678076275251408.\n",
            "Training on epoch 14 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.09166666666666662, recall = 0.008570622726511759.\n",
            "Training on epoch 14 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08571428571428572, recall = 0.007217573423887924.\n",
            "Training on epoch 14 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08877551020408159, recall = 0.009036563059605715.\n",
            "\n",
            "Training on 14 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999993, recall = 0.0075364506989033485.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08849999999999997, recall = 0.007489529542103159.\n",
            "\n",
            "Training on the 15 epoch\n",
            "Training on epoch 15 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.07888888888888887, recall = 0.006472385089754113.\n",
            "Training on epoch 15 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.0722222222222222, recall = 0.006154568214185246.\n",
            "Training on epoch 15 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09468085106382976, recall = 0.007546789242035322.\n",
            "Training on epoch 15 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08367346938775508, recall = 0.006822921828856543.\n",
            "Training on epoch 15 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09032258064516126, recall = 0.007240256448304961.\n",
            "Training on epoch 15 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.07526881720430105, recall = 0.007394852776482006.\n",
            "Training on epoch 15 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.07956989247311826, recall = 0.007771139403571303.\n",
            "Training on epoch 15 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08736842105263157, recall = 0.008078957467973442.\n",
            "\n",
            "Training on 15 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.007558772127474777.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075051481039122205.\n",
            "\n",
            "Training on the 16 epoch\n",
            "Training on epoch 16 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09666666666666664, recall = 0.008011172194566884.\n",
            "Training on epoch 16 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.07872340425531914, recall = 0.0067758826340575725.\n",
            "Training on epoch 16 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08499999999999996, recall = 0.007414081438723823.\n",
            "Training on epoch 16 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.07812499999999999, recall = 0.005845662610405678.\n",
            "Training on epoch 16 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.10208333333333326, recall = 0.00743449525712598.\n",
            "Training on epoch 16 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09069767441860464, recall = 0.007630178596769726.\n",
            "Training on epoch 16 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.07741935483870967, recall = 0.006372559651925853.\n",
            "Training on epoch 16 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.0871287128712871, recall = 0.005979692048202077.\n",
            "\n",
            "Training on 16 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08799999999999997, recall = 0.0075411042829518085.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08749999999999997, recall = 0.007374587013367528.\n",
            "\n",
            "Training on the 17 epoch\n",
            "Training on epoch 17 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.0858695652173913, recall = 0.006414951470541982.\n",
            "Training on epoch 17 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08064516129032256, recall = 0.00824379212759123.\n",
            "Training on epoch 17 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.07835051546391747, recall = 0.007983426438894868.\n",
            "Training on epoch 17 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08709677419354839, recall = 0.007909267565417669.\n",
            "Training on epoch 17 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.6e-05.\n",
            " Top K precision = 0.06941176470588234, recall = 0.00734887383522841.\n",
            "Training on epoch 17 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08556701030927832, recall = 0.008046128686541568.\n",
            "Training on epoch 17 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.1010869565217391, recall = 0.008835395950220511.\n",
            "Training on epoch 17 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09368421052631576, recall = 0.008904790351141233.\n",
            "\n",
            "Training on 17 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999997, recall = 0.007537938794141442.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08399999999999995, recall = 0.007331235124940974.\n",
            "\n",
            "Training on the 18 epoch\n",
            "Training on epoch 18 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.07368421052631577, recall = 0.007197466310334614.\n",
            "Training on epoch 18 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09690721649484532, recall = 0.008231122066948992.\n",
            "Training on epoch 18 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08877551020408163, recall = 0.008091805294634354.\n",
            "Training on epoch 18 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.08437499999999998, recall = 0.007497171735075431.\n",
            "Training on epoch 18 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693177, and regularization loss is 3e-05.\n",
            " Top K precision = 0.09489795918367344, recall = 0.007332342397969792.\n",
            "Training on epoch 18 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09677419354838705, recall = 0.0064795973190329426.\n",
            "Training on epoch 18 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.07894736842105261, recall = 0.007045881326610895.\n",
            "Training on epoch 18 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.07717391304347823, recall = 0.0053756550426396965.\n",
            "\n",
            "Training on 18 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08999999999999998, recall = 0.007583103027718081.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075051481039122205.\n",
            "\n",
            "Training on the 19 epoch\n",
            "Training on epoch 19 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.07311827956989247, recall = 0.0067599678504139.\n",
            "Training on epoch 19 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09680851063829782, recall = 0.008566952717067934.\n",
            "Training on epoch 19 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08387096774193548, recall = 0.008127377092610374.\n",
            "Training on epoch 19 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.09905660377358483, recall = 0.00827609543083774.\n",
            "Training on epoch 19 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08924731182795698, recall = 0.007610668471650119.\n",
            "Training on epoch 19 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.08762886597938142, recall = 0.007221835274455416.\n",
            "Training on epoch 19 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09062499999999997, recall = 0.0074872733600923344.\n",
            "Training on epoch 19 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.07029702970297028, recall = 0.00611967592514065.\n",
            "\n",
            "Training on 19 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999998, recall = 0.007558772127474777.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08749999999999997, recall = 0.007460828312954554.\n",
            "\n",
            "Training on the 20 epoch\n",
            "Training on epoch 20 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
            " Top K precision = 0.0829787234042553, recall = 0.007875983639039203.\n",
            "Training on epoch 20 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.0978723404255319, recall = 0.007635186964888919.\n",
            "Training on epoch 20 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.06847826086956521, recall = 0.004886308645387673.\n",
            "Training on epoch 20 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.07840909090909091, recall = 0.006508004184669237.\n",
            "Training on epoch 20 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.07422680412371133, recall = 0.00563654789504957.\n",
            "Training on epoch 20 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09702970297029696, recall = 0.0067244789973743635.\n",
            "Training on epoch 20 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09108910891089106, recall = 0.007730740142466774.\n",
            "Training on epoch 20 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.0653061224489796, recall = 0.007091815633848347.\n",
            "\n",
            "Training on 20 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.007558772127474777.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08849999999999994, recall = 0.007549266424052723.\n",
            "\n",
            "Training on the 21 epoch\n",
            "Training on epoch 21 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.4e-05.\n",
            " Top K precision = 0.09494949494949492, recall = 0.008230466249384574.\n",
            "Training on epoch 21 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.10210526315789469, recall = 0.008616110581141213.\n",
            "Training on epoch 21 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.7e-05.\n",
            " Top K precision = 0.08659793814432984, recall = 0.0075890911051091125.\n",
            "Training on epoch 21 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09042553191489362, recall = 0.005510730731499009.\n",
            "Training on epoch 21 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08526315789473682, recall = 0.007639416896663152.\n",
            "Training on epoch 21 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.10531914893617018, recall = 0.009413213761268477.\n",
            "Training on epoch 21 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08787878787878783, recall = 0.007832352952142838.\n",
            "Training on epoch 21 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.07422680412371133, recall = 0.007407790113618295.\n",
            "\n",
            "Training on 21 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08900000000000001, recall = 0.007558772127474775.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075051481039122205.\n",
            "\n",
            "Training on the 22 epoch\n",
            "Training on epoch 22 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.07872340425531912, recall = 0.007610591360159516.\n",
            "Training on epoch 22 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693154, and regularization loss is 7e-06.\n",
            " Top K precision = 0.07399999999999998, recall = 0.00812583079451911.\n",
            "Training on epoch 22 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.078021978021978, recall = 0.006993224630087888.\n",
            "Training on epoch 22 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08829787234042552, recall = 0.007537521877328669.\n",
            "Training on epoch 22 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08645833333333332, recall = 0.00802290868886671.\n",
            "Training on epoch 22 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09090909090909091, recall = 0.006079963226241125.\n",
            "Training on epoch 22 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.0927835051546391, recall = 0.0078011246100111635.\n",
            "Training on epoch 22 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08817204301075264, recall = 0.0073017502321741385.\n",
            "\n",
            "Training on 22 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08949999999999995, recall = 0.007705830951004188.\n",
            "\n",
            "Training on the 23 epoch\n",
            "Training on epoch 23 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08958333333333329, recall = 0.0069547652641723705.\n",
            "Training on epoch 23 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09263157894736841, recall = 0.007925315678469066.\n",
            "Training on epoch 23 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09784946236559137, recall = 0.007422492208154855.\n",
            "Training on epoch 23 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.09417475728155333, recall = 0.007961096628419406.\n",
            "Training on epoch 23 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
            " Top K precision = 0.09239130434782607, recall = 0.006418468353061155.\n",
            "Training on epoch 23 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.07659574468085105, recall = 0.006971552897176267.\n",
            "Training on epoch 23 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09444444444444443, recall = 0.007598272831760399.\n",
            "Training on epoch 23 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.6e-05.\n",
            " Top K precision = 0.10329670329670322, recall = 0.006883566430667821.\n",
            "\n",
            "Training on 23 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999993, recall = 0.0075587721274747765.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 24 epoch\n",
            "Training on epoch 24 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09795918367346933, recall = 0.008234800576084344.\n",
            "Training on epoch 24 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.09166666666666662, recall = 0.008620756565889141.\n",
            "Training on epoch 24 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
            " Top K precision = 0.0789473684210526, recall = 0.006917894218808665.\n",
            "Training on epoch 24 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.07628865979381441, recall = 0.006082416312994017.\n",
            "Training on epoch 24 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.096938775510204, recall = 0.007286744401543114.\n",
            "Training on epoch 24 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.6e-05.\n",
            " Top K precision = 0.08210526315789471, recall = 0.008792443660540914.\n",
            "Training on epoch 24 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09438202247191008, recall = 0.00773787883265142.\n",
            "Training on epoch 24 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.10106382978723401, recall = 0.008823844317037104.\n",
            "\n",
            "Training on 24 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999998, recall = 0.007558772127474779.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 25 epoch\n",
            "Training on epoch 25 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.09090909090909087, recall = 0.007253119027343197.\n",
            "Training on epoch 25 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.0959183673469387, recall = 0.007748430139100309.\n",
            "Training on epoch 25 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.0989473684210526, recall = 0.008821208184200931.\n",
            "Training on epoch 25 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08989898989898987, recall = 0.008178873823182175.\n",
            "Training on epoch 25 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09789473684210523, recall = 0.009018824885420851.\n",
            "Training on epoch 25 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.09504950495049501, recall = 0.006808900251982375.\n",
            "Training on epoch 25 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693177, and regularization loss is 3e-05.\n",
            " Top K precision = 0.08936170212765954, recall = 0.008522061864784368.\n",
            "Training on epoch 25 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.075531914893617, recall = 0.006980217287522448.\n",
            "\n",
            "Training on 25 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08749999999999991, recall = 0.007432532588829303.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08799999999999995, recall = 0.007526617786638764.\n",
            "\n",
            "Training on the 26 epoch\n",
            "Training on epoch 26 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.10543478260869561, recall = 0.008964473984819189.\n",
            "Training on epoch 26 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.09651162790697669, recall = 0.006998317168805911.\n",
            "Training on epoch 26 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.08829787234042552, recall = 0.007286432713161883.\n",
            "Training on epoch 26 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.07446808510638298, recall = 0.007113164079161328.\n",
            "Training on epoch 26 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09578947368421051, recall = 0.008424113833296899.\n",
            "Training on epoch 26 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.097752808988764, recall = 0.007707189122249963.\n",
            "Training on epoch 26 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.7e-05.\n",
            " Top K precision = 0.1083333333333333, recall = 0.00876966628567138.\n",
            "Training on epoch 26 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.0905263157894737, recall = 0.006981901397024267.\n",
            "\n",
            "Training on 26 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08799999999999995, recall = 0.007448739525222256.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08499999999999995, recall = 0.007363389465776987.\n",
            "\n",
            "Training on the 27 epoch\n",
            "Training on epoch 27 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.10319148936170208, recall = 0.008890815799204775.\n",
            "Training on epoch 27 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08764044943820223, recall = 0.006826709859572333.\n",
            "Training on epoch 27 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.0989690721649484, recall = 0.006430526702089494.\n",
            "Training on epoch 27 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08888888888888885, recall = 0.0056555286258899795.\n",
            "Training on epoch 27 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 9e-06.\n",
            " Top K precision = 0.08556701030927832, recall = 0.008288318912235873.\n",
            "Training on epoch 27 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.6e-05.\n",
            " Top K precision = 0.0945054945054945, recall = 0.008089168393255665.\n",
            "Training on epoch 27 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09462365591397846, recall = 0.007244648699000553.\n",
            "Training on epoch 27 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.0826086956521739, recall = 0.007518019293981369.\n",
            "\n",
            "Training on 27 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.007558772127474773.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08799999999999995, recall = 0.00746994547862834.\n",
            "\n",
            "Training on the 28 epoch\n",
            "Training on epoch 28 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08764044943820222, recall = 0.009954941489010544.\n",
            "Training on epoch 28 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.0813725490196078, recall = 0.007809266439327549.\n",
            "Training on epoch 28 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
            " Top K precision = 0.09680851063829782, recall = 0.007438206562995221.\n",
            "Training on epoch 28 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08791208791208788, recall = 0.007816812369108406.\n",
            "Training on epoch 28 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08586956521739127, recall = 0.0078011649624375986.\n",
            "Training on epoch 28 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.10224719101123593, recall = 0.007606070040104281.\n",
            "Training on epoch 28 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08936170212765956, recall = 0.00818289697418307.\n",
            "Training on epoch 28 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08842105263157893, recall = 0.007649741139291363.\n",
            "\n",
            "Training on 28 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08949999999999995, recall = 0.0077200624500554215.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 29 epoch\n",
            "Training on epoch 29 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09148936170212764, recall = 0.008686856167549778.\n",
            "Training on epoch 29 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.08068181818181817, recall = 0.006975198064187712.\n",
            "Training on epoch 29 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.0978723404255319, recall = 0.007933707734702339.\n",
            "Training on epoch 29 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.4e-05.\n",
            " Top K precision = 0.08556701030927832, recall = 0.008619436750024094.\n",
            "Training on epoch 29 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09120879120879122, recall = 0.0069399729906991.\n",
            "Training on epoch 29 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.07741935483870965, recall = 0.007451181249848335.\n",
            "Training on epoch 29 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09677419354838705, recall = 0.00867200513255313.\n",
            "Training on epoch 29 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09157894736842102, recall = 0.007651849805626229.\n",
            "\n",
            "Training on 29 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08749999999999997, recall = 0.007510540616220755.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 30 epoch\n",
            "Training on epoch 30 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08556701030927832, recall = 0.007823643662471593.\n",
            "Training on epoch 30 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08645833333333329, recall = 0.008278785152526016.\n",
            "Training on epoch 30 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.10833333333333332, recall = 0.0072157883436200256.\n",
            "Training on epoch 30 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.0914893617021276, recall = 0.00719260262280647.\n",
            "Training on epoch 30 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09134615384615383, recall = 0.006847573260683882.\n",
            "Training on epoch 30 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08390804597701146, recall = 0.008432496463190227.\n",
            "Training on epoch 30 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.09578947368421051, recall = 0.008762557857642836.\n",
            "Training on epoch 30 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08369565217391303, recall = 0.007319210833028312.\n",
            "\n",
            "Training on 30 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.007558772127474777.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 31 epoch\n",
            "Training on epoch 31 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08446601941747571, recall = 0.0070498768134892404.\n",
            "Training on epoch 31 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693155, and regularization loss is 7e-06.\n",
            " Top K precision = 0.08124999999999996, recall = 0.008182124422480137.\n",
            "Training on epoch 31 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.0863157894736842, recall = 0.00717151389860549.\n",
            "Training on epoch 31 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08571428571428569, recall = 0.008607307994600402.\n",
            "Training on epoch 31 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
            " Top K precision = 0.10439560439560437, recall = 0.00833401827889402.\n",
            "Training on epoch 31 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.07956989247311824, recall = 0.00800323831572608.\n",
            "Training on epoch 31 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
            " Top K precision = 0.08260869565217388, recall = 0.007959100430303373.\n",
            "Training on epoch 31 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.08252427184466016, recall = 0.007651914699639905.\n",
            "\n",
            "Training on 31 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999997, recall = 0.007558772127474777.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08849999999999994, recall = 0.007549266424052723.\n",
            "\n",
            "Training on the 32 epoch\n",
            "Training on epoch 32 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09081632653061222, recall = 0.007487608259482521.\n",
            "Training on epoch 32 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.08349514563106793, recall = 0.006837663001254808.\n",
            "Training on epoch 32 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.0684782608695652, recall = 0.005881776532976134.\n",
            "Training on epoch 32 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08602150537634408, recall = 0.008434878871637502.\n",
            "Training on epoch 32 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.0833333333333333, recall = 0.005709555527480755.\n",
            "Training on epoch 32 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.10312499999999995, recall = 0.00812559116193542.\n",
            "Training on epoch 32 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.10101010101010095, recall = 0.008577029879005493.\n",
            "Training on epoch 32 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.07553191489361703, recall = 0.0056841492472084875.\n",
            "\n",
            "Training on 32 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999993, recall = 0.007558772127474777.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075051481039122205.\n",
            "\n",
            "Training on the 33 epoch\n",
            "Training on epoch 33 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693176, and regularization loss is 2.8e-05.\n",
            " Top K precision = 0.0783505154639175, recall = 0.007502006700662135.\n",
            "Training on epoch 33 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.10399999999999993, recall = 0.008592322203079738.\n",
            "Training on epoch 33 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08387096774193545, recall = 0.007574115542297723.\n",
            "Training on epoch 33 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09484536082474226, recall = 0.005890543088973228.\n",
            "Training on epoch 33 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.09438202247191006, recall = 0.0074800104319114715.\n",
            "Training on epoch 33 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.07473684210526314, recall = 0.007326048567923381.\n",
            "Training on epoch 33 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.092156862745098, recall = 0.0075781665468246115.\n",
            "Training on epoch 33 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09302325581395347, recall = 0.006130634705786497.\n",
            "\n",
            "Training on 33 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999991, recall = 0.007558772127474775.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08399999999999995, recall = 0.007277611101378419.\n",
            "\n",
            "Training on the 34 epoch\n",
            "Training on epoch 34 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09263157894736838, recall = 0.007853290753698053.\n",
            "Training on epoch 34 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09565217391304343, recall = 0.0077968235557862465.\n",
            "Training on epoch 34 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.0821052631578947, recall = 0.00719634759999823.\n",
            "Training on epoch 34 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08247422680412364, recall = 0.008299279155106.\n",
            "Training on epoch 34 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.07789473684210525, recall = 0.007303517240354061.\n",
            "Training on epoch 34 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.07241379310344825, recall = 0.007148308190670926.\n",
            "Training on epoch 34 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
            " Top K precision = 0.09313725490196072, recall = 0.00877259583873706.\n",
            "Training on epoch 34 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08172043010752682, recall = 0.008005691974142894.\n",
            "\n",
            "Training on 34 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999997, recall = 0.007474026364762913.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 35 epoch\n",
            "Training on epoch 35 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08599999999999998, recall = 0.008132844811286552.\n",
            "Training on epoch 35 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.11052631578947363, recall = 0.007684212492576956.\n",
            "Training on epoch 35 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09999999999999998, recall = 0.00885010160949973.\n",
            "Training on epoch 35 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.07731958762886598, recall = 0.007082675379690347.\n",
            "Training on epoch 35 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.6e-05.\n",
            " Top K precision = 0.10736842105263157, recall = 0.007903178371638963.\n",
            "Training on epoch 35 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08541666666666665, recall = 0.007768895007252422.\n",
            "Training on epoch 35 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09157894736842102, recall = 0.008762303729078715.\n",
            "Training on epoch 35 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.08613861386138609, recall = 0.007677057959140965.\n",
            "\n",
            "Training on 35 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999993, recall = 0.00756159857010948.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08499999999999995, recall = 0.007363389465776987.\n",
            "\n",
            "Training on the 36 epoch\n",
            "Training on epoch 36 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08333333333333333, recall = 0.0068137332943774215.\n",
            "Training on epoch 36 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09255319148936166, recall = 0.008589725169122512.\n",
            "Training on epoch 36 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08021978021978018, recall = 0.008003331694040952.\n",
            "Training on epoch 36 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.07765957446808508, recall = 0.006960620678809262.\n",
            "Training on epoch 36 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09405940594059405, recall = 0.007330339127269372.\n",
            "Training on epoch 36 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.08829787234042552, recall = 0.006727870330459729.\n",
            "Training on epoch 36 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08210526315789472, recall = 0.007099318103748226.\n",
            "Training on epoch 36 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09565217391304345, recall = 0.007654461695407283.\n",
            "\n",
            "Training on 36 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999997, recall = 0.007558772127474775.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08599999999999994, recall = 0.007454012791377817.\n",
            "\n",
            "Training on the 37 epoch\n",
            "Training on epoch 37 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.090625, recall = 0.006920445276638092.\n",
            "Training on epoch 37 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08924731182795696, recall = 0.0096347609304797.\n",
            "Training on epoch 37 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.07717391304347823, recall = 0.006477194733693347.\n",
            "Training on epoch 37 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.0894736842105263, recall = 0.007055759385417359.\n",
            "Training on epoch 37 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
            " Top K precision = 0.08404255319148936, recall = 0.008212194957634781.\n",
            "Training on epoch 37 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.10206185567010304, recall = 0.006758848728169445.\n",
            "Training on epoch 37 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.07894736842105257, recall = 0.007225310020742687.\n",
            "Training on epoch 37 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08969072164948452, recall = 0.006280069867187541.\n",
            "\n",
            "Training on 37 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08749999999999993, recall = 0.007459924381581926.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08849999999999997, recall = 0.007617004302157751.\n",
            "\n",
            "Training on the 38 epoch\n",
            "Training on epoch 38 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09239130434782605, recall = 0.007467433457253873.\n",
            "Training on epoch 38 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.0747474747474747, recall = 0.0076646671203050454.\n",
            "Training on epoch 38 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.08979591836734693, recall = 0.006850702232649034.\n",
            "Training on epoch 38 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.09999999999999995, recall = 0.008628531880891434.\n",
            "Training on epoch 38 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.07582417582417582, recall = 0.006567924500419948.\n",
            "Training on epoch 38 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.07977528089887637, recall = 0.006378790050609057.\n",
            "Training on epoch 38 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08541666666666664, recall = 0.0073872325139274705.\n",
            "Training on epoch 38 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.0923076923076923, recall = 0.008336584028357772.\n",
            "\n",
            "Training on 38 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08699999999999988, recall = 0.00744151399004259.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 39 epoch\n",
            "Training on epoch 39 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
            " Top K precision = 0.10202020202020198, recall = 0.008928794871221397.\n",
            "Training on epoch 39 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.0804123711340206, recall = 0.006803469151579373.\n",
            "Training on epoch 39 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.06630434782608693, recall = 0.005352468378409632.\n",
            "Training on epoch 39 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08913043478260867, recall = 0.007139135984181504.\n",
            "Training on epoch 39 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.10505050505050503, recall = 0.009751218148686012.\n",
            "Training on epoch 39 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.0897959183673469, recall = 0.008502557148770639.\n",
            "Training on epoch 39 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.0927083333333333, recall = 0.008347612460821907.\n",
            "Training on epoch 39 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09897959183673463, recall = 0.006968662648706821.\n",
            "\n",
            "Training on 39 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08699999999999991, recall = 0.007611817452034214.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08649999999999995, recall = 0.007456991484762598.\n",
            "\n",
            "Training on the 40 epoch\n",
            "Training on epoch 40 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08749999999999997, recall = 0.00716125195102373.\n",
            "Training on epoch 40 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08936170212765956, recall = 0.007878717672054775.\n",
            "Training on epoch 40 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08387096774193548, recall = 0.006419235849956077.\n",
            "Training on epoch 40 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09166666666666662, recall = 0.008656018106498114.\n",
            "Training on epoch 40 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08541666666666664, recall = 0.0069983623532680105.\n",
            "Training on epoch 40 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.07653061224489795, recall = 0.007176421455765273.\n",
            "Training on epoch 40 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08666666666666661, recall = 0.007715709581162007.\n",
            "Training on epoch 40 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.0831578947368421, recall = 0.007946920257580089.\n",
            "\n",
            "Training on 40 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08549999999999992, recall = 0.007439101028110537.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 41 epoch\n",
            "Training on epoch 41 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08297872340425534, recall = 0.007475706070492847.\n",
            "Training on epoch 41 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.07669902912621356, recall = 0.007608449752771782.\n",
            "Training on epoch 41 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09361702127659573, recall = 0.006568032328759332.\n",
            "Training on epoch 41 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.10434782608695647, recall = 0.00952251060012834.\n",
            "Training on epoch 41 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.0945652173913043, recall = 0.00822738856074572.\n",
            "Training on epoch 41 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.0869565217391304, recall = 0.0074939785742441.\n",
            "Training on epoch 41 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.06989247311827956, recall = 0.006692347960398613.\n",
            "Training on epoch 41 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08977272727272727, recall = 0.006593149421603284.\n",
            "\n",
            "Training on 41 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999997, recall = 0.007558772127474779.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 42 epoch\n",
            "Training on epoch 42 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 8e-06.\n",
            " Top K precision = 0.078, recall = 0.0071339021543093736.\n",
            "Training on epoch 42 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.0918367346938775, recall = 0.008036448563788703.\n",
            "Training on epoch 42 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08865979381443297, recall = 0.007937160383414573.\n",
            "Training on epoch 42 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.06999999999999998, recall = 0.006422014124907522.\n",
            "Training on epoch 42 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.059782608695652155, recall = 0.006837757901164215.\n",
            "Training on epoch 42 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09032258064516127, recall = 0.007520949139512847.\n",
            "Training on epoch 42 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.07425742574257423, recall = 0.00602796182691916.\n",
            "Training on epoch 42 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.08863636363636362, recall = 0.006350564533923942.\n",
            "\n",
            "Training on 42 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08900000000000001, recall = 0.007558772127474777.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08199999999999993, recall = 0.007329560941028958.\n",
            "\n",
            "Training on the 43 epoch\n",
            "Training on epoch 43 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.091578947368421, recall = 0.008166086433722144.\n",
            "Training on epoch 43 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.09789473684210523, recall = 0.008602580283342636.\n",
            "Training on epoch 43 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08947368421052627, recall = 0.00791738752526863.\n",
            "Training on epoch 43 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09456521739130432, recall = 0.007759562112409536.\n",
            "Training on epoch 43 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09462365591397845, recall = 0.007491009330595765.\n",
            "Training on epoch 43 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.09278350515463912, recall = 0.00845081009287675.\n",
            "Training on epoch 43 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08636363636363634, recall = 0.007910856252054142.\n",
            "Training on epoch 43 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08260869565217388, recall = 0.006864097331690788.\n",
            "\n",
            "Training on 43 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.0894999999999999, recall = 0.007629194662686044.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08749999999999997, recall = 0.007460828312954554.\n",
            "\n",
            "Training on the 44 epoch\n",
            "Training on epoch 44 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09381443298969068, recall = 0.008487184891141373.\n",
            "Training on epoch 44 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09893617021276596, recall = 0.007592633472651469.\n",
            "Training on epoch 44 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.09890109890109887, recall = 0.00844055430992649.\n",
            "Training on epoch 44 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09670329670329668, recall = 0.006830252498538917.\n",
            "Training on epoch 44 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
            " Top K precision = 0.08599999999999994, recall = 0.007767699987444494.\n",
            "Training on epoch 44 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08105263157894736, recall = 0.007547161812723416.\n",
            "Training on epoch 44 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 9e-06.\n",
            " Top K precision = 0.06888888888888889, recall = 0.00737045174547581.\n",
            "Training on epoch 44 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09157894736842105, recall = 0.008388605198578746.\n",
            "\n",
            "Training on 44 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 45 epoch\n",
            "Training on epoch 45 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08645833333333332, recall = 0.007526850104671333.\n",
            "Training on epoch 45 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.07444444444444444, recall = 0.006342967025544474.\n",
            "Training on epoch 45 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08541666666666664, recall = 0.007052695686778267.\n",
            "Training on epoch 45 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09587628865979378, recall = 0.007098732901669531.\n",
            "Training on epoch 45 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.07799999999999996, recall = 0.008027246461195854.\n",
            "Training on epoch 45 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.06741573033707864, recall = 0.00587663814536386.\n",
            "Training on epoch 45 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09484536082474222, recall = 0.008426338492523847.\n",
            "Training on epoch 45 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09999999999999999, recall = 0.008320227207588994.\n",
            "\n",
            "Training on 45 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999998, recall = 0.0075587721274747765.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08799999999999995, recall = 0.007526617786638764.\n",
            "\n",
            "Training on the 46 epoch\n",
            "Training on epoch 46 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09081632653061221, recall = 0.0077397610691975855.\n",
            "Training on epoch 46 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 9e-06.\n",
            " Top K precision = 0.07599999999999997, recall = 0.00634573278419768.\n",
            "Training on epoch 46 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09780219780219775, recall = 0.007887277357092888.\n",
            "Training on epoch 46 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09504950495049505, recall = 0.00642226880973426.\n",
            "Training on epoch 46 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
            " Top K precision = 0.09306930693069301, recall = 0.006563299914006844.\n",
            "Training on epoch 46 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09899999999999992, recall = 0.007756480806927906.\n",
            "Training on epoch 46 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693178, and regularization loss is 3.1e-05.\n",
            " Top K precision = 0.0802197802197802, recall = 0.006371208813283654.\n",
            "Training on epoch 46 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.7e-05.\n",
            " Top K precision = 0.09690721649484527, recall = 0.007241626352260935.\n",
            "\n",
            "Training on 46 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08699999999999994, recall = 0.007412815010450753.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08599999999999994, recall = 0.007454012791377817.\n",
            "\n",
            "Training on the 47 epoch\n",
            "Training on epoch 47 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 9e-06.\n",
            " Top K precision = 0.09081632653061221, recall = 0.008155955547318586.\n",
            "Training on epoch 47 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09263157894736838, recall = 0.006936636447375391.\n",
            "Training on epoch 47 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09139784946236555, recall = 0.007282556034977159.\n",
            "Training on epoch 47 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09893617021276593, recall = 0.008325707698738437.\n",
            "Training on epoch 47 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.07473684210526317, recall = 0.005795129110097073.\n",
            "Training on epoch 47 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08437499999999999, recall = 0.007424861559493342.\n",
            "Training on epoch 47 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.07878787878787875, recall = 0.007456800152244768.\n",
            "Training on epoch 47 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 9e-06.\n",
            " Top K precision = 0.09569892473118274, recall = 0.007770194927810066.\n",
            "\n",
            "Training on 47 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999997, recall = 0.0075587721274747765.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 48 epoch\n",
            "Training on epoch 48 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.10312499999999991, recall = 0.00996624176017758.\n",
            "Training on epoch 48 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09157894736842102, recall = 0.00947603905126523.\n",
            "Training on epoch 48 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.0858695652173913, recall = 0.006457461317407716.\n",
            "Training on epoch 48 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.08979591836734693, recall = 0.006510218331364919.\n",
            "Training on epoch 48 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.07299999999999997, recall = 0.007568814976243903.\n",
            "Training on epoch 48 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09247311827956983, recall = 0.007176289093142499.\n",
            "Training on epoch 48 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
            " Top K precision = 0.09898989898989896, recall = 0.007255196484285569.\n",
            "Training on epoch 48 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693175, and regularization loss is 2.8e-05.\n",
            " Top K precision = 0.07727272727272726, recall = 0.008480968438930418.\n",
            "\n",
            "Training on 48 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08949999999999993, recall = 0.007751079819782466.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 49 epoch\n",
            "Training on epoch 49 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.09489795918367344, recall = 0.008122266291167943.\n",
            "Training on epoch 49 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.07699999999999997, recall = 0.0065742672096245035.\n",
            "Training on epoch 49 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09894736842105262, recall = 0.00817715918932475.\n",
            "Training on epoch 49 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08282828282828282, recall = 0.006647570942500723.\n",
            "Training on epoch 49 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09999999999999996, recall = 0.008112629160993834.\n",
            "Training on epoch 49 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08888888888888886, recall = 0.008086053337330564.\n",
            "Training on epoch 49 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09595959595959594, recall = 0.007446058319339298.\n",
            "Training on epoch 49 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08585858585858584, recall = 0.008505033946555222.\n",
            "\n",
            "Training on 49 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08900000000000001, recall = 0.007558772127474777.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08599999999999994, recall = 0.007524943602726746.\n",
            "\n",
            "Training on the 50 epoch\n",
            "Training on epoch 50 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09368421052631576, recall = 0.007544002155257603.\n",
            "Training on epoch 50 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.0833333333333333, recall = 0.007935760913365992.\n",
            "Training on epoch 50 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08191489361702126, recall = 0.006445188705287.\n",
            "Training on epoch 50 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08469387755102038, recall = 0.0074494418603470456.\n",
            "Training on epoch 50 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09340659340659335, recall = 0.007120260373952234.\n",
            "Training on epoch 50 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.07096774193548384, recall = 0.006212823983012476.\n",
            "Training on epoch 50 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08969072164948452, recall = 0.006709600692964655.\n",
            "Training on epoch 50 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09555555555555553, recall = 0.008226688538249604.\n",
            "\n",
            "Training on 50 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08499999999999992, recall = 0.007420759856578143.\n",
            "\n",
            "Training on the 51 epoch\n",
            "Training on epoch 51 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.07755102040816324, recall = 0.006517856499024418.\n",
            "Training on epoch 51 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09270833333333328, recall = 0.006925254114542583.\n",
            "Training on epoch 51 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09684210526315785, recall = 0.009033042010025747.\n",
            "Training on epoch 51 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08695652173913039, recall = 0.007781029354231433.\n",
            "Training on epoch 51 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08297872340425529, recall = 0.008612224087781553.\n",
            "Training on epoch 51 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09215686274509804, recall = 0.008523937165420993.\n",
            "Training on epoch 51 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09340659340659337, recall = 0.007541252931984923.\n",
            "Training on epoch 51 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09010989010989011, recall = 0.007459000958348387.\n",
            "\n",
            "Training on 51 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.0885, recall = 0.007497043732413051.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 52 epoch\n",
            "Training on epoch 52 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.10291262135922324, recall = 0.00897277120736156.\n",
            "Training on epoch 52 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693153, and regularization loss is 6e-06.\n",
            " Top K precision = 0.10107526881720424, recall = 0.008066632777641266.\n",
            "Training on epoch 52 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09374999999999999, recall = 0.007686061785164133.\n",
            "Training on epoch 52 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08061224489795918, recall = 0.005537460322160947.\n",
            "Training on epoch 52 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.1040816326530612, recall = 0.0077144165279593.\n",
            "Training on epoch 52 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.1021276595744681, recall = 0.008629892936125386.\n",
            "Training on epoch 52 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
            " Top K precision = 0.08541666666666664, recall = 0.007406913408792862.\n",
            "Training on epoch 52 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08764044943820222, recall = 0.005978098156785957.\n",
            "\n",
            "Training on 52 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999994, recall = 0.007507751719311511.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08599999999999994, recall = 0.007454012791377817.\n",
            "\n",
            "Training on the 53 epoch\n",
            "Training on epoch 53 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08791208791208788, recall = 0.008054122390388205.\n",
            "Training on epoch 53 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08723404255319145, recall = 0.007371138576494269.\n",
            "Training on epoch 53 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08932038834951452, recall = 0.006964767626436377.\n",
            "Training on epoch 53 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08494623655913976, recall = 0.007875844262764166.\n",
            "Training on epoch 53 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08526315789473683, recall = 0.007903810921387758.\n",
            "Training on epoch 53 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.10315789473684207, recall = 0.007850625954641179.\n",
            "Training on epoch 53 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08791208791208789, recall = 0.007387231527167768.\n",
            "Training on epoch 53 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
            " Top K precision = 0.10101010101010098, recall = 0.0079526173445039.\n",
            "\n",
            "Training on 53 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999994, recall = 0.007497043732413047.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08599999999999994, recall = 0.007454012791377817.\n",
            "\n",
            "Training on the 54 epoch\n",
            "Training on epoch 54 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09494949494949492, recall = 0.008348201001797003.\n",
            "Training on epoch 54 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08510638297872337, recall = 0.0077624451358116004.\n",
            "Training on epoch 54 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08723404255319146, recall = 0.0062487756679783174.\n",
            "Training on epoch 54 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.09374999999999994, recall = 0.00800281583149855.\n",
            "Training on epoch 54 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.07717391304347826, recall = 0.007754661972703771.\n",
            "Training on epoch 54 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
            " Top K precision = 0.09333333333333332, recall = 0.00878333672994957.\n",
            "Training on epoch 54 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09569892473118279, recall = 0.007958035889750414.\n",
            "Training on epoch 54 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.095049504950495, recall = 0.009346936392753913.\n",
            "\n",
            "Training on 54 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999994, recall = 0.007464432504833267.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08499999999999995, recall = 0.007363389465776987.\n",
            "\n",
            "Training on the 55 epoch\n",
            "Training on epoch 55 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09230769230769226, recall = 0.00788981015442436.\n",
            "Training on epoch 55 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.1076923076923076, recall = 0.009288740594215616.\n",
            "Training on epoch 55 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.0808510638297872, recall = 0.006604615623201164.\n",
            "Training on epoch 55 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.10121951219512192, recall = 0.006083328741824903.\n",
            "Training on epoch 55 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08172043010752683, recall = 0.006831607252680345.\n",
            "Training on epoch 55 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08736842105263155, recall = 0.007663987188254726.\n",
            "Training on epoch 55 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08099999999999996, recall = 0.007396346729559982.\n",
            "Training on epoch 55 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.7e-05.\n",
            " Top K precision = 0.0894736842105263, recall = 0.007891234977809468.\n",
            "\n",
            "Training on 55 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999993, recall = 0.007558772127474776.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 56 epoch\n",
            "Training on epoch 56 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.10106382978723398, recall = 0.0074354151979017045.\n",
            "Training on epoch 56 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693154, and regularization loss is 7e-06.\n",
            " Top K precision = 0.09157894736842105, recall = 0.007698609051741861.\n",
            "Training on epoch 56 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08089887640449435, recall = 0.0073606773438356435.\n",
            "Training on epoch 56 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08539325842696625, recall = 0.00623021930508076.\n",
            "Training on epoch 56 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.7e-05.\n",
            " Top K precision = 0.07777777777777779, recall = 0.00828677083768903.\n",
            "Training on epoch 56 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.09111111111111109, recall = 0.007543793820567858.\n",
            "Training on epoch 56 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693153, and regularization loss is 6e-06.\n",
            " Top K precision = 0.09318181818181817, recall = 0.008647704410104715.\n",
            "Training on epoch 56 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08823529411764701, recall = 0.006836863050258775.\n",
            "\n",
            "Training on 56 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999991, recall = 0.007558772127474777.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 57 epoch\n",
            "Training on epoch 57 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08681318681318678, recall = 0.009614580259645773.\n",
            "Training on epoch 57 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.07191011235955057, recall = 0.0072208459596279535.\n",
            "Training on epoch 57 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693176, and regularization loss is 2.9e-05.\n",
            " Top K precision = 0.08080808080808081, recall = 0.005931680800348433.\n",
            "Training on epoch 57 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.10329670329670322, recall = 0.005938408477041749.\n",
            "Training on epoch 57 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08494623655913976, recall = 0.007978167336239798.\n",
            "Training on epoch 57 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09489795918367343, recall = 0.008847816547567531.\n",
            "Training on epoch 57 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09285714285714282, recall = 0.008785292058085198.\n",
            "Training on epoch 57 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.0883720930232558, recall = 0.007763368328076106.\n",
            "\n",
            "Training on 57 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08799999999999994, recall = 0.007535637367497908.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 58 epoch\n",
            "Training on epoch 58 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09489795918367339, recall = 0.0091165709597168.\n",
            "Training on epoch 58 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.0894736842105263, recall = 0.007189856681279792.\n",
            "Training on epoch 58 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08777777777777777, recall = 0.008300434264557056.\n",
            "Training on epoch 58 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.08749999999999998, recall = 0.0074845046874244085.\n",
            "Training on epoch 58 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08723404255319148, recall = 0.007764960236726661.\n",
            "Training on epoch 58 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693177, and regularization loss is 3e-05.\n",
            " Top K precision = 0.07578947368421049, recall = 0.006210269695720875.\n",
            "Training on epoch 58 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.08222222222222218, recall = 0.0066147590927469.\n",
            "Training on epoch 58 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.07701149425287356, recall = 0.0069462189788509045.\n",
            "\n",
            "Training on 58 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08749999999999997, recall = 0.007435984423181442.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08599999999999994, recall = 0.007454012791377817.\n",
            "\n",
            "Training on the 59 epoch\n",
            "Training on epoch 59 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08924731182795696, recall = 0.007491246954513086.\n",
            "Training on epoch 59 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.10412371134020618, recall = 0.008300235567399727.\n",
            "Training on epoch 59 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08936170212765954, recall = 0.00897288358745728.\n",
            "Training on epoch 59 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
            " Top K precision = 0.10217391304347823, recall = 0.0086664502488281.\n",
            "Training on epoch 59 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08124999999999998, recall = 0.007277961524938075.\n",
            "Training on epoch 59 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
            " Top K precision = 0.08099999999999996, recall = 0.007672919243859413.\n",
            "Training on epoch 59 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09148936170212764, recall = 0.007413708432519236.\n",
            "Training on epoch 59 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.1009523809523809, recall = 0.007712545704177407.\n",
            "\n",
            "Training on 59 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.007558772127474777.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08849999999999997, recall = 0.007578682530660441.\n",
            "\n",
            "Training on the 60 epoch\n",
            "Training on epoch 60 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09462365591397848, recall = 0.005951281089225585.\n",
            "Training on epoch 60 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.08499999999999996, recall = 0.007778955681938041.\n",
            "Training on epoch 60 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693175, and regularization loss is 2.8e-05.\n",
            " Top K precision = 0.09787234042553189, recall = 0.008168894654055327.\n",
            "Training on epoch 60 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
            " Top K precision = 0.08666666666666661, recall = 0.009132310143533351.\n",
            "Training on epoch 60 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.0852941176470588, recall = 0.0086976732678282.\n",
            "Training on epoch 60 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09444444444444439, recall = 0.009373790945940319.\n",
            "Training on epoch 60 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.0852631578947368, recall = 0.008577132174374566.\n",
            "Training on epoch 60 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08043478260869563, recall = 0.006516369342054577.\n",
            "\n",
            "Training on 60 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999997, recall = 0.007492982653790566.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 61 epoch\n",
            "Training on epoch 61 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.10714285714285712, recall = 0.009286876588946173.\n",
            "Training on epoch 61 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08383838383838381, recall = 0.007211446497525943.\n",
            "Training on epoch 61 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.0909090909090909, recall = 0.0076437623587103445.\n",
            "Training on epoch 61 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.10526315789473678, recall = 0.008805072906527456.\n",
            "Training on epoch 61 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.07340425531914892, recall = 0.0060623986326336365.\n",
            "Training on epoch 61 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.0757894736842105, recall = 0.005626969298579932.\n",
            "Training on epoch 61 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09693877551020401, recall = 0.007877403983891414.\n",
            "Training on epoch 61 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09399999999999994, recall = 0.007621973495092083.\n",
            "\n",
            "Training on 61 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08749999999999991, recall = 0.0075182025237208626.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08849999999999994, recall = 0.007535024896097157.\n",
            "\n",
            "Training on the 62 epoch\n",
            "Training on epoch 62 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.10505050505050498, recall = 0.008658625371134446.\n",
            "Training on epoch 62 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
            " Top K precision = 0.09565217391304347, recall = 0.007514158168506651.\n",
            "Training on epoch 62 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08749999999999993, recall = 0.007420182373621548.\n",
            "Training on epoch 62 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.0725490196078431, recall = 0.006326333422261178.\n",
            "Training on epoch 62 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.07812499999999999, recall = 0.005794998783901659.\n",
            "Training on epoch 62 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.10537634408602149, recall = 0.008687800059871903.\n",
            "Training on epoch 62 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.10952380952380954, recall = 0.007115405059656607.\n",
            "Training on epoch 62 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
            " Top K precision = 0.08865979381443295, recall = 0.007218154002312534.\n",
            "\n",
            "Training on 62 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999993, recall = 0.007558772127474775.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 63 epoch\n",
            "Training on epoch 63 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.07708333333333332, recall = 0.006236825107266374.\n",
            "Training on epoch 63 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08725490196078428, recall = 0.007655406064963896.\n",
            "Training on epoch 63 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.07676767676767675, recall = 0.006700484356272692.\n",
            "Training on epoch 63 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08453608247422678, recall = 0.005080217986981483.\n",
            "Training on epoch 63 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08415841584158411, recall = 0.007511352444900893.\n",
            "Training on epoch 63 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09468085106382977, recall = 0.007998763653303898.\n",
            "Training on epoch 63 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08823529411764704, recall = 0.007384188603226782.\n",
            "Training on epoch 63 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09484536082474222, recall = 0.0063884501113858185.\n",
            "\n",
            "Training on 63 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999994, recall = 0.00746948641318906.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08499999999999995, recall = 0.007363389465776987.\n",
            "\n",
            "Training on the 64 epoch\n",
            "Training on epoch 64 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.07362637362637361, recall = 0.006966568171494789.\n",
            "Training on epoch 64 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09263157894736837, recall = 0.007432987883796722.\n",
            "Training on epoch 64 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08260869565217388, recall = 0.007753453872565132.\n",
            "Training on epoch 64 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09361702127659571, recall = 0.008438705136801426.\n",
            "Training on epoch 64 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.08775510204081631, recall = 0.007807762140853473.\n",
            "Training on epoch 64 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.10105263157894731, recall = 0.009552078533620263.\n",
            "Training on epoch 64 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08152173913043477, recall = 0.005602389897052052.\n",
            "Training on epoch 64 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09462365591397845, recall = 0.006286932156451872.\n",
            "\n",
            "Training on 64 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.007558772127474777.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 65 epoch\n",
            "Training on epoch 65 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.10322580645161288, recall = 0.007146072757367082.\n",
            "Training on epoch 65 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.10204081632653057, recall = 0.006984124415742551.\n",
            "Training on epoch 65 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
            " Top K precision = 0.07659574468085104, recall = 0.007710389474415739.\n",
            "Training on epoch 65 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.0769230769230769, recall = 0.00788602523776055.\n",
            "Training on epoch 65 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
            " Top K precision = 0.11666666666666663, recall = 0.009475217223967583.\n",
            "Training on epoch 65 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08421052631578949, recall = 0.007462947907931603.\n",
            "Training on epoch 65 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08367346938775508, recall = 0.007740233503110143.\n",
            "Training on epoch 65 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 9e-06.\n",
            " Top K precision = 0.08977272727272724, recall = 0.007824397579821575.\n",
            "\n",
            "Training on 65 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999998, recall = 0.0075479729914056624.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075051481039122205.\n",
            "\n",
            "Training on the 66 epoch\n",
            "Training on epoch 66 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09673913043478258, recall = 0.006097290031269018.\n",
            "Training on epoch 66 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.108080808080808, recall = 0.008790328850949419.\n",
            "Training on epoch 66 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09032258064516127, recall = 0.007273166615043115.\n",
            "Training on epoch 66 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
            " Top K precision = 0.08599999999999998, recall = 0.006622865976773516.\n",
            "Training on epoch 66 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.07789473684210522, recall = 0.006227129248919101.\n",
            "Training on epoch 66 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.10430107526881716, recall = 0.009131580725978812.\n",
            "Training on epoch 66 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.10112359550561793, recall = 0.00891013546298711.\n",
            "Training on epoch 66 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09361702127659573, recall = 0.0070392776745147835.\n",
            "\n",
            "Training on 66 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999993, recall = 0.007558772127474777.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 67 epoch\n",
            "Training on epoch 67 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08222222222222221, recall = 0.007325739857406894.\n",
            "Training on epoch 67 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.10421052631578943, recall = 0.007319139449567808.\n",
            "Training on epoch 67 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.12111111111111106, recall = 0.008947006499791707.\n",
            "Training on epoch 67 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08913043478260867, recall = 0.00725660896197941.\n",
            "Training on epoch 67 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09690721649484531, recall = 0.00820336753902528.\n",
            "Training on epoch 67 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09999999999999995, recall = 0.007836468048935126.\n",
            "Training on epoch 67 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09696969696969691, recall = 0.007567765104897825.\n",
            "Training on epoch 67 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.07187499999999998, recall = 0.0051730190841687805.\n",
            "\n",
            "Training on 67 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08649999999999995, recall = 0.007456486303425602.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 68 epoch\n",
            "Training on epoch 68 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09425287356321835, recall = 0.007609505736774739.\n",
            "Training on epoch 68 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.11578947368421047, recall = 0.008043376994776755.\n",
            "Training on epoch 68 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 9e-06.\n",
            " Top K precision = 0.09473684210526313, recall = 0.008719689298399204.\n",
            "Training on epoch 68 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08571428571428566, recall = 0.0077253207532552975.\n",
            "Training on epoch 68 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09999999999999995, recall = 0.007515576288431253.\n",
            "Training on epoch 68 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08865979381443295, recall = 0.007337995661612136.\n",
            "Training on epoch 68 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.07741935483870967, recall = 0.007310744208811688.\n",
            "Training on epoch 68 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693154, and regularization loss is 7e-06.\n",
            " Top K precision = 0.06521739130434782, recall = 0.0047335635964373644.\n",
            "\n",
            "Training on 68 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999994, recall = 0.007549938205213293.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 69 epoch\n",
            "Training on epoch 69 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.08585858585858584, recall = 0.007936668751631928.\n",
            "Training on epoch 69 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09473684210526312, recall = 0.00771499069089092.\n",
            "Training on epoch 69 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.0927835051546391, recall = 0.008417611050197555.\n",
            "Training on epoch 69 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09787234042553188, recall = 0.008378042501938477.\n",
            "Training on epoch 69 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.09680851063829785, recall = 0.007306279729175076.\n",
            "Training on epoch 69 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08111111111111109, recall = 0.006434956324786847.\n",
            "Training on epoch 69 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693154, and regularization loss is 7e-06.\n",
            " Top K precision = 0.0783505154639175, recall = 0.008800544716030154.\n",
            "Training on epoch 69 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09157894736842105, recall = 0.007934128226443436.\n",
            "\n",
            "Training on 69 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08900000000000001, recall = 0.0075587721274747765.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08799999999999995, recall = 0.007526617786638764.\n",
            "\n",
            "Training on the 70 epoch\n",
            "Training on epoch 70 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.07472527472527471, recall = 0.007445772751298649.\n",
            "Training on epoch 70 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.08152173913043477, recall = 0.007542628049727712.\n",
            "Training on epoch 70 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08775510204081628, recall = 0.005810202017672069.\n",
            "Training on epoch 70 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.06781609195402297, recall = 0.006023410439504175.\n",
            "Training on epoch 70 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09387755102040814, recall = 0.006792869468484844.\n",
            "Training on epoch 70 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.0882978723404255, recall = 0.007197750923080105.\n",
            "Training on epoch 70 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.6e-05.\n",
            " Top K precision = 0.10879120879120874, recall = 0.00921599351913999.\n",
            "Training on epoch 70 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.0824175824175824, recall = 0.00768668288699846.\n",
            "\n",
            "Training on 70 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.007558772127474777.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 71 epoch\n",
            "Training on epoch 71 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09473684210526313, recall = 0.007339264862573991.\n",
            "Training on epoch 71 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.09052631578947368, recall = 0.0072067737434462695.\n",
            "Training on epoch 71 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09333333333333332, recall = 0.008856138804518939.\n",
            "Training on epoch 71 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08315789473684208, recall = 0.006511189002290112.\n",
            "Training on epoch 71 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09702970297029698, recall = 0.006927040557040257.\n",
            "Training on epoch 71 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.09361702127659571, recall = 0.007522427248793158.\n",
            "Training on epoch 71 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08484848484848484, recall = 0.006585130791518139.\n",
            "Training on epoch 71 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09489795918367343, recall = 0.0076116477206344445.\n",
            "\n",
            "Training on 71 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999993, recall = 0.007537938794141446.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 72 epoch\n",
            "Training on epoch 72 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.07472527472527471, recall = 0.006152294573829355.\n",
            "Training on epoch 72 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08709677419354836, recall = 0.008049817935400426.\n",
            "Training on epoch 72 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09062499999999996, recall = 0.009176901530825959.\n",
            "Training on epoch 72 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09684210526315785, recall = 0.008084220609991368.\n",
            "Training on epoch 72 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09270833333333328, recall = 0.0075283782277252255.\n",
            "Training on epoch 72 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.09565217391304345, recall = 0.007107201012572611.\n",
            "Training on epoch 72 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.11382978723404247, recall = 0.008139416281878193.\n",
            "Training on epoch 72 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09230769230769227, recall = 0.009491116790075162.\n",
            "\n",
            "Training on 72 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08799999999999994, recall = 0.007495480988234271.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08849999999999994, recall = 0.007549266424052723.\n",
            "\n",
            "Training on the 73 epoch\n",
            "Training on epoch 73 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.07555555555555556, recall = 0.00810927383095156.\n",
            "Training on epoch 73 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.07826086956521737, recall = 0.007083761757793667.\n",
            "Training on epoch 73 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08787878787878788, recall = 0.008296380327956985.\n",
            "Training on epoch 73 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.7e-05.\n",
            " Top K precision = 0.09347826086956515, recall = 0.007540245947903593.\n",
            "Training on epoch 73 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09702970297029695, recall = 0.007980156868993334.\n",
            "Training on epoch 73 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.09891304347826084, recall = 0.009188697810115611.\n",
            "Training on epoch 73 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
            " Top K precision = 0.09560439560439558, recall = 0.007057902382853472.\n",
            "Training on epoch 73 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08899999999999995, recall = 0.00796112480417445.\n",
            "\n",
            "Training on 73 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08949999999999997, recall = 0.00748938734786583.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08599999999999994, recall = 0.007454012791377817.\n",
            "\n",
            "Training on the 74 epoch\n",
            "Training on epoch 74 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 8e-06.\n",
            " Top K precision = 0.0851063829787234, recall = 0.005756891805952588.\n",
            "Training on epoch 74 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09898989898989896, recall = 0.00703509578879858.\n",
            "Training on epoch 74 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08571428571428569, recall = 0.007658462860524647.\n",
            "Training on epoch 74 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08617021276595745, recall = 0.00704854618660286.\n",
            "Training on epoch 74 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.0900990099009901, recall = 0.007028828914687364.\n",
            "Training on epoch 74 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.09417475728155336, recall = 0.00800976444356397.\n",
            "Training on epoch 74 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08999999999999997, recall = 0.007857762769672889.\n",
            "Training on epoch 74 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09583333333333333, recall = 0.009099776471981376.\n",
            "\n",
            "Training on 74 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999997, recall = 0.007558772127474776.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08499999999999995, recall = 0.007421858450541804.\n",
            "\n",
            "Training on the 75 epoch\n",
            "Training on epoch 75 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.10210526315789469, recall = 0.007439915883457791.\n",
            "Training on epoch 75 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08510638297872339, recall = 0.007109072253217954.\n",
            "Training on epoch 75 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.10306122448979584, recall = 0.008383837935884644.\n",
            "Training on epoch 75 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.07083333333333332, recall = 0.008166807444892914.\n",
            "Training on epoch 75 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.07777777777777777, recall = 0.005651572834654505.\n",
            "Training on epoch 75 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09399999999999997, recall = 0.008138855001537599.\n",
            "Training on epoch 75 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.10120481927710838, recall = 0.007561205676486959.\n",
            "Training on epoch 75 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08834951456310675, recall = 0.007933919185380915.\n",
            "\n",
            "Training on 75 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.0889999999999999, recall = 0.007558772127474775.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08599999999999994, recall = 0.007454012791377817.\n",
            "\n",
            "Training on the 76 epoch\n",
            "Training on epoch 76 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.0846938775510204, recall = 0.006873529357518733.\n",
            "Training on epoch 76 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
            " Top K precision = 0.09883720930232552, recall = 0.008456802418373134.\n",
            "Training on epoch 76 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.09239130434782605, recall = 0.008702329960850965.\n",
            "Training on epoch 76 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08526315789473682, recall = 0.0071474393640722274.\n",
            "Training on epoch 76 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.0978947368421052, recall = 0.008562861971951882.\n",
            "Training on epoch 76 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.10699999999999996, recall = 0.007430262311652713.\n",
            "Training on epoch 76 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08842105263157891, recall = 0.006106393786216321.\n",
            "Training on epoch 76 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.09299999999999997, recall = 0.007780644725036898.\n",
            "\n",
            "Training on 76 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999993, recall = 0.007492982653790566.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 77 epoch\n",
            "Training on epoch 77 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.09444444444444439, recall = 0.007925952399632757.\n",
            "Training on epoch 77 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.09789473684210521, recall = 0.007288880372925245.\n",
            "Training on epoch 77 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 8e-06.\n",
            " Top K precision = 0.09199999999999997, recall = 0.006591376219647555.\n",
            "Training on epoch 77 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09499999999999995, recall = 0.008481978834247488.\n",
            "Training on epoch 77 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09468085106382976, recall = 0.007321797003566882.\n",
            "Training on epoch 77 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.6e-05.\n",
            " Top K precision = 0.09347826086956515, recall = 0.008891494297069815.\n",
            "Training on epoch 77 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08709677419354835, recall = 0.007336507220740535.\n",
            "Training on epoch 77 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.09999999999999998, recall = 0.010038584576654935.\n",
            "\n",
            "Training on 77 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.0879999999999999, recall = 0.007537173855336548.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08599999999999994, recall = 0.007524943602726746.\n",
            "\n",
            "Training on the 78 epoch\n",
            "Training on epoch 78 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.08058252427184465, recall = 0.005997859293509925.\n",
            "Training on epoch 78 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693175, and regularization loss is 2.8e-05.\n",
            " Top K precision = 0.09569892473118276, recall = 0.008519423804719725.\n",
            "Training on epoch 78 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.09438202247191008, recall = 0.006770987454980925.\n",
            "Training on epoch 78 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.09278350515463912, recall = 0.00736185609692621.\n",
            "Training on epoch 78 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09999999999999992, recall = 0.00892910722331473.\n",
            "Training on epoch 78 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08602150537634408, recall = 0.0076620651371029315.\n",
            "Training on epoch 78 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08876404494382022, recall = 0.007775844307322135.\n",
            "Training on epoch 78 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.07745098039215682, recall = 0.00621558946886314.\n",
            "\n",
            "Training on 78 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.00755877212747478.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 79 epoch\n",
            "Training on epoch 79 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09622641509433956, recall = 0.007872032434293366.\n",
            "Training on epoch 79 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08775510204081631, recall = 0.008110520736346579.\n",
            "Training on epoch 79 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08020833333333331, recall = 0.006928301794749213.\n",
            "Training on epoch 79 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.08494623655913976, recall = 0.00889515128946257.\n",
            "Training on epoch 79 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08499999999999996, recall = 0.008316931711054102.\n",
            "Training on epoch 79 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08924731182795698, recall = 0.008797005612509373.\n",
            "Training on epoch 79 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08383838383838377, recall = 0.0070077078837022.\n",
            "Training on epoch 79 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08865979381443295, recall = 0.00832239255895612.\n",
            "\n",
            "Training on 79 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999998, recall = 0.007558772127474773.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08599999999999994, recall = 0.007400388767815259.\n",
            "\n",
            "Training on the 80 epoch\n",
            "Training on epoch 80 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.08478260869565214, recall = 0.008059274334654453.\n",
            "Training on epoch 80 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.10421052631578943, recall = 0.008996921409786446.\n",
            "Training on epoch 80 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.090625, recall = 0.008298241893117564.\n",
            "Training on epoch 80 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.1020833333333333, recall = 0.0075626558647928005.\n",
            "Training on epoch 80 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08229166666666664, recall = 0.008205886907690963.\n",
            "Training on epoch 80 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09183673469387751, recall = 0.008356002225036924.\n",
            "Training on epoch 80 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08631578947368418, recall = 0.008338734315591059.\n",
            "Training on epoch 80 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08709677419354839, recall = 0.009025852916728602.\n",
            "\n",
            "Training on 80 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.007558772127474776.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 81 epoch\n",
            "Training on epoch 81 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
            " Top K precision = 0.0911111111111111, recall = 0.006667003693412587.\n",
            "Training on epoch 81 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.10777777777777775, recall = 0.008185236882366415.\n",
            "Training on epoch 81 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.09799999999999998, recall = 0.006666550619781358.\n",
            "Training on epoch 81 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.0949494949494949, recall = 0.007411780329265771.\n",
            "Training on epoch 81 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.10312499999999995, recall = 0.008949222932356244.\n",
            "Training on epoch 81 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.06888888888888885, recall = 0.006107121408507003.\n",
            "Training on epoch 81 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.10326086956521735, recall = 0.008578355425964468.\n",
            "Training on epoch 81 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.09247311827956983, recall = 0.009448596003481944.\n",
            "\n",
            "Training on 81 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999991, recall = 0.0075587721274747765.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 82 epoch\n",
            "Training on epoch 82 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08947368421052627, recall = 0.006815903386433114.\n",
            "Training on epoch 82 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09247311827956985, recall = 0.008403580225588812.\n",
            "Training on epoch 82 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09263157894736837, recall = 0.007704327019510467.\n",
            "Training on epoch 82 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09684210526315787, recall = 0.007876105152297622.\n",
            "Training on epoch 82 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09999999999999994, recall = 0.00901920146375695.\n",
            "Training on epoch 82 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08695652173913043, recall = 0.006192228361484637.\n",
            "Training on epoch 82 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08999999999999994, recall = 0.007773240320994052.\n",
            "Training on epoch 82 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.6e-05.\n",
            " Top K precision = 0.09207920792079204, recall = 0.006910921914282087.\n",
            "\n",
            "Training on 82 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.007558772127474773.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 83 epoch\n",
            "Training on epoch 83 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
            " Top K precision = 0.07741935483870967, recall = 0.007844823182131488.\n",
            "Training on epoch 83 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.0845360824742268, recall = 0.007392893099887125.\n",
            "Training on epoch 83 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08510638297872336, recall = 0.006646097968976769.\n",
            "Training on epoch 83 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.09042553191489357, recall = 0.007347722407238679.\n",
            "Training on epoch 83 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.07692307692307693, recall = 0.007525711551852471.\n",
            "Training on epoch 83 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.10315789473684206, recall = 0.00855346634850942.\n",
            "Training on epoch 83 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.07708333333333332, recall = 0.006319537540536741.\n",
            "Training on epoch 83 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.10416666666666663, recall = 0.006148629230869166.\n",
            "\n",
            "Training on 83 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999997, recall = 0.007558772127474776.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08799999999999995, recall = 0.007526617786638764.\n",
            "\n",
            "Training on the 84 epoch\n",
            "Training on epoch 84 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693175, and regularization loss is 2.7e-05.\n",
            " Top K precision = 0.08061224489795916, recall = 0.005928224923783297.\n",
            "Training on epoch 84 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08453608247422675, recall = 0.00833065823134802.\n",
            "Training on epoch 84 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09999999999999998, recall = 0.008328208012318317.\n",
            "Training on epoch 84 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08924731182795698, recall = 0.0075827773872656845.\n",
            "Training on epoch 84 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08210526315789472, recall = 0.005661462821503478.\n",
            "Training on epoch 84 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09090909090909088, recall = 0.008040671933963746.\n",
            "Training on epoch 84 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09139784946236554, recall = 0.009343471576431124.\n",
            "Training on epoch 84 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08367346938775509, recall = 0.007353565131840989.\n",
            "\n",
            "Training on 84 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999991, recall = 0.007558772127474776.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08799999999999995, recall = 0.007526617786638764.\n",
            "\n",
            "Training on the 85 epoch\n",
            "Training on epoch 85 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.10404040404040399, recall = 0.00864829487419006.\n",
            "Training on epoch 85 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.07765957446808508, recall = 0.007813280156572042.\n",
            "Training on epoch 85 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.0914893617021276, recall = 0.008498111783296881.\n",
            "Training on epoch 85 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.08275862068965517, recall = 0.005813917663891361.\n",
            "Training on epoch 85 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693153, and regularization loss is 6e-06.\n",
            " Top K precision = 0.08541666666666665, recall = 0.007948762964580655.\n",
            "Training on epoch 85 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09787234042553193, recall = 0.00977517134188577.\n",
            "Training on epoch 85 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.08602150537634402, recall = 0.007238080391078751.\n",
            "Training on epoch 85 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.083695652173913, recall = 0.008319853336530706.\n",
            "\n",
            "Training on 85 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08799999999999995, recall = 0.007456731311148248.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08849999999999994, recall = 0.007549266424052723.\n",
            "\n",
            "Training on the 86 epoch\n",
            "Training on epoch 86 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.07894736842105263, recall = 0.008255666731739289.\n",
            "Training on epoch 86 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09680851063829783, recall = 0.009180986530875134.\n",
            "Training on epoch 86 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.07857142857142854, recall = 0.007718825505191884.\n",
            "Training on epoch 86 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.0782608695652174, recall = 0.007273482109029364.\n",
            "Training on epoch 86 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08888888888888888, recall = 0.007850484609429007.\n",
            "Training on epoch 86 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693175, and regularization loss is 2.7e-05.\n",
            " Top K precision = 0.08421052631578943, recall = 0.007744535959833576.\n",
            "Training on epoch 86 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09368421052631572, recall = 0.008406706290797528.\n",
            "Training on epoch 86 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08659793814432988, recall = 0.007473083721605081.\n",
            "\n",
            "Training on 86 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999994, recall = 0.0075345002828145794.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 87 epoch\n",
            "Training on epoch 87 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 9e-06.\n",
            " Top K precision = 0.09222222222222219, recall = 0.009367039378931333.\n",
            "Training on epoch 87 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08736842105263155, recall = 0.00807473461046344.\n",
            "Training on epoch 87 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.10319148936170204, recall = 0.00757818649545757.\n",
            "Training on epoch 87 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08514851485148513, recall = 0.007781902916770237.\n",
            "Training on epoch 87 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09021739130434782, recall = 0.008136182806736544.\n",
            "Training on epoch 87 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.0943181818181818, recall = 0.007566299197866952.\n",
            "Training on epoch 87 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08043478260869563, recall = 0.006924057605241116.\n",
            "Training on epoch 87 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.0949494949494949, recall = 0.007826090476551657.\n",
            "\n",
            "Training on 87 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.0885, recall = 0.007546606677353119.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 88 epoch\n",
            "Training on epoch 88 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.07448979591836732, recall = 0.00611196692559117.\n",
            "Training on epoch 88 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09894736842105258, recall = 0.006909751890414761.\n",
            "Training on epoch 88 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08210526315789471, recall = 0.007195155812988407.\n",
            "Training on epoch 88 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.07999999999999997, recall = 0.00848291608212186.\n",
            "Training on epoch 88 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08155339805825242, recall = 0.007336112361070254.\n",
            "Training on epoch 88 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08539325842696628, recall = 0.006944624867674027.\n",
            "Training on epoch 88 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.10721649484536078, recall = 0.009050189029622967.\n",
            "Training on epoch 88 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.07684210526315785, recall = 0.008790409790969405.\n",
            "\n",
            "Training on 88 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999997, recall = 0.0075587721274747765.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 89 epoch\n",
            "Training on epoch 89 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09999999999999999, recall = 0.008226355932806427.\n",
            "Training on epoch 89 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09578947368421048, recall = 0.006463683319688921.\n",
            "Training on epoch 89 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.07755102040816321, recall = 0.007502629869306846.\n",
            "Training on epoch 89 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.07789473684210524, recall = 0.00619156297482243.\n",
            "Training on epoch 89 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09247311827956983, recall = 0.007680447048140728.\n",
            "Training on epoch 89 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08924731182795696, recall = 0.008164273967707473.\n",
            "Training on epoch 89 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08541666666666663, recall = 0.008032804644336264.\n",
            "Training on epoch 89 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 9e-06.\n",
            " Top K precision = 0.09494949494949492, recall = 0.008166972896223845.\n",
            "\n",
            "Training on 89 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08699999999999994, recall = 0.0073790896559021504.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08849999999999997, recall = 0.007492982653790566.\n",
            "\n",
            "Training on the 90 epoch\n",
            "Training on epoch 90 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.07717391304347823, recall = 0.006888361093720686.\n",
            "Training on epoch 90 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08709677419354836, recall = 0.007022559459141406.\n",
            "Training on epoch 90 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.08399999999999996, recall = 0.007406136387173278.\n",
            "Training on epoch 90 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09569892473118272, recall = 0.00822418792904743.\n",
            "Training on epoch 90 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.07938144329896905, recall = 0.006353237983701536.\n",
            "Training on epoch 90 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693176, and regularization loss is 2.9e-05.\n",
            " Top K precision = 0.10752688172043005, recall = 0.008729895504844484.\n",
            "Training on epoch 90 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08958333333333329, recall = 0.008399636547941796.\n",
            "Training on epoch 90 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09484536082474222, recall = 0.007335866906001178.\n",
            "\n",
            "Training on 90 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.007558772127474776.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08799999999999995, recall = 0.007472993763076208.\n",
            "\n",
            "Training on the 91 epoch\n",
            "Training on epoch 91 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08181818181818179, recall = 0.007311386608906471.\n",
            "Training on epoch 91 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 8e-06.\n",
            " Top K precision = 0.09270833333333328, recall = 0.007769504362736272.\n",
            "Training on epoch 91 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.07849462365591398, recall = 0.007270920251396395.\n",
            "Training on epoch 91 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08555555555555552, recall = 0.008835170536791356.\n",
            "Training on epoch 91 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08369565217391303, recall = 0.0065058956624189.\n",
            "Training on epoch 91 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09354838709677417, recall = 0.006798394924275944.\n",
            "Training on epoch 91 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09411764705882351, recall = 0.007439798406634298.\n",
            "Training on epoch 91 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09793814432989686, recall = 0.008183128485246457.\n",
            "\n",
            "Training on 91 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08699999999999995, recall = 0.007437506621506319.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08799999999999995, recall = 0.00746994547862834.\n",
            "\n",
            "Training on the 92 epoch\n",
            "Training on epoch 92 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09270833333333332, recall = 0.007143628241553287.\n",
            "Training on epoch 92 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.0760869565217391, recall = 0.006760948722209284.\n",
            "Training on epoch 92 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.08602150537634405, recall = 0.006990332583973432.\n",
            "Training on epoch 92 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.0846938775510204, recall = 0.0080680093870039.\n",
            "Training on epoch 92 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.10102040816326525, recall = 0.007440759169474748.\n",
            "Training on epoch 92 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.10103092783505149, recall = 0.008409656848510258.\n",
            "Training on epoch 92 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.09899999999999996, recall = 0.0066819665805026695.\n",
            "Training on epoch 92 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.0852631578947368, recall = 0.008311559206446129.\n",
            "\n",
            "Training on 92 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08799999999999994, recall = 0.0073796867421214015.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 93 epoch\n",
            "Training on epoch 93 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09603960396039594, recall = 0.00827033846116447.\n",
            "Training on epoch 93 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09361702127659573, recall = 0.0077665783872911.\n",
            "Training on epoch 93 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.07777777777777772, recall = 0.006499211569031326.\n",
            "Training on epoch 93 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08155339805825236, recall = 0.008186173854769021.\n",
            "Training on epoch 93 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09239130434782607, recall = 0.007932979097658294.\n",
            "Training on epoch 93 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
            " Top K precision = 0.10425531914893618, recall = 0.008892185185529524.\n",
            "Training on epoch 93 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.07931034482758618, recall = 0.007868533869308126.\n",
            "Training on epoch 93 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08387096774193546, recall = 0.006791974138821234.\n",
            "\n",
            "Training on 93 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999994, recall = 0.007537938794141441.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 94 epoch\n",
            "Training on epoch 94 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09999999999999994, recall = 0.0083809309156996.\n",
            "Training on epoch 94 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693184, and regularization loss is 3.6e-05.\n",
            " Top K precision = 0.0826086956521739, recall = 0.007612756100247958.\n",
            "Training on epoch 94 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08571428571428565, recall = 0.008656021155591607.\n",
            "Training on epoch 94 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08469387755102036, recall = 0.009199301357328537.\n",
            "Training on epoch 94 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.10978260869565216, recall = 0.007741809493582289.\n",
            "Training on epoch 94 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.075, recall = 0.005617526925134142.\n",
            "Training on epoch 94 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.0835164835164835, recall = 0.007171961752604637.\n",
            "Training on epoch 94 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08350515463917521, recall = 0.007163622071349367.\n",
            "\n",
            "Training on 94 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.0885, recall = 0.007545035863738514.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 95 epoch\n",
            "Training on epoch 95 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08695652173913042, recall = 0.007504406189296788.\n",
            "Training on epoch 95 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.0939393939393939, recall = 0.007803459082053041.\n",
            "Training on epoch 95 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.0864583333333333, recall = 0.008868356202183151.\n",
            "Training on epoch 95 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08799999999999995, recall = 0.00815311836903067.\n",
            "Training on epoch 95 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08705882352941176, recall = 0.006115514629418735.\n",
            "Training on epoch 95 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09489795918367344, recall = 0.006766337351429045.\n",
            "Training on epoch 95 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
            " Top K precision = 0.08556701030927832, recall = 0.006927936444171735.\n",
            "Training on epoch 95 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08617021276595745, recall = 0.00830706689360904.\n",
            "\n",
            "Training on 95 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.007558772127474773.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 96 epoch\n",
            "Training on epoch 96 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08899999999999997, recall = 0.006707400989076743.\n",
            "Training on epoch 96 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09468085106382976, recall = 0.008005424911908471.\n",
            "Training on epoch 96 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.07978723404255317, recall = 0.005938757104893802.\n",
            "Training on epoch 96 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.0989361702127659, recall = 0.008843329329493473.\n",
            "Training on epoch 96 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.10699999999999994, recall = 0.009205350898947678.\n",
            "Training on epoch 96 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.08989898989898985, recall = 0.007123028214682875.\n",
            "Training on epoch 96 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09368421052631576, recall = 0.008339320283464246.\n",
            "Training on epoch 96 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.07934782608695651, recall = 0.007522799414539147.\n",
            "\n",
            "Training on 96 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.007558772127474776.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08599999999999994, recall = 0.007454012791377817.\n",
            "\n",
            "Training on the 97 epoch\n",
            "Training on epoch 97 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.07126436781609195, recall = 0.006546405261975158.\n",
            "Training on epoch 97 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
            " Top K precision = 0.0914893617021276, recall = 0.007510837440357608.\n",
            "Training on epoch 97 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.10777777777777774, recall = 0.008209547536593203.\n",
            "Training on epoch 97 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.0943181818181818, recall = 0.009288125140966151.\n",
            "Training on epoch 97 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.07187500000000001, recall = 0.0064551533538189515.\n",
            "Training on epoch 97 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08494623655913972, recall = 0.008232142749501053.\n",
            "Training on epoch 97 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09574468085106379, recall = 0.00671565029534167.\n",
            "Training on epoch 97 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09183673469387751, recall = 0.00728145842389854.\n",
            "\n",
            "Training on 97 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.007558772127474777.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 98 epoch\n",
            "Training on epoch 98 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693177, and regularization loss is 3e-05.\n",
            " Top K precision = 0.10412371134020616, recall = 0.007184350836860045.\n",
            "Training on epoch 98 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.07959183673469383, recall = 0.006898971399242608.\n",
            "Training on epoch 98 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.0717391304347826, recall = 0.006362149766422351.\n",
            "Training on epoch 98 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09569892473118276, recall = 0.008343406193273119.\n",
            "Training on epoch 98 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.09787234042553189, recall = 0.008510681142995026.\n",
            "Training on epoch 98 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09052631578947361, recall = 0.007642929318877833.\n",
            "Training on epoch 98 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.0833333333333333, recall = 0.007765329649487282.\n",
            "Training on epoch 98 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08599999999999994, recall = 0.007038951363608073.\n",
            "\n",
            "Training on 98 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.088, recall = 0.007610894242143431.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08849999999999997, recall = 0.007617004302157751.\n",
            "\n",
            "Training on the 99 epoch\n",
            "Training on epoch 99 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.0831578947368421, recall = 0.005181408288722896.\n",
            "Training on epoch 99 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.10707070707070701, recall = 0.008045920989883375.\n",
            "Training on epoch 99 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08124999999999995, recall = 0.007758669599894207.\n",
            "Training on epoch 99 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.0741573033707865, recall = 0.006562410291396384.\n",
            "Training on epoch 99 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08817204301075267, recall = 0.006315794280105545.\n",
            "Training on epoch 99 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09693877551020402, recall = 0.007478640586094088.\n",
            "Training on epoch 99 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.09899999999999996, recall = 0.006646524209498519.\n",
            "Training on epoch 99 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.0824175824175824, recall = 0.007153817294441674.\n",
            "\n",
            "Training on 99 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999998, recall = 0.0075450358637385116.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "root = os.getcwd()\n",
        "movielens = MovieLens(root=root, transform=trans_ml)\n",
        "data = movielens.get()\n",
        "train_mask, val_mask, test_mask = \\\n",
        "        movielens.train_val_test_split(val_frac=config_dict[\"val_frac\"],\n",
        "                                       test_frac=config_dict[\"test_frac\"])\n",
        "\n",
        "n_users = len(data[\"users\"].unique())\n",
        "m_items = len(data[\"items\"].unique())\n",
        "print(f\"#Users: {n_users}\")\n",
        "print(f\"#Items: {m_items}\")\n",
        "\n",
        "model_config = {\n",
        "    \"n_users\": n_users,\n",
        "    \"m_items\": m_items,\n",
        "    \"embedding_size\": config_dict[\"embedding_size\"],\n",
        "    \"num_layers\": config_dict[\"num_layers\"],\n",
        "}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "lightGCN = LightGCN(model_config, device=device)\n",
        "\n",
        "num_samples_per_user = config_dict[\"num_samples_per_user\"]\n",
        "epochs = config_dict[\"epochs\"]\n",
        "batch_size = config_dict[\"batch_size\"]\n",
        "lr = config_dict[\"lr\"]\n",
        "weight_decay = config_dict[\"weight_decay\"]\n",
        "\n",
        "K = config_dict[\"K\"]\n",
        "\n",
        "lightGCN.to(device)\n",
        "\n",
        "samples_train, samples_val, samples_test = \\\n",
        "        sample_pos_neg(data, train_mask, val_mask, test_mask,\n",
        "                       num_samples_per_user)\n",
        "\n",
        "samples_train=samples_train.to(device)\n",
        "samples_val=samples_val.to(device)\n",
        "samples_test=samples_test.to(device)\n",
        "train_mask=train_mask.to(device)\n",
        "val_mask=val_mask.to(device)\n",
        "test_mask=test_mask.to(device)\n",
        "data = data.to(device)\n",
        "\n",
        "print(f\"#Training samples: {len(samples_train)}\",\n",
        "      f\"#Validation samples: {len(samples_val)}\",\n",
        "      f\"#Test samples: {len(samples_test)}\")\n",
        "\n",
        "optimizer = optim.Adam(lightGCN.parameters(), lr=lr)\n",
        "print(\"Optimizer:\", optimizer)\n",
        "\n",
        "epochs_tracked = []\n",
        "train_topks = []\n",
        "val_topks = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(\"Training on the {} epoch\".format(epoch))\n",
        "    lightGCN.train()\n",
        "    loss_sum = 0\n",
        "    # Shuffle the order of rows.\n",
        "    samples_train = samples_train[torch.randperm(samples_train.size()[0])]\n",
        "    for batch_idx in range(math.ceil(len(samples_train) / batch_size)):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        current_batch = \\\n",
        "            samples_train[batch_idx*batch_size: (batch_idx+1)*batch_size]\n",
        "        # Shuffle the order of rows.\n",
        "        current_batch = current_batch[torch.randperm(current_batch.size()[0])]\n",
        "        users = current_batch[:, 0:1]\n",
        "        pos = current_batch[:, 1:2]\n",
        "        neg = current_batch[:, 2:3]\n",
        "\n",
        "        # tính toán mất mát\n",
        "        loss, reg_loss = bpr_loss(lightGCN, users, pos, neg, data,\n",
        "                                  train_mask)\n",
        "\n",
        "        reg_loss = reg_loss * weight_decay\n",
        "        loss = loss + reg_loss\n",
        "        loss_sum += loss.detach()\n",
        "\n",
        "        # cập nhật tham số mô hình\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % config_dict[\"minibatch_per_print\"] == 0:\n",
        "            all_users = torch.linspace(start=0,\n",
        "                                       end=n_users - 1, steps=n_users).long()\n",
        "            user_indices = current_batch[:, 0]\n",
        "            user_indices = user_indices.repeat(2).long()\n",
        "            item_indices = torch.cat(\n",
        "                (current_batch[:, 1], current_batch[:, 2])).long()\n",
        "            pred = getUsersRating(lightGCN,\n",
        "                                  all_users,\n",
        "                                  data)[user_indices, item_indices]\n",
        "            truth = data[\"edge_index\"][user_indices, item_indices]\n",
        "            topk_precision, topk_recall = \\\n",
        "                personalized_topk(pred, K, user_indices, data[\"edge_index\"])\n",
        "\n",
        "            print(\"Training on epoch {} minibatch {}/{} completed\\n\".format(epoch, batch_idx+1,\n",
        "                                                                            math.ceil(len(samples_train) / batch_size)),\n",
        "                  \"bpr_loss on current minibatch is {}, and regularization loss is {}.\\n\".format(round(float(loss.detach().cpu()), 6),\n",
        "                                                                                                 round(float(reg_loss.detach().cpu()), 6)),\n",
        "                  \"Top K precision = {}, recall = {}.\".format(topk_precision, topk_recall))\n",
        "\n",
        "    if epoch % config_dict[\"epochs_per_print\"] == 0:\n",
        "        epochs_tracked.append(epoch)\n",
        "\n",
        "        # evaluation on both the trainisng and validation set\n",
        "        lightGCN.eval()\n",
        "        # predict on the training set\n",
        "        users = samples_train[:, 0:1]\n",
        "        user_indices = samples_train[:, 0]\n",
        "        user_indices = user_indices.repeat(2).long()\n",
        "        item_indices = torch.cat(\n",
        "            (samples_train[:, 1], samples_train[:, 2])).long()\n",
        "        pred = getUsersRating(lightGCN,\n",
        "                              users[:,0],\n",
        "                              data)[user_indices, item_indices]\n",
        "        truth = data[\"edge_index\"][users.long()[:,0]]\\\n",
        "            [user_indices, item_indices]\n",
        "        train_topk_precision, train_topk_recall = \\\n",
        "            personalized_topk(pred, K, user_indices, data[\"edge_index\"])\n",
        "        train_topks.append((train_topk_precision, train_topk_recall))\n",
        "\n",
        "        # predict on the validation set\n",
        "        users_val = samples_val[:, 0:1]\n",
        "        pos_val = samples_val[:, 1:2]\n",
        "        neg_val = samples_val[:, 2:3]\n",
        "\n",
        "        loss_val, reg_loss_val = bpr_loss(\n",
        "            lightGCN, users_val, pos_val, neg_val, data, val_mask)\n",
        "        reg_loss_val = reg_loss_val * weight_decay\n",
        "\n",
        "        # predict on the validation set\n",
        "        user_indices = samples_val[:, 0]\n",
        "        user_indices = user_indices.repeat(2).long()\n",
        "        item_indices = torch.cat((samples_val[:, 1], samples_val[:, 2])).long()\n",
        "        pred_val = getUsersRating(lightGCN,\n",
        "                                  users_val[:,0],\n",
        "                                  data)[user_indices, item_indices]\n",
        "        truth_val = data[\"edge_index\"][users_val.long()[:,0]]\\\n",
        "            [user_indices, item_indices]\n",
        "        val_topk_precision, val_topk_recall = \\\n",
        "            personalized_topk(pred_val, K, user_indices, data[\"edge_index\"])\n",
        "        val_topks.append((val_topk_precision, val_topk_recall))\n",
        "\n",
        "        print(\"\\nTraining on {} epoch completed.\\n\".format(epoch),\n",
        "              \"Average bpr_loss on train set is {} for the current epoch.\\n\".format(round(float(loss_sum/len(samples_train)), 6)),\n",
        "              \"Training top K precision = {}, recall = {}.\\n\".format(train_topk_precision, train_topk_recall),\n",
        "              \"Average bpr_loss on the validation set is {}, and regularization loss is {}.\\n\".format(round(float((loss_val+reg_loss_val)/len(samples_val)), 6),\n",
        "                                                                                                      round(float(reg_loss_val/len(samples_val)), 6)),\n",
        "              \"Validation top K precision = {}, recall = {}.\\n\".format(val_topk_precision, val_topk_recall))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhWgVYTn6F05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "1ea4c539-5e9d-423b-d710-d8ef3f267745"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB1mklEQVR4nO3dd3xT1fsH8M9N0qaDTkoXFChtoZRRNrSggBQLsgr4ExG1IAoiG0XBAThRFMSB+MW9EEQFAQEtCIjsVWbZq0AHBbrpSu7vj5ukSZuWpqS5HZ/365VX25uTm5PbNvfJc55zriCKoggiIiKiOkQhdweIiIiIbI0BEBEREdU5DICIiIiozmEARERERHUOAyAiIiKqcxgAERERUZ3DAIiIiIjqHJXcHaiOtFotrl+/DhcXFwiCIHd3iIiIqAJEUURWVhb8/f2hUJSf42EAZMb169cREBAgdzeIiIioEhITE9GoUaNy2zAAMsPFxQWAdABdXV1l7g0RERFVRGZmJgICAgzn8fIwADJDP+zl6urKAIiIiKiGqUj5CougiYiIqM5hAERERER1DgMgIiIiqnMYABEREVGdwwCIiIiI6hwGQERERFTnMAAiIiKiOocBEBEREdU5DICIiIiozmEARERERHWO7AHQkiVL0LRpUzg4OKBr167Yt29fue1XrVqF0NBQODg4oE2bNtiwYYPJ/SkpKRg9ejT8/f3h5OSEfv364ezZs1X5EoiIiKiGkTUAWrlyJWbMmIG5c+fi0KFDCA8PR3R0NFJTU82237VrF0aOHImxY8fi8OHDiImJQUxMDI4fPw4AEEURMTExuHDhAv744w8cPnwYTZo0QVRUFHJycmz50oiIiKgaE0RRFOV68q5du6Jz58749NNPAQBarRYBAQGYPHkyZs2aVar9iBEjkJOTg/Xr1xu2devWDe3atcPnn3+OM2fOoEWLFjh+/DhatWpl2Kevry/eeecdPP300xXqV2ZmJtzc3JCRkcGLoVZTdwo0cLRXyt0NIiKqRiw5f8uWASooKMDBgwcRFRVV3BmFAlFRUdi9e7fZx+zevdukPQBER0cb2ufn5wMAHBwcTPapVqvx33//ldmX/Px8ZGZmmtyo+tpwLAkt52zCkq3n5O4KERHVULIFQGlpadBoNPDx8THZ7uPjg+TkZLOPSU5OLrd9aGgoGjdujNmzZ+P27dsoKCjAe++9h6tXryIpKanMvsyfPx9ubm6GW0BAwD2+OqoqoigaAp/Fm8/gXGq2zD0iIqKaSPYiaGuys7PD77//jjNnzsDT0xNOTk7YunUr+vfvD4Wi7Jc6e/ZsZGRkGG6JiYk27DVZ4sjVDJy4LmXoCjUi5vxxHDKO4hIRUQ0lWwDk5eUFpVKJlJQUk+0pKSnw9fU1+xhfX9+7tu/YsSPi4+ORnp6OpKQkbNq0CTdv3kSzZs3K7ItarYarq6vJjaqnH/dcBgB0D64PtUqBXedvYu2R65XbmSgC5/8B0m0T8J5LzcLBy7ds8lw1QcadQmxJSEF+kcbq+068lYud59IYHNdwZ1OycOjKbbm7QbWUbAGQvb09OnbsiC1bthi2abVabNmyBREREWYfExERYdIeAOLi4sy2d3NzQ4MGDXD27FkcOHAAQ4YMse4LIJvLyC3EOl2wM6NvC0zqHQwAeOvPBGTmFVq2s8I7wG9PAz8MBZZGAmf+tnZ3TfyyPxH9P9qBR/63B5dvckbi6eQsDPxkB8Z+dwAj/rcHqZl5Vtv3XyeSEb34X4z6ci9m/nq0SgIsqnrZ+UUYtnQXhn22Cwv/Pg2tlsEsWZesQ2AzZszAF198ge+++w4JCQmYMGECcnJyMGbMGADAk08+idmzZxvaT506FZs2bcLChQtx6tQpzJs3DwcOHMCkSZMMbVatWoVt27YZpsL37dsXMTExePDBB23++si6fjt0FflFWoT6uqBDY3eM69kMzbyccSMrH4v+PlPxHWVcA77uBxz/Vfo5PxNY/gjw32IpK2RFRRotXl93Ai/+dhSFGhEarYi4kyl3f2At9veJZAz7bCcSb90BAMQnpmPQp//hSGL6Pe1XFEV8suUsxv9wELkFUtDz68GrGLlsD1KzrBdgkW2sPnwNWXlFAIBP/jmH8T8eRHZ+kcy9otpE1gBoxIgR+OCDDzBnzhy0a9cO8fHx2LRpk6HQ+cqVKybFy5GRkVi+fDmWLVuG8PBw/Prrr1izZg1at25taJOUlIQnnngCoaGhmDJlCp544gn8/PPPNn9tZF2iKOKnvdLw16huTSAIAtQqJd4YIv3uv999CcevZdx9R4n7gGW9gKR4wNETeGI10CEWgAhsngv8Pk7KDllBem4BRn+zH9/svAQA6NDYHQDqbAAkiiI+/ecsxv1wEDkFGkQ0q4/Vz0Ui2LseUjLz8cj/duOP+GuV2nduQREmLT+MhXFSIDw6sim+GdMZrg4qHLqSjsGf7MTRq+lWfDVUlURRxE+64e6olt6wVykQdzIFwz7biSs3c2XuHVmFVit3D+RdB6i6suk6QAnrgBOry22SkpmHq7fvflK2UyoQ7F0PTmWsj5OeW4jE27loWt8ZLg4qs22y84twMS0HjTyc4OFkV3yHZxBw3wzAzhEpmXn4eudFDGjjh7aN3M3uJ78gH0e/fwmqRuFo32+M2TZ5udk4tnIeVN7N0X7AuHJf254LN/Hosj1wsldi37Rw1Nv/KdDlGcCjKSb/fBjrjlxHk/pOZfYHALpmbMSIlEWwEwtxzb4Zvmj4Nm7a+wGiiPvS12B46idQQovr9oFIUgeaPjjkQXQcPKHcPhpLvJWLJ77ai0s3c+Fkr8SiR9qhc8Ym7Ny0AgKA6Fa+sFeV/vyRkpmHY1ku+Lv+KNxRupjdd4ucAwjL2Yc/vUajQOFk2H5fsBf+r1MjCIIA3DgDHPwG6D4NcPFBkUaLr/67iOPXTZd4UKsUmNArCEEN6pl/IRlXgd1LgLaPAP7tzbcpKgC2vA5kFX9YuZVTgGPpaqz1GosChaP02jLysO+SVAMVG9EErw4Mg51Sgay8QkxdEY9/TqXicWUcgn3ccLBBjGFfDioFnusdjEAvZ/NdvHUDO/43FdrcW1AIQJuG7mhS3wlwb4yLbWfg6R8O4fyNHKhVCkSF+UAhCIbH1ne2x3O9g+Dt4iBl//Z8BtQPAZpXPmMsiiJ2rl4Kx4txJtsFAQis7wwPZ/vije5NgAdeBRTm/2f3XbyFTceTMaFXEBq4qIGCHOC/DwHPZkD4SGmnJZ+/qAD7f34Deer66PHwNCgUpdtotSJ2rf4U3sn/IqhBPSjNtAGAq7fvIDu/CC18XMw9VTGn+kCfOYDaBTn5Rfhs2zlcuVX8ntUo7wwezPwNzb0c4aw2eq0BXYHOzwAlJqkcvHwbw5fuglqlwL6Xo3DxZg7GfX8AqVn5cHeyw30hDUzaN/JwxMTewainVgGaQuDf94HgvkBAZ7PdLSzS4L/v5+CktjFOOXcp82X1vvULmuSdKueFS66pgxDn+ZjZ34fhpXo4Ynrf5rBTlpF3OL0JOP4bIJY9ZHszuwAXslVoMfxVuPoFm22TnJGHL3ZcwPj7m8Hb1cFsG2SlAFvfkv6eLJCckYdT2U74w+sZFCnszbZplHcWPXL+RtjQWfBoaL6PuH4YWD0BeOQ7oEELi/pwN5acvxkAmWHTAGhhSyCrkkW8tubXDid6fo4xv11DalY+GrioseX5nnB1sCvV9PdfvsWwk1MBAHt8HkWnpz+Byq74Hyb12kWkf/MImhedQYGoxPnH96FlSBn/LIAhyBnZpTHme24Atr0DNOsNPLkGKZl56LNwe5npcSU0mK1ajqdVGwEAmzSdMaNwAnJh+uYQoTiBz+w+godQemq9RhSQFbsZ7s063fUwiaKIx77Yi90XbqKhuyO+jO2EluJ54IsHALFin3rOa/3wdOELuCj6Ge8ZE5TrMFO1EgpBxPMFz+I37f0mjxveoRHeHtoaDn9OBuJ/Anq9jPQu0zFp+WH8dy7N7HP1btEA34wxcxK4shdYOQrIuQE0vQ8Yvb50G0B60/71KbN3TSmYiLXa7oafVQoBbwxpjce6NjZpp9GK+OH3NRh9fDQAYFTBbOzUtjHcPyjcH5+MNB+A7fh+Hu678KH5vj3+OzIb3Y+pPx/G1tM3zDbxc3PAsic6oY1wHviiN+DgDrx4sdRJuSJyC4rw0i+H8MHZh6AWKliX9sQaIKh3qc1arYj739+Kq7fvwM/NAd8O9UWLreOBlGNSg/ZPAAMWAip18YNybiLrx8fgkrQHRaICU5quxYLHIqTAwKiPL648gIXnBkAtWHFIqcs4JHZ7Hc98fwCnkrMMm9UowN/2L6KJwvwK/2gxABj2P0BdHPDP+CUevx+6hoc7NsIH/xcOQDr5jv/hAI5cNZ/pbeHjgi9jOyHg6nrg92cAv3Bg/L9m26774xcMOvwMboiu6Jy/FEDpwKWJkIzt6hkVfPHApILJWK81X7+q98pDLfHM/SUm5Gi1wLb5wL8LKvxcuSp3OD3+E9C0R6n7ZqyMx++Hr+GRTo2w4OFw8zv4eSRweoP5+ypgcsEkrNNGmr3vG7v30Ft5BFlKN7g8uQJoUqLdsV+BPyYCRXlA837AYysr3Q9zLDl/m08DkO0U6iLw+14AnBuUunvVwUScuJ4JPzcHhAe4l70fETiceBspmflQKgQMbOuH9gEe0IoitiSkYOf5mwAAJ3slcgs0EASgT6gPugfXBwDsPn8TcQkpEMXiNgDQrVl99G3uDuWuj4CkeDT4uR8aFkxHKkIMtTfzBrcy6cqFG9k4fewAoPug1y1lBY4uPIsm41bCzbMBTh/4B57rn0JzSLM77AUN9q/5BC2eX2z202padj42HZeyC6O6Ngb2XtA90Vbg5nn41A/CyvHdsO9i6RlW9oWZ6HXsJTS8KS2WGR84DklBz2KmYO7kFoa/8+5H4xvbIBh9CrM79xc6ao4gb810YNr2u54Y1x65jt0XbsLBToEV47ohwF0NfDkDELW45N4V395ogTB/VzzS0XS9qfjEdKyLT8QzdpsQpEjCJue52NZmAa57RUKpuYPuJ19HUPImQ/snWmjROjgMAJCSmY8vdlzAb4eu4vyNbPxifx72ALKuHseQ/TtxWZeJmtAzCPV02b+8Qi3e23QK287cQOKtXAR4FmeTcOgHYP10QKs7iV/dDxTlm55s9S7pFhkNegAIiYYIEcc2fYm2OIfhIUq0bx5maBoRVB+hvqXflJQKAaPttxp+/sx9OdZErEJqroglW89j2+lUFBRpzWbNtNcOAQASffogoL0uc3P8N+DqPuD6IbgG98GXsZ3x14lkpBgVW4si8NPeyzh/IwcPf74LK7pcRHsAyEsHbl8E6geVfq3luJZ+B898dwB5yaegVheiUKHGwZCphvt3n7+JjDuF6B7shb4tfaQatKv7geuHzAZA/569Ycj8NsqMh9fPiwEhUwrQ8jOBwz8AaWeBET8A9byBlBPAz4/CJf0KAEAlaHHpzFEM+0yLL57shCb1nXH1di6e+f4gCpIToFYXIVdUY0HRCLg52GFElwD4uzkip6AIqw4k4pLRUFOPYC9EtfQp1UcAwJ1bwPb3IO7/ErMOBOFUbgC86qkx/v5mUCkFtDv/GZpcSMVNRX18kj8ACkFAv9Y+6OwNCDs/Ak7/CXz1IDDyZ8CjKdJzC7D+qNH/u46vmwNWjo/AhmNJyLhTHFwWaUQs23EBp1OyMPjT/7Ch+U74AdLxKLwD2DmadPd6+h2cPrgNgxRAAyETC6I8kOPoX+plBSZdBo4DGU6NkRDwaJm/d6/MEwhO+hML6q1At+4jUKgqnU29lJaD73Zfxoebz2BguB/83HR9ys8CVj8LnNJ9uOgQC3iHmTy2SCti4/EkHLwsvV8OV/6LNkWXgO+HAA+9D3Qq/vBRpNHin9NSoLklIRUarVg6u3dqgxT8KFRS1k5p5n/aSH6RBr8fuobTKVmIUhxED+UJjA/OQIcWYaUbiyK6bb8MFAIumgxovx0ExcCFQMfRUqC39S1gx0KpbXBfYNiycp+7qjEAkpt+HLTdY6XecLefuYGZifugVAhY/0QPtPQrP5ptk1+EGb/E468TKfjqIDBa3RSXbuZg2xnpk++k3sGY3CcYr687ieV7r+Cb48AQlT+UCgG/H5NqL0Z0CsCsIa2wdNt5fLTlLL49C9wHL3QNbo2oI9MQqkjEL+q3cKrzmxi0ozG+330JD3dshNYN3QBI2Y85f5zAQ6K0v1teneBw4xja5h1E4if3I6HZ/6H9uc+gFgpxSdEY9m2Gwv/IR+id9SdW7JuOx7o1LfW6Vh24ikKNiPAAd+l5MoymrR/8FnjwTbTyd0MrfzfTB944A/w8Brh1HlA5AkOXol2roWhX7lEMBNDNZMu6HdFosXkAfDOPQnvoByg6xZb56My8Qry5PgEAMPmBECmo2P+VdJJTuyKn/6f49puzcE5RYkinvlCriocD3ji0E4c06Wh4/5N46uprUCfuRXT8JKDnLOkNKzleetPybw9c3Y92rllo1714qK5HsBcmLj+E+MR03HQ4Bz8AV88exeX83OJMVIm/oV3n07DjbBpW7L+CmdGhgKYI+PtVYO9SqUHLwcCV3VIW6NohoImZT7iXd0lfOz0FtByEpPQ72Lv+X7RVnUMPPy16GvWxTHkZ0idDALBzhlvuZcRq10Lb9wWs3J+ItOwC7L90C92DvUwelpKZh4A7pwEF4NJjHNCmn3SHqNEFQPEApADroTZ+KOnhTo0M2aFd+3ajvf4d8fphiwKg/Zdu4dkfDuJmTgGGOt0AtICdd3N0G/mKoU32yRQ8/f0B/HhWwMaH7kOItlAXAB02u8+f9kqBzPuBhzE06UOoUITj2qbYGfYxngktgOK3sUDiHmBZbyDiOeCft4HCHFwRvaERBQQqUtDOKQ3LU7IxZMlOTHkgBJ9uPYdbOQUYruuj0rs5/r0zHBfScvC//xR44cEW+Hb3JVy9HYh6ahX6hvlg9eFrOJ7ngahu5j/xA8DFM8cQmLQBMzX/Q7b/Ynwe20U6yd88D/zzLQDAJeYDZCQ0w+rD1/B1PDCyS2O88WRf2K16Akg9Kb2OR77Dr1cboaBIizA/V7Qr8aHPwU6JYR0alXr+QeH+GPfDARy9moHrJ3fBTwFAWyQFQY1Ms7ZvrDuJgeJ5w8+P+KcBYd1Ryl/Se5hbq2h0G/BK6fv1CvOApZFwunUej99ZDvSbX6qJVivixPVMHLh8G2+uP4nPRnUEbl+SMjGpJwGlPTDoY6DdSJPHpWXnY8KPB7H/UmMIgvQePmJrb7yrWobB2C19SEk+DvR/D1Da4eDl20jPlYLDmzkFiE9MR8cmHsU7LMgFNr4kfR85Geg+FeW5cjMXT3+/H2dSmsJepcDAji2A+FfQWriA1ub+r9OvAJvToYESGzWdMFC5F1g3FUg+Jk0+ObNR99xTcLXji2jkYH6Y31Zq1UKINZJWl4JWmMaieYUazP1Dusjr6Mimdw1+AMBZrcLSUR0xtU8IAODbXZew7fQNqFUKfDyyPV6IbgG1Sol3hrbBmzGtoVQI+CP+On4/dA1KhYB5g8Lw7vA2cLBTYnrf5vhsVAc42imx42waPtifj+EF83DWoyfsUIg2+2dhQeN90IrAK2uOG6ao/nksCf+dS0OQUvoE53nfM0gavgbJaIAA8Tq6nf8IaqEQh50i4TXtX/gPmIV8lQsCFDewY9NKpGXnm7ymlMw8/LD7EgCjT4PG6/Yc/lHKTJSUfBz4so8U/Lg2Asb+BbQaetdjaE6fru2wRBgBAND8PQfIuVlm24V/nUZadj6aNXDG0/cFAtk3pPoYAHjgNbQMCYG3ixo5BRrsuVCcsTp5PROHrqRDpRAwMDIciF0HtHtcGjLb9o5R0fYaoMv40scBQI8QL6yZ2B3NGziigSjtuwmS0LWpO9ZO6m72b0h/TFfuT0RBkRZYPa44+Ok1G/i/74AmupPDZTOXk8lJA27oaiQaSyfI08lZSBOlYFR5p+xjZeLoL1I21KsFMOgjaduOD6BIv4Q+oVLmwVzx+L9Hz6GZQloJ3j3IaBhPX69URnCh5+pghy9jO2N8z2ZoJhTXMP3w+xp0eDOuwrdHl+3BzZwChPm5Yl6kbqi3fojJc0WF+SCqpQ+KtCJeXXMcol87XR/jS/UrKeMOtiSk4Gnln/i/pPehQhFOevbBwwVzMX9XNl443AB4ZgtQPxjIvAr89TJQmIPrnl0wOP9NnHWQJgfM7qJCeCM3pOcW4o31J3ErpwCt/F0xJ0Iatlb7tMDq57rj/uYNkFeoxVt/JuDq7TtoUt8Jq5+LxLQo6TUcuZqOvELztSlLt53HIxcHIFN0RDvFBazqclYKfkQR2PACoCkAgvrAvs1QLHokHLP7h0IQgJ/3XcGojRrcHvWX9Pu6cwvi9zE4s/MPAMCobo2lerYK8HVzwC/jIzA03BthwiXDds3Vgybttp5KxaYTyWijuFC8say/Ef32smrf9OwcpEwMAOz9HEg6WqqJQiEY3nM3HEtG/L9rpYAv9SRQzweFT6zHG4nh6PTWZpO/qx7v/YP9l27DRa3C17Gd8fyDLdC6iR+mFE7CoZApAATgwFfSch45N7E5wfR/pOTP2PEBkHEFcAsA7p9p2JydX4QZK+PRscTfddSH23EmJRveLmqsHNcNnSL7SA9IOgJozfw96I+ZTyu8oZ6J9wsfkX7e/6UU/CjVEGM+x3f1xqLXwh3YcKzsKzTYAgMguemHWkoUQf5v+wVcupkLH1e14U2oIhQKwRC8ONkr4efmgF+fjcTgcNMU7xPdmuCHsV3g6WwPdyc7fDemC0Z3DzR5w3mojR9+nRCBhu6OcLBTYP7ISIRMXgN0ew4AMFTYinpqFY4kpuPn/VeQlVeIN9adBAC0tteN99cPQVDbSNhN2IaTdtKb8u6GoxH+/HrUc/UA7J1g12GUtD/NX3h3Y3HBYXxiOgZ98h+uZ+TB20WNQW39pQxFpm6mkIOblH4/udb0IGi10qeO/EygURdg3DapHqCSnOxVyG8/FgnaxrArSJdmi5lx7GoGftDNXHlzSGspuxM3R8pu+LYFOo+FQiGgj24oYbPRCV0/wy26la9UkKtSA0M+Bfq9CwhKwLsVMG4rEHgf4K4bOsu4UqoPgV7O+P3xplAJUmbRScjHD/8XgPr1zKe5+7T0gbeLGmnZBdh6OEEaOgKAR74Hes2ShvsMAdCu0jvQb2vQEnCWhlNPp2ThJnTBVo75uhsToggc+Eb6vtNTQJuHgcD7pRqBjS8iqqW3dLwSUkotbHjp2E7pUDg0BJw8i+/wbQtAkP5WssqfdadUCJjdvyW6uxcvuNdccxa3cgoqfNNoRQzQ/b+45VySduJV+v927qAwONgpsPfiLay/0UDqY0aiFCgb+XlfIrQiMM5hs7ThvucRNvk3vPNIF6gUAn4/fA1xqa7A01uAYOn6iGLnZzCmcBbS4QKvJtKwtEv2RawcH4Fh7RsCAAa29cOvz0bCLeeyoY9uTnb4OrYTnu4hfaLvHlwfa57rjhAfFzT2dIKPqxqFGtHsgoQarYgvd1zADXjgYLOJAAD7bW9Ir+fkGmmhUaVaChAEAYIgYHzPIHwd2xkuahX2XbqFgd9dQEK/lUDoQAiiBr1yNsDZXokh7RqW+3srycFOiUW9HeEoFBi27dgeh5u6D1V5hRrMXXsCbshGE8GoHslcAKTVSCd54O4BEAAE95E+YIla4M/nzc5waunnijGRTfG4Mg6t/4mV3rv82+P2qL8xapMWX++8iLTsfJO/q7xCLQK9nLF6YiR6h0r/B1Fh3gAEfJg3UBo2tK8HXNoB8YteOHd8LwDgoTbS4sDG7zG4cQbY+bH0ff/3AHtpUkHirVwM/2wXfj98DTdL/F0XFGkR3sgNayf1QPvGHoBXc8DOCSjIBm6auRaj7lgqG3XAa4NaYYkmBhM0L0Br5wy4+KHwyfWYfb4V5q49gSKtWGZdoq1wCExuZjJAl2/mYMk26Y/rtYFhcDFTZHw3D7Xxw30hXlCrlGbrJgAgMsgLO196ACJEONmb/1No5e+GrS/0Ql6RprjYufPTwJ7PYHfzDF7oG4R560/jvY2ncOhyOlKz8hHmCTjn6j75e0mFzfV9GsFz9g6k30pFhJfpSt+Kzk8B+z5HH8UhzD14BPs6BeBaei5e+u0YCoq0CPGuhy9jO0lXf09PlIJGhZ0UiG2bDxz4Gmj7f8U7PPQdcO0AYO8incjrla6tstSj3Zph1p6n8Lt6nlR70f4JoHFXw/0arYhX1xyDVgQGh/tLQzWXdgJHlgMQgIEfGoLcvmHe+HnfFWxOSMEbQ1ohp0CDNYeloM645gGCAHSbALQdIQV7+iDZTRcAZV6XAkKl6e+u3h3Tonr79PNAfdOiYz07pQKPdg7Ax/+cw/FdmxANSMFMmNHCoU11AdCVvdIMG6XR3+PlnaZtIGWAbou6ACi7jMJXY4l7gdQT0jBl+KPS635oobRA5dm/cX/bfVCr7HD19h2cTsky1BDlFhRJb7hKQCh5klLXk2aX3DgltWnRr/w+aDVwzS3OqHW2v4K4Cd3LnJ1VkoOdsriGSn9iqF86AArwdMLkB0Lw/l+n8frfiXjIMxjKW2elPupmnhVqtFix7wr8kQZvTYoUAPeYDggChnVohDMp2fh8+3nMW3sCPWb0hOOoX4HcW9ibApzeIc2UbNm6I3AWQNpZKTAY0Q6vDgyDp34G2s2zuj5K/58qpQKvDgzDxN7BcHeyM3wQEgQBXQPrY+2R69h38RYig0yHIOMT03EzpwAuDir0eOwl4Ku/geSjUuYnUToZo8f0UsOJvUO9sXpiJJ75/iAupuVg2BeH8fUDjyHi1Hp0UZxCTLi/SeF2RQlJ8QAArcIOCm0h/HISMPjTnfgythM2Hk/GlVu5GFzvKlAEadhJUyAde1E0ncF185x0krdzkk76FRH9DnA2Thp6PfwD0LHEUHlRAV7S/A92dt8CABK8ooF+n+Dp707gWvoduKhVmD+8DVr4FA8LCQLQtL4zVEYzx6Ja+uCdDaew58JNZI3qC5enNwM/Pwrh9iV8Kr6EmapJeG3gTPx9IgVnU7NxKS0HTes7AX/OkGr6mvcDWjwEQKpLe+6ng7idW4gGLmq8/3BbNHQvrplSKAQE1ncurs1UKKUPk1d2S0PiJWdwGWXNBrb1w8r9idh4rgMmNFmOtx/ugAkrjmP/pUQoBGB2/5ZSllxGzADJSRSLZwUJSt0mqYamoEiL+0K8MMBM3UJFuTjYlRn86DnaK8sMfvTsVQrTmV4eTaWTVdEdPN5cRJifKzLzivDboasAgLfu082ucvaWTtw6gkIB9xLBDwDpn6jpfVAKIh5VbcW4Hw5g+sojKCjSIqqlN35/LhJN6uumQOsKPOHWSCoYFJTAlV1AqlR3g5w0YPM86fveLwOulT9+xpr7uEDVpBtWFPWSNvw5Qwo+dFbsv4IjVzNQT63CqwNaSoHCn89Ld3YcbVKHEBnkBUc7JZIy8nDieib+iL+GnAINmnk5IyKofuknd/I0PRG7+EoBs7bIZOq5QclLe5j7pGZkRJfGUAiAx4190oaSszYatAQcPaQhqpLpfX0AZPSYU8lZuKkbAkNOBT7hHfha+tpmOODornvO5ob6BHXcbEQFSb//uBPFn2j/PZOGMEi1HC7NzEx3ruAwGADp70qTL50U7ZyhKMpFiDIZIT4uFbqZFJCn6YILL/OzGp+5rxmCGjgjLbsAx8Rmpfq4JSEVqVn5eMBR93vzCzeZITWlTzD83RxwLf0OPvnnrHSWdK5vqBka0q4hHP1CpcY3zxkW9/Q0nn5v6KNpkObhbF9q2KlLoJRZ22s0ZKunH2Lp3cIbdnb2UqAPQcr+ZCUBHoFAj2lmj0OwtwvWPNcd94V44U6hBrF/FSJPtIOXkIkxLSxc2V1PdxwVrWKk51Bcx+302xj22S58vk36W5nYQjdDrXm0lJ3KywBuXTC7H/i2LfUBo0yu/tJ7DiBliRP3S/8vSUeBaweBH2Jgd/hbiBDwbuGjGJI0GsO+OIxr6XfQtL4TVk+MxMC2/iZ/V8HeLibBDwA0a1APzRo4o1AjYvuZG4B3S+CZrbjq3hnOQj4+Uy2E3+GP8Eij2wgTLuHQvn+BfcuASzsAlYOU/REE/LDnMp74ai9u5xaibSM3rJvUA71aeJs8f1CDeqUnppT1fyWKJgGQIAh4Y0gr2CsV+OtcDqI+3mMYzvtqdGc8c3+zCg9xVhUGQHIyHkPVneA2HU/G9jM3YK9U4PXBrWT/AzFLoTRE/qqbp/DW0OKFKAe08UMHJ91Jz8wQQJk6SWsFPabaiuxcaebLpN7BWPZEJ9MMmL4A2j1ACm5CpU8yhiGUuLnSLB6fNkCX8tcWstSobo3xXtGjyEA9IOU4cERaYHPr6VS886cUgD3/YHNp7Y34n4AbCYCTlzTTwoiDnRL3hUifpONOpuDHPdKJ67GuFax5UCilABAwLQjXK7lNf7IrQ0N3RzwQ6o0uCt3wo1E2R3o+haG+xxDwAMCddKnWCjAMkxVptDifmm2oAULOjfJX1865CZxYI31vNJsFAHDf84B7YyDzKsar/wJgWtOwOSEFbYWLAAChYYfS+/bXbatIAKQPEj2bFQ+XVuRxJd25DeTq/v7rmw+A7FUKvKlbwPOPG9JwqHj9kOF+/XDoww10w1Qlfh9O9irM1c28/GLHBZxLzSo9U9IzEBAUUhYjK9m0A7m3pOGXcvporFszKQA6dOW2VCdmRD/EEhWmmyHWqJNp5uOh90vNwjLm5mSHb0Z3xtgegSiAHQ5ppfeM4DtH7tovs/S/sxb9ARc/KKHFowHpuFOoQYFGi57NG6C5Vve7DugK+LY2fVzJ/Zj7uypPl/GAT2vp7+CrKOB/90m3Lx6Q/nfsXYCRP+NEs6dQoBFxp1CD+0K88MfEHgj2rnhBcN+Sw+hOnphhPwffFEVLP2+bj3dSn8MG9csYtu9RYOOL0vb7XwA8muLnfVfw2prjKNKKGNLOH7+Mj4CvWxlrBpVUVgB0+6IUTCrV0ocmSMHa+J5SkJ+eW6gbzuuO3i28K/xaqxIDIDlpizMIUCiRnV+E13U1NON7NkOzshanqw70UzVTTqJDYw8837c5OjXxwJxBYaXS6xUSOghw8kID3MbYBqfxia5ou9SnD312w003pKM/aR5ZAZzbDMT/KP08cFHFP7lVUL/WvhCcvfBtUV8AgHhpB5b9ex5PfbvfsLLxE92aSI0v7pC+dhlnWpuioz9hfL/7EhKSMmGvUuDhjqVnt5RJPwxm7kKuhiyZrs3N8gMgAIht74EwQTrh5vl3K92giZkA6MoeAKK0SKaLlNm7dDMHBRot8uzdpTbaQikgLcuR5VLmxS+8OGDRs3eSZsABaHn7H6n51QykZOZBoxVxKOEcAhS62hlzNV7Gb9R3W+7MOCNiSeao1H50J1cXP5OsTUmRwV6IjWiCIxrp5JB1YT8KirS4fDMHO86mQRCAVgWmwaWxB8N88ECoNwo1Il5bcwK/HEg0nSmpUkuLLAKlf//61+ra0FAHUp6gBvVQ39ke+UVak9W0L6Xl4GxqNlQKAT2bGw0z95kr1XBFTAJC+t51/yqlAq8NDMP7D7fFBSfd7/HSzvIfZE5RQXFA7t/e8Ht8pX0enusVhC6BnngrpjUEfdG5UZsyA6CK1P8YU6qk2r36wUA9X9NbQDfg6c0QWvTHO0PboEugJ57rFYRvRneGm5NlZQ76949/TqWiUKNFWnY+9idm4fWiWKT3XQR4NoPG2QcpojtSRHdonX2kaeeRU5CWnY/5G6QPbBN7B2HxiHZwsKvYUC+A4mOSfNQkC16cNWsNqIqzjRN7B+PBMB8Mbd8Qa57rjmDv6nNeYw2QnIxX/FSo8PHms0jOzENjTydM7G1B8CAHH10AlHoCADC5Twgm62aflZVeL5fKHujwBPDfh5jtvRsIf9F8O33hr74QOLCXlGa/fRFY8bi0rcOTQEDZq7tWllqlxP91bIT4/6TfTcqpPXgnU8qaPNo5AG8MaV2crta/GZSYgqvXJ9QbggDc1k1ZHdjWD+5O5ldWNctdFwCaKYQ2BEBBD0j1UGnlD4EBQKT9OSgEERe0vjh0UcTDJWM2QwC0W8pcKpRm63/0C+A18akPZLpKheg5adIQWklarWnxs7nsV4v+gKCA3Y2TeNA/H39fV2NLQiqa+9RDo7zTgD0gegZDMBpqNfBtLQ2R5qRK9VJu5RTVGoL2kOLgvjIBkAXB/7zBrfC1C6DZ/jpci25i/P82wN1H+r0OaqaE3bXzAASgcemAVBAEvD64FXaeS8PuCzdxOFEqUDapIfMKkf4v0s5KAUkl+qh/ri6Bnth4PBl7L95Cp6bSH4c+G9e1mSfcHI1O4E6e0ixGC/1fpwCg/mPAdz9LxfUl63Lu5kaCFEw7uEnvCf7tgdMboEyKx4vDpQJtZN/QZUgFaXjr9iVpu/FMPE1R8VCvpQGQ/jGTD5bbJMDTCb+ML3/RxPJ0aOwBDyc73M4txIFLt5F4OxeiCLRu6Ar37gOA7mOhBBC7+F+cSs7C4ph2iNEVws/fcASZeUVo5e+K6VHNLR9l8AySMlkFWVKNXcksWolj5mCnxLIn776ArByYAZKTUQboTGouvvpPSue/PqSVZRG5HPQnCX3tjbFyikDL1SEWgCDNHCk5Jq+nP7nrAwCFwjB8hqI70lTxqNcte14LjOzSGMe1UuGed/4VuCry8PrgVpg/rE1xvdWddGn6PVDmG2j9emp0bFwcFIzq2sSyjhgyQGYCIP0QWNADxT/f5fpmyitSMLNPG4of91wuNdsKvm2lN738DGltFcCo/qc4ADqjC4BCfV2KF/YsaybYpX+l42TvArR+2HwbJ0+gsXSieNxTyo5uTkhBXEIK2hiGv8o4Sdk5VjyYMZcBKvkJtyIsCP4FQcDYB1rjjrtUZKu5dggrD0i/u7EButoun9bmg0foC6qlICavUAsXB5U0U1JP//9XsgasEh9Q9HVAxouN6pclKHOBxMpo2Ema4JB1XQreLGF8AhYE89kdXZE0vEIAB9fiNknxxTO30k5L7yX2LtLJvhpSKgQ8oFseYnNCSvFQZInfhf7nOF2wuvfCTfx26CoEAXgrpnWp+qIKUSgA/3bS98bH1jizVkMwAJKTUQ3Qa+tOQaMV0a+Vb7UZHy2X/sRy87y0EJieVittAyzLAAFS3YL+pK2fjl2SYQjMaBXldqOk4lUA6PuG2SEna2nq5YzQkGBcFz2hEET8NMARsZFNTT9F6afPujcpty/6NLb+6vYW0QeAJYfAtFrp+l2A9Ebk4A5ALP6dlEU3nf0AwhCfmI5Zvx1DfpFRhlKpKp71dnkXkJ9d/IbXpHQGqLmPUQBU1kww/TXw2j4izdoqS4v+AICOeXsAAP+dS8PGY8loq1/Lpbw3XHNv1OYYB+2ezQC1qzQNX7/GUUUZZ5IqqF6gVMB9n7P0u/R1dUCbIt1QTsl6rBKeub8ZmumukTa8QyNppqSevgi7ZA1YJT6gdA2UivMPXLqFIo0Wt3MKcEC3MrFVAyB7J6BhR+l7c8sulKdkBkL/9eZZIC/TfBuvFtKEDuNp3YY27Sp1ORRb6RsmnSc2HU/GjrNS3VmpAEj3HrP99A3kFhTh1TXS39WjnRtL09orq+T/lVbLAIgsZBQA7b2cASd7pVRDUxO4+EqfTEWN9IlJL/Oq9OlJYVdcg2CJZr2kr/osgzHjk7u7UQDk7AU8/DXw4FtSMFTF5g1uhUwPKe3bRjCTqapg/UBsRFNM6h2MD0e0szwNbVgLqEQAlJMqTe0VFNKsFH0QWl4dUH624ZNx5AODoBCAlQcSMeqLvbiRZbTIpPGCiIl7pd+9W2OT38WZFOMMkG7KdFkZIP3wQyPzF6w00E3Zdbq+Gy09RBQUaXHlVm4FA6AK1PPkZxXPpvMKlk56lS2E1g83WhL8604mjwXcwoReQVj8aDsorkiXbik1I68EtUqJZU92xLj7m2F6VInp2vXL+N3fZZaaOS18XeDqoEJOgQYnkzKx7Yx0mYVQ3xIz4KzBMNx6jwGQs1dxraD+Q0nJNkpV6d+1cQBUjd0X0gD2KgWupd/BnUIN/Nwc0MrfdLHTtg3d0MBFjez8Ijz30yGcTc2Gp7M9Xup3jxcgLfl/deu8NCSmcpSCyhqCAZCcdDVAGigACJjaJwT+7mXPmKhWBEFanA8wHQbTv7l6BlauCNmnuLi6lJwb0hi/oJAKOI21HCQt7W6DT2xBDeohtIOupsLcCbKCAZCjvRIvRLeo0CrfpegzYBlXTQt89UNiLv7Sej36k2B5dUBX90nDsW6NMeyBSHw9ujNcHFQ4cPk2hnz6H45fy5DaGS+IaKb+J7egCJdvSdePauHrIl2fCih7Knymbr0i19LXYTJRPwjwagFBW4SxvlLQ0wDp8BNuwVDLUZaKFELrP/k7eRUPN1WmEFqrKR66tWQCgK742y45Hi9Ft0A3X8FQW2euALqkYG8XvPxQy9KFtPogLP1K8WrpmiKjPlY8SFMqBJPp8JtPSlk9q2Z/9PR/U/przFVEYV7xe4bx/13JTIW5/82Sv+vKFkDbmLNahe5Gy2ZEtfQp9UFKoRAMC4lu010MeHb/UMvqDc3RH5uU41Lxuf6Y+VmwbEA1wABITroaoCJRgRDveniqh7yLQlnMW5rqaJKtqWz9j2Gf+qG1c6UvcVHy5C6n8k6QtngDdW0IQJCGaYwzLCVrpPSf8svLAOk/aes+efdq4Y01E7ujmZczrmfk4eHPd+GJr/ZiTFwR8gU1kHsTGbu/M3kMAJxNyYYoAl717KWVp8urARJF6dpAQPGU/vLohsF6ivsBAK0VuvqQBi3KHz7zaSVlI+/cMl8vBZjP2lQmADKsJaQuPv4V4dNKWtcpN00KaPXZH68WxVm0yqjnI9WxiNrioCf9sjQzT+VgOoxcAfoAaMe5NGn9GRhNf7emgK5S8Xr65eKM792knpBel1N909dl/HvMTJIyfYIC8G1jvk3JmWTVnPHx71vG78J4e+emHhhu5lpqFvMIlIbXNQXS5TxqSNBYEgMgOemGwLRQ4JUBLWFXmYI0ORlmghllayqRXjfh4if9Y4kaIO2M6X0lZ4DJyU/3j37rvFT0rJd7S3rjBu7p8ht3pbIvzpwYn9iN10kCjDJA5QRAl0pnc4Ia1DO5RtSOs2nYejYdB4qk36tbkS6rY5ShOK0b/mrhq5v+bQiAzNQA5WVICysC0u/8bnTDYF7J2+HvokR7pS4AutsbrkotBRhA2cGMuVlRJT/hVoTxWkIVXEEagHQtKUOx9iGzv49KEYTSdUCGPgZZnC3V1wH9e+YGsvOL0MBFjbYNzcy+u1dql+L/nYoOg5UsgNYzDm70BdANQk2n/xsXvaccM51JVs1FtfSBg50CXvXU6NrMfL1hZJAXPJzsYKcU8FZMm9JLi1RGySJzBkBkMX0GCEo086o+ayNUmLmZYPqTSUWXjy9JEEzWGDJhrgBaLs71iz/l6+sLgOI3As+g4lWNq4q5mWAlj5GhBuic+SGgwjzpsiFAqeEW/TWivhndGYseCceiR8LhEdbLcP9NwROi0UnitHEBNGAUAJkZAtMPfzl6SIWvd9OoE+DkBSEvA2sGKvFUoFSAW6E33Ltlc8zNivJoavoJtyLuJfg37qOZ2XWVVrIO6B762MrfFc5GRdZRLb2tczI1x9y6U+Up6wSsHwK7fRE4v9V8m/rB0vW0CnOli/Lq21THRWhL8HF1wNpJPfD7hEjp2oNmONgpsfq57vhzyn3FH06sQX8crx2w7Lpp1QgDIDkZMkAC1HY18FehHwLLvCatfAoUDydUdggMKLXGkEHJ7IbczJ1Y9Sv62uKNwFwhdHqJLJlnMynln59pfjbWtQPSSb6ej9S2BJVSgd6h3hjWoRGGdWiEsG79DfftLGqBI9cyDT+fNp4CD5Q/BKa/oK1rBdPxCqV0DSMA3te3oN7NY9J2awRA5mZulTWNujyVmAFWqo8XtkuZCOCuBdAV4lWiBuwe+qhSKtCxaXGWoUrqf/T0wV9FF0QsawaSo0dxJufICvNtFArAr530ffzP5ttUY819XNC4fvkfIpp6ORd/MLEW/TE6uU4KHu3rWVb7Vg3UwLNu7VFUJC2CVwQl1He5Zle15OBWnGlIPQUU5EizwADLp8AbK2uNoZL1LXIzd6kFW04FNbcatCFI1B0jlVE9irk6IEP9T/eKfeJt1Mmw5MA+bSh+2nPZcFfxEJiuqNswDb68AOguBdDGdHVAOLpCGlYTlNI6OXdjCGTiS2fBylu2QX8ZBKPLVJSrMguAlurjIalmxyPQsmNTlvolasAqM0vNSFddHZCDnUK64G9VaRIBQJD6fbcL6hbkFr9XmPu/02/LzyinTbu7tyFTJY+rX7hlQ7/VQA0869YehYVSAKSFosz0ZbWnzwKlnig+kTh63ttaPDVhCAwoIwNkw7Fww1pAusBQFEtfKgQovw5IP9OmotkGO0egzf+hSO2BOE1HrDt6HRm5hbiVU2CYMh+iX+q+ni4Ays8oXdBuKIAuZ3XmkoJ6SwXG+myjd8uKDZ95t5Qel59ReoHNrOvSp1eFShr2MmZxBugesp/eYcVrWQHWGf4CjDJAZ6W/j3vJUgF4qI0fnO2VeLRz46pdrNXRo7h2627DYMnHpJrBej7m68mM/xcVquL9ltXG3M9UmlsjaeakXg08ZgyAZFRQ0zNAgGmwcvMePgGb7FM/tHZVKpYFdLOGSmQ35KYv1Ey/LBU/Z6XoMhuCNB20qpUcArtzu7iw2HhmlXEdkLGiAiBRdwX4pj0q/rwxn0E56yI8fJsgr1CL3w5dxalkaSissacTnNW6abAO7tIJByhdB1TRKfDG7J2L14kCKr5Oi9KueNZPyWBGHxR6NC09s1D/hp6acNeVtEutJWQplb1pNuteC6D19CsZ56VLdTDZuotnVnKSQqCXM46/Ho25tlivzHjZhfKUVQCtZ3xi9m5p/uKsxm1KziQj84yHiQEGQGSZwkJpdokGiqorJqxq+k9TqQnWqf8BpOJh/To/+tT2ndvSaq1AxaZN24Kje/EJxniWiVfzci+EaTX6LE96oi77oxuOcvaWZhbp6YdBSs6qS4ovvnyIhYuXCYKAUboLv/6093LpAmipUdkzwQxDYBZkgIDiYTCg9MVTy9PQzHAlUH7WxrWh1H9tkVQ/cvHf4lvJK6ybW0vIUsZXHrdG/Q8gZcj0J/PTm6Svzt7S8HUlCYJg+cKdlaE/BnerAzIEQGX8PRjPxiyrjWczQO1W3KYGFEBXCwyAqLIKC6RZYCJq6PAXUGII7B6nwJvsV59Z0hVC67Mczt7mP8HJRc6poPpAsCBL+oSfXkaGzKuMIbBT66WvTSIrtYBkTDt/ONkrcf5GDpbvlYbhQkvOMjGsBl0yA1TJAEhXCA3AspV69b+T81tNVmAvd1aU8Sfc9dOA7wYV35ZGmtY23WNtjUkfXRtVbhX1sugD4NMbpK/3mqG1FX0GyHh4vaSi/OJh3LL+HhxciwPcstoIQvF91XwF6GpF/zerdjM7iaK6YwAko0LdEJhWqMEBkFdzqRg1LwO4uEPadq8ZIMBoJpguA1RydlN1IWcAZO9UnGFJTyx7lpz+95F+ubgWJ+0csGep9H34o5V6ehcHOwxpJwUwZ1Ol7FypabbO+tWgjYIF40UQLQ2AXP2A3q8AHccUr8VUEcF9pUUBU08Ah74r3n63mphuz0kZhAahxTcHdyD3JrB5rpn93EPwHzZEWtE8ap51MxD6gEc/lFRTZurUawAE9ZG+3zDT/DIOOz+Whsrr+ZRfN9X7ZSB0INB6eNlt7nte+jvpOObe+l2XBPcB2jwC9J1XI7NmNWfN6lrIUAQt1OA4VKWW3lDTTgPZumEBa3zCNMwE0xVCV7cCaD3jAEi3rpNNU8FuAVJwkX6l7GPk4itNUS3IBm5dlFZP3vC8NP09OEo6MVTSqK6N8fO+4nWISgdAZqbC52cW1ypVZqZTzxctf0y9BsADrwKbXgI2vw6EDpK23S1zE9RbuhlL3A98FQXE/wS0f1zKoN3LDDA9tQsw4sfKP74s+uBOd+mdGpMBAoD+C4ClEcD5LUDCWilI1Lt1EdjxgfR99Dvlrwjeeph0K0+zntKNKk6lBoZ/IXcvKq0Gn3lrvqLakAECirM1gJQNssYKqsZDYCYF0NUsAPJrC0CQhnSyU0ovs1/VjAuhy1omQBBMp0OfWA1c2CbNjOq/4J4+ubVu6IbwAHcAgJ1SQKCXs2kD/RCY8VRmffanoosgWkvnp6XfTV46EDdHKmzW/11ZkrUM6Ax0iJW+Xz8D0BTe8+yqKlVyeK869rEsXsFA92nS9xtnScXmgPSesPFF6VIwgT3Lz+wQlYEBkIwKC3U1QDU9ANJfFBUAPJpIM1rulWFoLV0qODWc3K1YG2ENahfTVa8bVHBqtrUYrwWUUUYABBR/6r9+GNg0W/r+vhnShUbv0eNdpecL9XUtfTkXcxdENcwAs3D4614pVcCAD6XvjywHDv8IQJQKgi295lbUPKl4/EYCsHtJ2WsJVQclA57q2Mfy3DdD+r/Pug5se1fadmo9cPZv6TpvAxbWyOEXkh8DIBkV6a4xVPMDoJbF31vr06WdQ/HJOfVEcQBU3YbAAHlnQugDwoxyhsCA4t/Lrk+koUrPZsWfrO/R8A6N8GZMa7w73Ezmy9wQmH6xTFsHQIBp9uavl6Wv9UMsP4E6eQJ935C+3/p22WsJVQeuDQGVbuKAwq76fYi4GztH4CHdUNeepdIQ5MZZ0s/dp9a8gI6qDQZAMioqqiUZIOMhMGu+GRmvMVRdh8CAEgFQO9s+t/54pJyUsmXG24zph0E0ugt7PvSB6VT5e6BQCHiiWxO08jcztdrcNPjKrAFkTVHzpLVe9Meisn+z7UYBAd2K92NuLaHqQKEoHgL1DJQyYTVN8welAnFRI83Cy7wqBXL3vyB3z6gGYwAkI42uBqjGB0DuTQE73bCPNWeY6AOgq/uLV/+t9hkgC9amsQb98bilG4JxcDe/BpFxZi4sRpq9YQvmLoiqnwJvySrQ1mScvQEq/zerUOiGX3T/v9W5tkYfAFfnPt5Nv3cBO2dp7SpAql+rTktiUI3DAEhG+iLomnb9lFIUCqBxN+n7Rp2tt199Zkl/FWcHd2lNj+rGt4003buer/ll9qtSyWxPWatke4VIWQ8HN2nGjK0YD4HppzFXdgq8NYU/BjTRrX7dOKLy+/FtDURO0u2n2733q6o06iJ9DbDi/6etuTWSprMDQMvBQIt+5bcnuosamAutPTRFummpNT0DBAAPfyN9srdmAKDPABXoZn5Ux+EvQCp6Hr8dgGC1YaUKc3CTbvpLhpQVANk5AuN3SLUuthx60hcXa4ukLJ6Tp/xDYIAUtD/+mzR7615n7UW9Ls1C8g67e1u5dBkHNO4K+NrgEi1VKWKiFLD6VuAiuER3wQBIRhp9EbSiFvwaHN2lmzV5NJWKN/Upb7dqcg0wc+Q8mbs1BvKO6b4vJ0iUY8hJpS4O0HLSpKnvhlWgZb6kiZ2DdZYsEATTyy1UR0oV0LCj3L24d4IANKoFr4OqBQ6ByahII2WAhJo+BFZVFErAO7T45+qaAZKb8XGpjsfIeBgsP7P4mm5yBo1EVOcxAJKR1lADVAsyQFXFeFihulwFvroxPi7V8RgZB0D64S9bL4JIRFQCz7wy0mh0l05gBqhsxgFQdZwBVh0YH5fqeIyMAyB73eUK5CyAJiICAyBZaXUBkMAMUNmM1xiqjsM71YHJEFg1zwApdauEc/iLiGTGM6+MtEX6AIgZoDKZDIHVsBVsbUV/XOzrSUNL1Y251aCZASIimTEAkpFWd/VwoSauzGorLr5Az5ekNWScPOXuTfXk2xbo9JQULFbHayIZXxBVv2oyAyAikhnPvDIqHgJjBqhc+sXPyDyFAhj4ody9KJvxBVELc6Xv5VoFmohIhwGQjAwBEDNAVJsZD4Hd0f2tswaIiGTGM6+MRN0QmIJF0FSbmbscBofAiEhmPPPKSNQthKhgBohqM30AlJ9ZvI0ZICKSGRdClJEhA6RiAES1mIMboLAz+tkdsHeWrTtERAADIFlxCIzqBEEozgIBHP4iomqBAZCMRK1uCExld5eWRDVcPaMAiDPAiKgaYAAkJ10NkFLJafBUy5lkgFj/Q0TyYwAkJ90QmJIZIKrtTAKgRvL1g4hIhwGQnERdAMRZYFTbMQNERNUMAyA5abUAmAGiOoABEBFVMwyAZFKk0UIhSjVAKmaAqLYzDoDcOARGRPJjACST/CItlIIuA2THDBDVcvWYASKi6oUBkEzyi7RQQj8LjBkgquXq+UpfHT25CCIRVQs888okv0gDJaQMEC+FQbWeTyugx3TAu5XcPSEiAsAASDb5hcUZIHAlaKrtBAGImid3L4iIDDgEJhNpCEx3ZWyBvwYiIiJb4plXJtIQGDNAREREcmAAJJP8Ii1UhgCIl8IgIiKyJQZAMpFqgKQiaGaAiIiIbIsBkEyMZ4FBYAaIiIjIlhgAycR4IUQOgREREdkWAyCZmBZBMwAiIiKyJQZAMmENEBERkXwYAMlEWgeIARAREZEcZA+AlixZgqZNm8LBwQFdu3bFvn37ym2/atUqhIaGwsHBAW3atMGGDRtM7s/OzsakSZPQqFEjODo6IiwsDJ9//nlVvoRKYRE0ERGRfGQNgFauXIkZM2Zg7ty5OHToEMLDwxEdHY3U1FSz7Xft2oWRI0di7NixOHz4MGJiYhATE4Pjx48b2syYMQObNm3Cjz/+iISEBEybNg2TJk3C2rVrbfWyKsT0UhgMgIiIiGxJ1gBo0aJFeOaZZzBmzBhDpsbJyQlff/212fYfffQR+vXrh5kzZ6Jly5Z488030aFDB3z66aeGNrt27UJsbCx69eqFpk2bYty4cQgPD79rZsnWTIfAGAARERHZkmwBUEFBAQ4ePIioqKjizigUiIqKwu7du80+Zvfu3SbtASA6OtqkfWRkJNauXYtr165BFEVs3boVZ86cwYMPPlhmX/Lz85GZmWlyq2p5hRrWABEREclEtgAoLS0NGo0GPj4+Jtt9fHyQnJxs9jHJycl3bf/JJ58gLCwMjRo1gr29Pfr164clS5bg/vvvL7Mv8+fPh5ubm+EWEBBwD6+sYkwuhcEaICIiIpuSvQja2j755BPs2bMHa9euxcGDB7Fw4UJMnDgRmzdvLvMxs2fPRkZGhuGWmJhY5f3ML9IYLYTIDBAREZEtyXbm9fLyglKpREpKisn2lJQU+Pr6mn2Mr69vue3v3LmDl19+GatXr8aAAQMAAG3btkV8fDw++OCDUsNnemq1Gmq1+l5fkkVMa4BqXRxKRERUrcl25rW3t0fHjh2xZcsWwzatVostW7YgIiLC7GMiIiJM2gNAXFycoX1hYSEKCwuhKBFQKJVKaLVaK7+Ce8OFEImIiOQj65l3xowZiI2NRadOndClSxcsXrwYOTk5GDNmDADgySefRMOGDTF//nwAwNSpU9GzZ08sXLgQAwYMwIoVK3DgwAEsW7YMAODq6oqePXti5syZcHR0RJMmTbB9+3Z8//33WLRokWyv0xzTS2EwACIiIrIlWc+8I0aMwI0bNzBnzhwkJyejXbt22LRpk6HQ+cqVKybZnMjISCxfvhyvvvoqXn75ZYSEhGDNmjVo3bq1oc2KFSswe/ZsjBo1Crdu3UKTJk3w9ttv49lnn7X56yuPyRAYi6CJiIhsShBFUZS7E9VNZmYm3NzckJGRAVdX1yp5juFLd+Hb5GFwEe4Akw8B9YOq5HmIiIjqCkvO36y+lYnJpTC4ECIREZFNMQCSiemlMFgDREREZEsMgGTChRCJiIjkwwBIJvmFRVAKuvIrZoCIiIhsigGQTIqKiop/YA0QERGRTTEAkkkhAyAiIiLZMACSgSiK0BQVFG9gDRAREZFNMQCSQZFWhCAaXZqDNUBEREQ2xQBIBiarQAMMgIiIiGyMAZAM8gs1JQIgDoERERHZEgMgGUgZIP0aQApAEOTtEBERUR3DAEgGvBAqERGRvBgAySC/SAOVoL8OGOt/iIiIbI0BkAxMrwPGDBAREZGtMQCSgckQGAMgIiIim2MAJIP8Ig1rgIiIiGTEAEgG0hAYa4CIiIjkwgBIBibT4DkERkREZHMMgGRgMgTGDBAREZHNMQCSQX6RFipmgIiIiGTDAEgG+YUaKFgETUREJBsGQDLIL9JyIUQiIiIZMQCSAYugiYiI5MUASAamRdAMgIiIiGyNAZAMTNYBYg0QERGRzTEAkoHppTBYA0RERGRrDIBkIA2BsQaIiIhILgyAZMAMEBERkbwYAMkgv1ALFYugiYiIZMMASAb5RVwIkYiISE4MgGQgLYSorwHiEBgREZGtMQCSQX6RtjgDxCEwIiIim6tU+iE9PR379u1DamoqtFqtyX1PPvmkVTpWm+UXaYxqgJgBIiIisjWLz77r1q3DqFGjkJ2dDVdXVwiCYLhPEAQGQBUgLYSoGwITmIQjIiKyNYvPvs8//zyeeuopZGdnIz09Hbdv3zbcbt26VRV9rHU4DZ6IiEheFgdA165dw5QpU+Dk5FQV/akTuBAiERGRvCwOgKKjo3HgwIGq6EudwQwQERGRvCw++w4YMAAzZ87EyZMn0aZNG9jZ2ZncP3jwYKt1rrYyWQiR6wARERHZnMUB0DPPPAMAeOONN0rdJwgCNBrNvfeqFhNFUVoIUcFp8ERERHKxOAAqOe2dLFOkFaEVwYUQiYiIZMQ52DaWXyQFkFwIkYiISD6VCoC2b9+OQYMGITg4GMHBwRg8eDB27Nhh7b7VSvmFUuaHCyESERHJx+IA6Mcff0RUVBScnJwwZcoUTJkyBY6OjujTpw+WL19eFX2sVfQZIHtBXwTNJBwREZGtWZx+ePvtt7FgwQJMnz7dsG3KlClYtGgR3nzzTTz22GNW7WBtYwiAFKK0gRkgIiIim7M4/XDhwgUMGjSo1PbBgwfj4sWLVulUbZZfJA2B2XMWGBERkWwsDoACAgKwZcuWUts3b96MgIAAq3SqNssvlAIfO2aAiIiIZGPx2ff555/HlClTEB8fj8jISADAzp078e233+Kjjz6yegdrm+IaIF0AxIUQiYiIbM7iAGjChAnw9fXFwoUL8csvvwAAWrZsiZUrV2LIkCFW72Btox8Cs+MQGBERkWwqNf4ydOhQDB061Np9qRMMQ2D6DBADICIiIpvjHGwb0w+BFWeAWANERERkaxU6+3p6euLMmTPw8vKCh4cHBEEos+2tW7es1rnayDAEJjAAIiIikkuFzr4ffvghXFxcDN+XFwBR+fQZIBWLoImIiGRToQAoNjbW8P3o0aOrqi91gv5SGMUZIAZAREREtmZxDdChQ4dw7Ngxw89//PEHYmJi8PLLL6OgoMCqnauNDBkg6K8GzwCIiIjI1iwOgMaPH48zZ84AkFaFHjFiBJycnLBq1Sq8+OKLVu9gbVNqCIw1QERERDZncQB05swZtGvXDgCwatUq9OzZE8uXL8e3336L3377zdr9q3X0RdCGDBBrgIiIiGzO4gBIFEVotVIWY/PmzXjooYcASJfISEtLs27vaiH9OkBKzgIjIiKSjcUBUKdOnfDWW2/hhx9+wPbt2zFgwAAAwMWLF+Hj42P1DtY2xTVA+gCISzERERHZmsVn38WLF+PQoUOYNGkSXnnlFQQHBwMAfv31V8O1wahs+iEwJZgBIiIikovFZ9+2bduazALTe//996FUsp7lbvQZIKVhFhgDICIiIluz2tnXwcHBWruq1YprgLgQIhERkVx4KQwbMwyBicwAERERyYWXwrAx/RCYwjAExiJoIiIiW+OlMGysOABiETQREZFcLE4/bNiwAX/99Vep7X///Tc2btxYqU4sWbIETZs2hYODA7p27Yp9+/aV237VqlUIDQ2Fg4MD2rRpgw0bNpjcLwiC2dv7779fqf5ZU6khMNYAERER2ZzFAdCsWbOg0WhKbddqtZg1a5bFHVi5ciVmzJiBuXPn4tChQwgPD0d0dDRSU1PNtt+1axdGjhyJsWPH4vDhw4iJiUFMTAyOHz9uaJOUlGRy+/rrryEIAoYPH25x/6xNXwQtcBYYERGRbARRFEVLHuDo6IiEhAQ0bdrUZPulS5fQqlUr5OTkWNSBrl27onPnzvj0008BSIFUQEAAJk+ebDagGjFiBHJycrB+/XrDtm7duqFdu3b4/PPPzT5HTEwMsrKysGXLFrP35+fnIz8/3/BzZmYmAgICkJGRAVdXV4tez93cv2ArrtzKxWmvmVBnXwOe3gI06mTV5yAiIqqLMjMz4ebmVqHzt8UZIDc3N1y4cKHU9nPnzsHZ2dmifRUUFODgwYOIiooq7pBCgaioKOzevdvsY3bv3m3SHgCio6PLbJ+SkoI///wTY8eOLbMf8+fPh5ubm+EWEBBg0euwhH4ITCHqa4A4BEZERGRrFgdAQ4YMwbRp03D+/HnDtnPnzuH555/H4MGDLdpXWloaNBpNqUto+Pj4IDk52exjkpOTLWr/3XffwcXFBcOGDSuzH7Nnz0ZGRobhlpiYaNHrsIS+CFpgDRAREZFsLA6AFixYAGdnZ4SGhiIwMBCBgYFo2bIl6tevjw8++KAq+nhPvv76a4waNarchRrVajVcXV1NblXFUAPEdYCIiIhkY/HZ183NDbt27UJcXByOHDkCR0dHtG3bFvfff7/FT+7l5QWlUomUlBST7SkpKfD19TX7GF9f3wq337FjB06fPo2VK1da3LeqIIqiYQhM0DIAIiIikkulVuETBAEPPvggJk+ejIkTJ1Yq+AEAe3t7dOzY0aQ4WavVYsuWLYiIiDD7mIiIiFLFzHFxcWbbf/XVV+jYsSPCw8Mr1T9rK9KK0OqvgGHIAHEIjIiIyNYsDoC0Wi3efPNNNGzYEPXq1cPFixcBAK+99hq++uorizswY8YMfPHFF/juu++QkJCACRMmICcnB2PGjAEAPPnkk5g9e7ah/dSpU7Fp0yYsXLgQp06dwrx583DgwAFMmjTJZL+ZmZlYtWoVnn76aYv7VFX09T8AAAZAREREsrE4AHrrrbfw7bffYsGCBbC3tzdsb926Nb788kuLOzBixAh88MEHmDNnDtq1a4f4+Hhs2rTJUOh85coVJCUlGdpHRkZi+fLlWLZsGcLDw/Hrr79izZo1aN26tcl+V6xYAVEUMXLkSIv7VFXyC43WT9IWSV9ZBE1ERGRzFq8DFBwcjP/973/o06cPXFxccOTIETRr1gynTp1CREQEbt++XVV9tRlL1hGwxPX0O4h89x/YKxU4Yz9KygLNOAW4+lntOYiIiOqqKl0H6Nq1awgODi61XavVorCw0NLd1Sn6ITC1SuAQGBERkYwsDoDCwsKwY8eOUtt//fVXtG/f3iqdqq30M8AcjSd+cRYYERGRzVl89p0zZw5iY2Nx7do1aLVa/P777zh9+jS+//57k8tTUGn6NYCcVAL0lwKDUKmJeERERHQPKrUS9Lp167B582Y4Oztjzpw5SEhIwLp169C3b9+q6GOtoR8CYwaIiIhIXhadfYuKivDOO+/gqaeeQlxcXFX1qdYqHgIzqjtnAERERGRzFmWAVCoVFixYgKKioqrqT62mHwJzMMkAsQiaiIjI1iweAuvTpw+2b99eFX2p9QxDYEqjDBDXASIiIrI5i8df+vfvj1mzZuHYsWPo2LEjnJ2dTe639IrwdUnpITABULAImoiIyNYsDoCee+45AMCiRYtK3ScIAjQaTantJNFngJxUgrSB9T9ERESysPgMrNVq796IzNJfCsNBPwTG+h8iIiJZcPzFhvQZIAd93MMMEBERkSwqFQBt2bIFAwcORFBQEIKCgjBw4EBs3rzZ2n2rlRzsFMVF0CyAJiIikoXFAdBnn32Gfv36wcXFBVOnTsXUqVPh6uqKhx56CEuWLKmKPtYa43sG4dSb/TG9T5C0gUNgREREsrB4DOadd97Bhx9+iEmTJhm2TZkyBd27d8c777yDiRMnWrWDtZJWt44SAyAiIiJZWJwBSk9PR79+/Uptf/DBB5GRkWGVTtV6hivBswaIiIhIDhYHQIMHD8bq1atLbf/jjz8wcOBAq3Sq1jNkgBgAERERycHiM3BYWBjefvttbNu2DREREQCAPXv2YOfOnXj++efx8ccfG9pOmTLFej2tTfRLCfBK8ERERLIQRFEU796sWGBgYMV2LAi4cOFCpTolt8zMTLi5uSEjIwOurq7Wf4LLu4Fv+gGeQcCUQ9bfPxERUR1kyfnb4gzQxYsXK90x0mERNBERkaw4BiMHFkETERHJigGQHPQZIC6ESEREJAsGQHLQF0FzCIyIiEgWDIDkwBogIiIiWTEAkgNrgIiIiGRl8Rl437592L17N5KTkwEAvr6+iIiIQJcuXazeuVqLNUBERESyqnAAlJqaiuHDh2Pnzp1o3LgxfHx8AAApKSmYPn06unfvjt9++w3e3t5V1tlaQ6vPADEAIiIikkOFh8Cee+45aDQaJCQk4NKlS9i7dy/27t2LS5cuISEhAVqtlhdCrSgth8CIiIjkVOEz8F9//YV///0XLVq0KHVfixYt8PHHH6NXr17W7FvtxSJoIiIiWVU4A6RWq5GZmVnm/VlZWVCr1VbpVK3HImgiIiJZVTgAGjFiBGJjY7F69WqTQCgzMxOrV6/GmDFjMHLkyCrpZK3DImgiIiJZVTgFsWjRImi1Wjz66KMoKiqCvb09AKCgoAAqlQpjx47FBx98UGUdrVVYBE1ERCSrCgdAarUaS5cuxXvvvYeDBw+aTIPv2LFj1Vw1vbZiAERERCQri4tQXF1d0bt376roS93BGiAiIiJZWW0l6JSUFLzxxhvW2l3txhogIiIiWVktAEpOTsbrr79urd3VblwHiIiISFYVPgMfPXq03PtPnz59z52pM1gDREREJKsKB0Dt2rWDIAgQRbHUffrtgiBYtXO1lsgAiIiISE4VDoA8PT2xYMEC9OnTx+z9J06cwKBBg6zWsVrNsBI0h8CIiIjkUOEzcMeOHXH9+nU0adLE7P3p6elms0NkBougiYiIZFXhAOjZZ59FTk5Omfc3btwY33zzjVU6VeuxBoiIiEhWFQ6Ahg4dWu79Hh4eiI2NvecO1QkMgIiIiGRltWnwZAEuhEhERCQrBkByYA0QERGRrBgAyYELIRIREcmKAZAcDNPgefiJiIjkwDOwHESt9JUZICIiIllU6gx8+/ZtfPXVV0hISAAAtGzZEk899RQ8PT2t2rlaiwshEhERycriDNC///6LwMBAfPzxx7h9+zZu376NTz75BIGBgfj333+roo+1D4ugiYiIZGVxCmLixIl45JFHsHTpUiiV0glco9Hgueeew8SJE3Hs2DGrd7LWYRE0ERGRrCzOAJ07dw7PP/+8IfgBAKVSiRkzZuDcuXNW7VytxSJoIiIiWVl8Bu7QoYOh9sdYQkICwsPDrdKpWo9F0ERERLKy+Aw8ZcoUTJ06FefOnUO3bt0AAHv27MGSJUvw7rvv4ujRo4a2bdu2tV5PaxPWABEREcnK4gBo5MiRAIAXX3zR7H2CIEAURQiCAI1Gc+89rI1YA0RERCQri8/AFy9erIp+1C2GGiBmgIiIiORgcQDUpEmTquhH3WKoAWIAREREJIdKjcGcP38eixcvNhRDh4WFYerUqQgKCrJq52otLoRIREQkK4tngf31118ICwvDvn370LZtW7Rt2xZ79+5Fq1atEBcXVxV9rH30NUAsgiYiIpKFxSmIWbNmYfr06Xj33XdLbX/ppZfQt29fq3Wu1mIGiIiISFYWZ4ASEhIwduzYUtufeuopnDx50iqdqvVYBE1ERCQriwOgBg0aID4+vtT2+Ph4eHt7W6NPtR+LoImIiGRV4TGYN954Ay+88AKeeeYZjBs3DhcuXEBkZCQAYOfOnXjvvfcwY8aMKutorcKFEImIiGQliKIoVqShUqlEUlISGjRogMWLF2PhwoW4fv06AMDf3x8zZ87ElClTIAhClXbYFjIzM+Hm5oaMjAy4urpa/wk+6QTcPAuM3gA07W79/RMREdVBlpy/K5wB0sdJgiBg+vTpmD59OrKysgAALi4u99DdOog1QERERLKyqAaoZHbHxcXlnoOfJUuWoGnTpnBwcEDXrl2xb9++ctuvWrUKoaGhcHBwQJs2bbBhw4ZSbRISEjB48GC4ubnB2dkZnTt3xpUrV+6pn1Yl8lIYREREcrIoAGrevDk8PT3LvVli5cqVmDFjBubOnYtDhw4hPDwc0dHRSE1NNdt+165dGDlyJMaOHYvDhw8jJiYGMTExOH78uKHN+fPn0aNHD4SGhmLbtm04evQoXnvtNTg4OFjUtyplWAfI4hp0IiIisoIK1wApFAosXrwYbm5u5baLjY2t8JN37doVnTt3xqeffgoA0Gq1CAgIwOTJkzFr1qxS7UeMGIGcnBysX7/esK1bt25o164dPv/8cwDAo48+Cjs7O/zwww8V7kdJVV4D9EELIDsZGL8D8Gtr/f0TERHVQVVSAwRIwYW1proXFBTg4MGDmD17tmGbQqFAVFQUdu/ebfYxu3fvLjXTLDo6GmvWrAEgBVB//vknXnzxRURHR+Pw4cMIDAzE7NmzERMTU2Zf8vPzkZ+fb/g5MzOz8i+sIrgQIhERkawqPAZj7dldaWlp0Gg08PHxMdnu4+OD5ORks49JTk4ut31qaiqys7Px7rvvol+/fvj7778xdOhQDBs2DNu3by+zL/Pnz4ebm5vhFhAQcI+v7i5YBE1ERCSrCgdAFRwpk5VWKy0wOGTIEEyfPh3t2rXDrFmzMHDgQMMQmTmzZ89GRkaG4ZaYmFi1HTUshMgMEBERkRwqfAbWBxfW4uXlBaVSiZSUFJPtKSkp8PX1NfsYX1/fctt7eXlBpVIhLCzMpE3Lli3x33//ldkXtVoNtVpdmZdROYaFEFkETUREJAfZzsD29vbo2LEjtmzZYtim1WqxZcsWREREmH1MRESESXsAiIuLM7S3t7dH586dcfr0aZM2Z86cQZMmTaz8Cu6BltPgiYiI5CTrGXjGjBmIjY1Fp06d0KVLFyxevBg5OTkYM2YMAODJJ59Ew4YNMX/+fADA1KlT0bNnTyxcuBADBgzAihUrcODAASxbtsywz5kzZ2LEiBG4//770bt3b2zatAnr1q3Dtm3b5HiJ5rEGiIiISFayBkAjRozAjRs3MGfOHCQnJ6Ndu3bYtGmTodD5ypUrUCiKk1SRkZFYvnw5Xn31Vbz88ssICQnBmjVr0Lp1a0OboUOH4vPPP8f8+fMxZcoUtGjRAr/99ht69Ohh89dnlihyIUQiIiKZVXgdoLqkStcB0mqAN3QLRs68ADjXt+7+iYiI6ihLzt+swrU1ff0PwCEwIiIimTAAsjV9/Q/AAIiIiEgmDIBsTTTOALEGiIiISA4MgGzNJAPEAIiIiEgODIBszbgGSOAQGBERkRwYANmaIQASAAUPPxERkRx4BrY1LoJIREQkOwZAtsZFEImIiGTHAMjWDBdCZQaIiIhILgyAbE2rlb4yA0RERCQbBkC2ZqgB4qEnIiKSC8/CtsYaICIiItkxALI1QwaIARAREZFcGADZGougiYiIZMcAyNYMRdAMgIiIiOTCAMjWuBAiERGR7BgA2RqLoImIiGTHAMjWWANEREQkOwZAtqZlBoiIiEhuDIBszRAA8dATERHJhWdhW2MNEBERkewYANkaa4CIiIhkxwDI1lgDREREJDsGQLbGdYCIiIhkxwDI1gwZIAZAREREcmEAZGssgiYiIpIdAyBbYxE0ERGR7BgA2RqLoImIiGTHAMjWDEXQPPRERERy4VnY1kSt9JUZICIiItkwALI11gARERHJjgGQrbEGiIiISHYMgGzNUAPEAIiIiEguDIBsjVeDJyIikh3PwrbGhRCJiIhkxwDI1lgETUREJDsGQLbGImgiIiLZMQCyNV4NnoiISHYMgGzNsBAiAyAiIiK5MACyNdYAERERyY4BkK2xBoiIiEh2DIBsjTVAREREsmMAZGuGdYAYABEREcmFAZCtcQiMiIhIdgyAbI1F0ERERLJjAGRrzAARERHJjgGQrbEImoiISHYMgGyNRdBERESyYwBka/ohMNYAERERyYYBkK2xBoiIiEh2DIBsjTVAREREsmMAZGsiM0BERERyYwBka4YaIB56IiIiufAsbGuGITBmgIiIiOTCAMjWWARNREQkOwZAtsYiaCIiItkxALI1FkETERHJjgGQrbEImoiISHY8C9saa4CIiIhkxwDI1lgDREREJDsGQLbGGiAiIiLZMQCyNX0GiBdDJSIikg0DIFvTaqWvHAIjIiKSDQMgW+NK0ERERLKrFgHQkiVL0LRpUzg4OKBr167Yt29fue1XrVqF0NBQODg4oE2bNtiwYYPJ/aNHj4YgCCa3fv36VeVLqDgWQRMREclO9gBo5cqVmDFjBubOnYtDhw4hPDwc0dHRSE1NNdt+165dGDlyJMaOHYvDhw8jJiYGMTExOH78uEm7fv36ISkpyXD7+eefbfFy7o5F0ERERLKTPQBatGgRnnnmGYwZMwZhYWH4/PPP4eTkhK+//tps+48++gj9+vXDzJkz0bJlS7z55pvo0KEDPv30U5N2arUavr6+hpuHh4ctXs7dGRZCZAaIiIhILrIGQAUFBTh48CCioqIM2xQKBaKiorB7926zj9m9e7dJewCIjo4u1X7btm3w9vZGixYtMGHCBNy8ebPMfuTn5yMzM9PkVmUMCyEyACIiIpKLrOMwaWlp0Gg08PHxMdnu4+ODU6dOmX1McnKy2fbJycmGn/v164dhw4YhMDAQ58+fx8svv4z+/ftj9+7dUCpLBx7z58/H66+/boVXVAGsASIiqrO0Wi0KCgrk7kaNZWdnZ/Y8Xhm1shDl0UcfNXzfpk0btG3bFkFBQdi2bRv69OlTqv3s2bMxY8YMw8+ZmZkICAioms6xBoiIqE4qKCjAxYsXodUvh0KV4u7uDl9fXwiCcE/7kfUs7OXlBaVSiZSUFJPtKSkp8PX1NfsYX19fi9oDQLNmzeDl5YVz586ZDYDUajXUanUlXkElcCFEIqI6RxRFJCUlQalUIiAgAAqF7CW4NY4oisjNzTVMkvLz87un/ckaANnb26Njx47YsmULYmJiAEjpwS1btmDSpElmHxMREYEtW7Zg2rRphm1xcXGIiIgo83muXr2Kmzdv3vPBumfGUT8zQEREdUZRURFyc3Ph7+8PJycnubtTYzk6OgIAUlNT4e3tfU/DYbKHoDNmzMAXX3yB7777DgkJCZgwYQJycnIwZswYAMCTTz6J2bNnG9pPnToVmzZtwsKFC3Hq1CnMmzcPBw4cMARM2dnZmDlzJvbs2YNLly5hy5YtGDJkCIKDgxEdHS3LazTQZ38AgNE/EVGdodFI5Q/29vYy96Tm0weQhYWF97Qf2dMQI0aMwI0bNzBnzhwkJyejXbt22LRpk6HQ+cqVKyapwsjISCxfvhyvvvoqXn75ZYSEhGDNmjVo3bo1AECpVOLo0aP47rvvkJ6eDn9/fzz44IN48803bTfMVRaTAEj2Q09ERDZ2r3UrZL1jKIiiKFplT7VIZmYm3NzckJGRAVdXV+vtOD8LmN9I+v6VZMDO0Xr7JiKiaisvLw8XL15EYGAgHBwc5O5OjVbesbTk/M1xGFsyzgCxCJqIiOqgpk2bYvHixXJ3gwGQTbEImoiIaoiS19QseZs3b16l9rt//36MGzfOup2tBJ6FbYlF0EREVEMkJSUZvl+5ciXmzJmD06dPG7bVq1fP8L0oitBoNFCp7h5WNGjQwLodrSSehW2JiyASERF0a9oUFMlyq2jpr/H1NN3c3CAIguHnU6dOwcXFBRs3bkTHjh2hVqvx33//4fz58xgyZAh8fHxQr149dO7cGZs3bzbZb8khMEEQ8OWXX2Lo0KFwcnJCSEgI1q5da83DbRbPxLbERRCJiAjAnUINwub8Jctzn3wjGk721jn9z5o1Cx988AGaNWsGDw8PJCYm4qGHHsLbb78NtVqN77//HoMGDcLp06fRuHHjMvfz+uuvY8GCBXj//ffxySefYNSoUbh8+TI8PT2t0k9zmAGyJS0zQEREVHu88cYb6Nu3L4KCguDp6Ynw8HCMHz8erVu3RkhICN58800EBQXdNaMzevRojBw5EsHBwXjnnXeQnZ2Nffv2VWnfeSa2JV4JnoiIADjaKXHyDXkW53W0s945qFOnTiY/Z2dnY968efjzzz+RlJSEoqIi3LlzB1euXCl3P23btjV87+zsDFdXV8MlL6oKAyBbEhkAERGRVPdirWEoOTk7O5v8/MILLyAuLg4ffPABgoOD4ejoiIcffhgFBQXl7sfOzs7kZ0EQqvyisTX/6Nck+hogDoEREVEttHPnTowePRpDhw4FIGWELl26JG+nysAaIFtiETQREdViISEh+P333xEfH48jR47gscceq/JMTmUxALIlFkETEVEttmjRInh4eCAyMhKDBg1CdHQ0OnToIHe3zOK1wMyosmuBJe4HvooC3BsD045Zb79ERFSt8Vpg1sNrgdVEXAiRiIioWmAAZEusASIiIqoWGADZEmuAiIiIqgUGQLZkmAbPDBAREZGcGADZkqibCsgAiIiISFYMgGyJNUBERETVAgMgW+JK0ERERNUCAyBbYhE0ERFRtcAAyJZYBE1ERFQtMACyJRZBExFRHdKrVy9MmzZN7m6YxQDIllgETURENcSgQYPQr18/s/ft2LEDgiDg6NGjNu6V9TAAsiXWABERUQ0xduxYxMXF4erVq6Xu++abb9CpUye0bdtWhp5ZBwMgW2INEBERAYAoAgU58twqeA30gQMHokGDBvj2229NtmdnZ2PVqlWIiYnByJEj0bBhQzg5OaFNmzb4+eefq+BgVQ2mImzJcDFUBkBERHVaYS7wjr88z/3ydcDe+a7NVCoVnnzySXz77bd45ZVXIAgCAGDVqlXQaDR4/PHHsWrVKrz00ktwdXXFn3/+iSeeeAJBQUHo0qVLVb+Ke8YMkC3ph8BYA0RERDXAU089hfPnz2P79u2Gbd988w2GDx+OJk2a4IUXXkC7du3QrFkzTJ48Gf369cMvv/wiY48rjhkgW2INEBERAYCdk5SJkeu5Kyg0NBSRkZH4+uuv0atXL5w7dw47duzAG2+8AY1Gg3feeQe//PILrl27hoKCAuTn58PJqeL7lxPPxLbEGiAiIgIAQajQMFR1MHbsWEyePBlLlizBN998g6CgIPTs2RPvvfcePvroIyxevBht2rSBs7Mzpk2bhoKCArm7XCEcArMlXgqDiIhqmEceeQQKhQLLly/H999/j6eeegqCIGDnzp0YMmQIHn/8cYSHh6NZs2Y4c+aM3N2tMAZAtqRQAipHQKWWuydEREQVUq9ePYwYMQKzZ89GUlISRo8eDQAICQlBXFwcdu3ahYSEBIwfPx4pKSnydtYCDIBsqftU4NVkYOCHcveEiIiowsaOHYvbt28jOjoa/v7S7LVXX30VHTp0QHR0NHr16gVfX1/ExMTI21ELcCyGiIiIyhUREQGxxPpBnp6eWLNmTbmP27ZtW9V16h4xA0RERER1DgMgIiIiqnMYABEREVGdwwCIiIiI6hwGQERERDZSspCYLGetY8gAiIiIqIopldIVAGrKKsnVWW5uLgDAzs7unvbDafBERERVTKVSwcnJCTdu3ICdnR0UCuYfLCWKInJzc5Gamgp3d3dDUFlZDICIiIiqmCAI8PPzw8WLF3H58mW5u1Ojubu7w9fX9573wwCIiIjIBuzt7RESEsJhsHtgZ2d3z5kfPQZARERENqJQKODg4CB3NwgsgiYiIqI6iAEQERER1TkMgIiIiKjOYQ2QGfpFljIzM2XuCREREVWU/rxdkcUSGQCZkZWVBQAICAiQuSdERERkqaysLLi5uZXbRhC5LncpWq0W169fh4uLCwRBsOq+MzMzERAQgMTERLi6ulp132SKx9p2eKxth8fadnisbcdax1oURWRlZcHf3/+ui00yA2SGQqFAo0aNqvQ5XF1d+Q9lIzzWtsNjbTs81rbDY2071jjWd8v86LEImoiIiOocBkBERERU5zAAsjG1Wo25c+dCrVbL3ZVaj8fadnisbYfH2nZ4rG1HjmPNImgiIiKqc5gBIiIiojqHARARERHVOQyAiIiIqM5hAERERER1DgMgG1qyZAmaNm0KBwcHdO3aFfv27ZO7SzXe/Pnz0blzZ7i4uMDb2xsxMTE4ffq0SZu8vDxMnDgR9evXR7169TB8+HCkpKTI1OPa491334UgCJg2bZphG4+19Vy7dg2PP/446tevD0dHR7Rp0wYHDhww3C+KIubMmQM/Pz84OjoiKioKZ8+elbHHNZNGo8Frr72GwMBAODo6IigoCG+++abJtaR4rCvn33//xaBBg+Dv7w9BELBmzRqT+ytyXG/duoVRo0bB1dUV7u7uGDt2LLKzs63SPwZANrJy5UrMmDEDc+fOxaFDhxAeHo7o6GikpqbK3bUabfv27Zg4cSL27NmDuLg4FBYW4sEHH0ROTo6hzfTp07Fu3TqsWrUK27dvx/Xr1zFs2DAZe13z7d+/H//73//Qtm1bk+081tZx+/ZtdO/eHXZ2dti4cSNOnjyJhQsXwsPDw9BmwYIF+Pjjj/H5559j7969cHZ2RnR0NPLy8mTsec3z3nvvYenSpfj000+RkJCA9957DwsWLMAnn3xiaMNjXTk5OTkIDw/HkiVLzN5fkeM6atQonDhxAnFxcVi/fj3+/fdfjBs3zjodFMkmunTpIk6cONHws0ajEf39/cX58+fL2KvaJzU1VQQgbt++XRRFUUxPTxft7OzEVatWGdokJCSIAMTdu3fL1c0aLSsrSwwJCRHj4uLEnj17ilOnThVFkcfaml566SWxR48eZd6v1WpFX19f8f333zdsS09PF9Vqtfjzzz/boou1xoABA8SnnnrKZNuwYcPEUaNGiaLIY20tAMTVq1cbfq7IcT158qQIQNy/f7+hzcaNG0VBEMRr167dc5+YAbKBgoICHDx4EFFRUYZtCoUCUVFR2L17t4w9q30yMjIAAJ6engCAgwcPorCw0OTYh4aGonHjxjz2lTRx4kQMGDDA5JgCPNbWtHbtWnTq1An/93//B29vb7Rv3x5ffPGF4f6LFy8iOTnZ5Fi7ubmha9euPNYWioyMxJYtW3DmzBkAwJEjR/Dff/+hf//+AHisq0pFjuvu3bvh7u6OTp06GdpERUVBoVBg796999wHXgzVBtLS0qDRaODj42Oy3cfHB6dOnZKpV7WPVqvFtGnT0L17d7Ru3RoAkJycDHt7e7i7u5u09fHxQXJysgy9rNlWrFiBQ4cOYf/+/aXu47G2ngsXLmDp0qWYMWMGXn75Zezfvx9TpkyBvb09YmNjDcfT3HsKj7VlZs2ahczMTISGhkKpVEKj0eDtt9/GqFGjAIDHuopU5LgmJyfD29vb5H6VSgVPT0+rHHsGQFRrTJw4EcePH8d///0nd1dqpcTEREydOhVxcXFwcHCQuzu1mlarRadOnfDOO+8AANq3b4/jx4/j888/R2xsrMy9q11++eUX/PTTT1i+fDlatWqF+Ph4TJs2Df7+/jzWtRyHwGzAy8sLSqWy1GyYlJQU+Pr6ytSr2mXSpElYv349tm7dikaNGhm2+/r6oqCgAOnp6Sbteewtd/DgQaSmpqJDhw5QqVRQqVTYvn07Pv74Y6hUKvj4+PBYW4mfnx/CwsJMtrVs2RJXrlwBAMPx5HvKvZs5cyZmzZqFRx99FG3atMETTzyB6dOnY/78+QB4rKtKRY6rr69vqYlCRUVFuHXrllWOPQMgG7C3t0fHjh2xZcsWwzatVostW7YgIiJCxp7VfKIoYtKkSVi9ejX++ecfBAYGmtzfsWNH2NnZmRz706dP48qVKzz2FurTpw+OHTuG+Ph4w61Tp04YNWqU4Xsea+vo3r17qeUczpw5gyZNmgAAAgMD4evra3KsMzMzsXfvXh5rC+Xm5kKhMD0VKpVKaLVaADzWVaUixzUiIgLp6ek4ePCgoc0///wDrVaLrl273nsn7rmMmipkxYoVolqtFr/99lvx5MmT4rhx40R3d3cxOTlZ7q7VaBMmTBDd3NzEbdu2iUlJSYZbbm6uoc2zzz4rNm7cWPznn3/EAwcOiBEREWJERISMva49jGeBiSKPtbXs27dPVKlU4ttvvy2ePXtW/Omnn0QnJyfxxx9/NLR59913RXd3d/GPP/4Qjx49Kg4ZMkQMDAwU79y5I2PPa57Y2FixYcOG4vr168WLFy+Kv//+u+jl5SW++OKLhjY81pWTlZUlHj58WDx8+LAIQFy0aJF4+PBh8fLly6IoVuy49uvXT2zfvr24d+9e8b///hNDQkLEkSNHWqV/DIBs6JNPPhEbN24s2tvbi126dBH37Nkjd5dqPABmb998842hzZ07d8TnnntO9PDwEJ2cnMShQ4eKSUlJ8nW6FikZAPFYW8+6devE1q1bi2q1WgwNDRWXLVtmcr9WqxVfe+010cfHR1Sr1WKfPn3E06dPy9TbmiszM1OcOnWq2LhxY9HBwUFs1qyZ+Morr4j5+fmGNjzWlbN161az78+xsbGiKFbsuN68eVMcOXKkWK9ePdHV1VUcM2aMmJWVZZX+CaJotNwlERERUR3AGiAiIiKqcxgAERERUZ3DAIiIiIjqHAZAREREVOcwACIiIqI6hwEQERER1TkMgIiIiKjOYQBEREREdQ4DICKiMgiCgDVr1sjdDSKqAgyAiKhaGj16NARBKHXr16+f3F0jolpAJXcHiIjK0q9fP3zzzTcm29RqtUy9IaLahBkgIqq21Go1fH19TW4eHh4ApOGppUuXon///nB0dESzZs3w66+/mjz+2LFjeOCBB+Do6Ij69etj3LhxyM7ONmnz9ddfo1WrVlCr1fDz88OkSZNM7k9LS8PQoUPh5OSEkJAQrF271nDf7du3MWrUKDRo0ACOjo4ICQkpFbARUfXEAIiIaqzXXnsNw4cPx5EjRzBq1Cg8+uijSEhIAADk5OQgOjoaHh4e2L9/P1atWoXNmzebBDhLly7FxIkTMW7cOBw7dgxr165FcHCwyXO8/vrreOSRR3D06FE89NBDGDVqFG7dumV4/pMnT2Ljxo1ISEjA0qVL4eXlZbsDQESVZ5VryhMRWVlsbKyoVCpFZ2dnk9vbb78tiqIoAhCfffZZk8d07dpVnDBhgiiKorhs2TLRw8NDzM7ONtz/559/igqFQkxOThZFURT9/f3FV155pcw+ABBfffVVw8/Z2dkiAHHjxo2iKIrioEGDxDFjxljnBRORTbEGiIiqrd69e2Pp0qUm2zw9PQ3fR0REmNwXERGB+Ph4AEBCQgLCw8Ph7OxsuL979+7QarU4ffo0BEHA9evX0adPn3L70LZtW8P3zs7OcHV1RWpqKgBgwoQJGD58OA4dOoQHH3wQMTExiIyMrNRrJSLbYgBERNWWs7NzqSEpa3F0dKxQOzs7O5OfBUGAVqsFAPTv3x+XL1/Ghg0bEBcXhz59+mDixIn44IMPrN5fIrIu1gARUY21Z8+eUj+3bNkSANCyZUscOXIEOTk5hvt37twJhUKBFi1awMXFBU2bNsWWLVvuqQ8NGjRAbGwsfvzxRyxevBjLli27p/0RkW0wA0RE1VZ+fj6Sk5NNtqlUKkOh8apVq9CpUyf06NEDP/30E/bt24evvvoKADBq1CjMnTsXsbGxmDdvHm7cuIHJkyfjiSeegI+PDwBg3rx5ePbZZ+Ht7Y3+/fsjKysLO3fuxOTJkyvUvzlz5qBjx45o1aoV8vPzsX79ekMARkTVGwMgIqq2Nm3aBD8/P5NtLVq0wKlTpwBIM7RWrFiB5557Dn5+fvj5558RFhYGAHBycsJff/2FqVOnonPnznBycsLw4cOxaNEiw75iY2ORl5eHDz/8EC+88AK8vLzw8MMPV7h/9vb2mD17Ni5dugRHR0fcd999WLFihRVeORFVNUEURVHuThARWUoQBKxevRoxMTFyd4WIaiDWABEREVGdwwCIiIiI6hzWABFRjcTReyK6F8wAERERUZ3DAIiIiIjqHAZAREREVOcwACIiIqI6hwEQERER1TkMgIiIiKjOYQBEREREdQ4DICIiIqpz/h+EgONP/IcyQAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# https://www.evidentlyai.com/ranking-metrics/precision-recall-at-k\n",
        "plt.plot(epochs_tracked, [precision for precision, _ in train_topks],\n",
        "         label=\"Train\")\n",
        "plt.plot(epochs_tracked, [precision for precision, _ in val_topks],\n",
        "         label=\"Val\")\n",
        "plt.ylabel(f\"Top {K} precision\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJnetNBG6C_k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ff6cc45-a01a-4648-b28d-aa59cc99d85c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed after 100 epochs\n",
            "Average bpr_loss on the test set is 7e-06, and regularization loss is 0.0.\n",
            " Top K precision = 0.08799999999999995, recall = 0.0075343222497241645.\n"
          ]
        }
      ],
      "source": [
        "# predict on the test set\n",
        "lightGCN.eval()\n",
        "print(\"Training completed after {} epochs\".format(epochs))\n",
        "\n",
        "users_test = samples_test[:, 0:1]\n",
        "pos_test = samples_test[:, 1:2]\n",
        "neg_test = samples_test[:, 2:3]\n",
        "\n",
        "loss_test, reg_loss_test = bpr_loss(\n",
        "    lightGCN, users_test, pos_test, neg_test, data, test_mask)\n",
        "reg_loss_test = reg_loss_test * weight_decay\n",
        "\n",
        "# predict on the test set\n",
        "user_indices = samples_test[:, 0]\n",
        "user_indices = user_indices.repeat(2).long()\n",
        "item_indices = torch.cat((samples_test[:, 1], samples_test[:, 2])).long()\n",
        "pred_test = getUsersRating(lightGCN, users_test[:,0], data)\\\n",
        "    [user_indices, item_indices]\n",
        "truth_test = data[\"edge_index\"][users_test.long()[:,0]]\\\n",
        "    [user_indices, item_indices]\n",
        "test_topk_precision, test_topk_recall = personalized_topk(\n",
        "    pred_test, K, user_indices, data[\"edge_index\"])\n",
        "\n",
        "print(\"Average bpr_loss on the test set is {}, and regularization loss is {}.\\n\".format(round(float((loss_test+reg_loss_test)/len(samples_test)), 6),\n",
        "                                                                                                round(float(reg_loss_test/len(samples_test)), 6)),\n",
        "      \"Top K precision = {}, recall = {}.\".format(test_topk_precision, test_topk_recall))\n",
        "\n",
        "# Save model embeddings.\n",
        "torch.save(lightGCN, config_dict[\"model_name\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}